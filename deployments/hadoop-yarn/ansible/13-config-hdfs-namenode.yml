#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

- name: "Configure HDFS namenode"
  hosts: master01
  gather_facts: false
  vars_files:
    - config/ansible.yml
    - config/hadoop.yml
    - /tmp/ansible-vars.yml
  vars:
    hdfsmetalink: "{{ hostvars[inventory_hostname].paths.hdfsmetalink }}"
    hdfsmetadest: "{{ hostvars[inventory_hostname].paths.hdfsmetadest }}"
    hdfsimage: "{{hdfsmetalink}}/namenode/fsimage"

  tasks:

    - name: "Create HDFS metadata directory"
      include_tasks: "tasks/create-linked.yml"
      vars:
        linkdest: "{{hdfsmetadest}}"
        linkpath: "{{hdfsmetalink}}"
        linkuser: "{{hdfsuser}}"

    - name: "Create [{{hdfsimage}}]"
      become: true
      file:
        path: "{{hdfsimage}}"
        mode: 'u=rwx,g=rwxs,o=rx'
        state: directory
        recurse: true
        owner: "{{hdfsuser}}"
        group: "{{hdfsuser}}"

    # https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Configuring_the_Hadoop_Daemons
    # https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
    - name: "Configure [{{hdhome}}/etc/hadoop/hdfs-site.xml]"
      become: true
      blockinfile:
        path: "{{hdhome}}/etc/hadoop/hdfs-site.xml"
        marker: "<!-- {mark} Ansible managed HDFS namenode config -->"
        insertbefore: "</configuration>"
        block: |
            <!--+
                | Determines where on the local filesystem the DFS name node should store the name table(fsimage).
                | If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <property>
                <name>dfs.namenode.name.dir</name>
                <value>{{hdfsimage}}</value>
            </property>

            <!--+
                | Names a file that contains a list of hosts that are permitted to connect to the namenode.
                | The full pathname of the file must be specified. If the value is empty, all hosts are permitted.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <property>
                <name>dfs.hosts</name>
                <value/>
            </property>

            <!--+
                | Names a file that contains a list of hosts that are not permitted to connect to the namenode.
                | The full pathname of the file must be specified. If the value is empty, no hosts are excluded.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <property>
                <name>dfs.hosts.exclude</name>
                <value/>
            </property>

            <!--+
                | Default block replication.
                | The actual number of replications can be specified when the file is created.
                | The default is used if replication is not specified in create time.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <property>
                <name>dfs.replication</name>
                <value>2</value>
            </property>

            <!--+
                | Reserved space calculator.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <property>
                <name>dfs.datanode.du.reserved.calculator</name>
                <value>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$ReservedSpaceCalculatorPercentage</value>
            </property>

            <!--+
                | Reserved space percentage.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <property>
                <name>dfs.datanode.du.reserved.pct</name>
                <value>10</value>
            </property>

            <property>
                <name>dfs.client.use.datanode.hostname</name>
                <value>true</value>
            </property>

            <property>
                <name>dfs.datanode.use.datanode.hostname</name>
                <value>true</value>
            </property>
