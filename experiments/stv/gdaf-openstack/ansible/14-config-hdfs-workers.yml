#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

- name: "Configure Hadoop workers"
  hosts: workers:zeppelin
  gather_facts: false
  vars:
    hdname: "hadoop-3.2.1"
    hdbase: "/opt"
    hdhome: "/opt/hadoop"
    hddata: "/var/local/hadoop"
    hdhost: "{{groups['masters'][0]}}"
    hduser: "{{hostvars[inventory_hostname].login}}"

  tasks:

    # TODO Create from hosts.yml
    - name: "Create [/data-01/hdfs/data]"
      become: true
      file:
        path: "/data-01/hdfs/data"
        mode: 'u=rwx,g=rwxs,o=rx'
        state: directory
        owner: "{{hduser}}"
        group: "{{hduser}}"

    # https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Configuring_the_Hadoop_Daemons
    - name: "Configure [{{hdhome}}/etc/hadoop/hdfs-site.xml]"
      become: true
      blockinfile:
        path:   "{{hdhome}}/etc/hadoop/hdfs-site.xml"
        marker: "<!-- {mark} Ansible managed HDFS worker config -->"
        insertbefore: "</configuration>"
        block: |
            <!--+
                | Determines where on the local filesystem an DFS data node should store its blocks.
                | If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices.
                | The directories should be tagged with corresponding storage types ([SSD]/[DISK]/[ARCHIVE]/[RAM_DISK]) for HDFS storage policies.
                | The default storage type will be DISK if the directory does not have a storage type tagged explicitly.
                | Directories that do not exist will be created if local filesystem permission allows. 
                +-->
            <property>
                <name>dfs.datanode.data.dir</name>
                <value>/data-01/hdfs/data</value>
            </property>


