#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#

    #
    # Try installing the Cinder CSI driver.
    # https://kubernetes.io/blog/2020/02/07/deploying-external-openstack-cloud-provider-with-kubeadm/#deploy-cinder-csi


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubernator \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        --volume "${AGLAIS_CODE}/experiments/zrq/kubernetes:/kubernetes:z" \
        atolmis/openstack-client \
        bash


# -----------------------------------------------------
# Set the cloud, credentials and cluster names.
#[user@kubernator]

    cloudname=gaia-prod
    clustername=drupal-one


# -----------------------------------------------------
# Get the connection details for our cluster.
#[user@kubernator]

    mkdir -p "${HOME}/.kube/${clustername:?}"
    openstack \
        --os-cloud "${cloudname:?}-super" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube/${clustername:?}"


# -----------------------------------------------------
# Check kubectl can get the connection details for our cluster.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        cluster-info

--START--
Kubernetes master is running at https://128.232.227.226:6443
Heapster is running at https://128.232.227.226:6443/api/v1/namespaces/kube-system/services/heapster/proxy
CoreDNS is running at https://128.232.227.226:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
--END--


# -----------------------------------------------------
# Create a secret with CA certs for OpenStack's API endpoints.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        create secret \
            --namespace kube-system \
                generic openstack-ca-cert

--START--
secret/openstack-ca-cert created
--END--


    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        --namespace kube-system \
        describe secret \
            openstack-ca-cert

--START--
Name:         openstack-ca-cert
Namespace:    kube-system
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
--END--


    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        --namespace kube-system \
        get secret \
            openstack-ca-cert \
                --output json

--START--
{
    "apiVersion": "v1",
    "kind": "Secret",
    "metadata": {
        "creationTimestamp": "2020-07-07T00:37:25Z",
        "name": "openstack-ca-cert",
        "namespace": "kube-system",
        "resourceVersion": "161496",
        "selfLink": "/api/v1/namespaces/kube-system/secrets/openstack-ca-cert",
        "uid": "dd743775-ecd9-4f29-b8ea-9618c784f2e5"
    },
    "type": "Opaque"
}
--END--


# -----------------------------------------------------
# Create the RBAC resources.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        apply --filename https://raw.githubusercontent.com/kubernetes/cloud-provider-openstack/release-1.15/manifests/cinder-csi-plugin/cinder-csi-controllerplugin-rbac.yaml

--START--
serviceaccount/csi-cinder-controller-sa created
clusterrole.rbac.authorization.k8s.io/csi-attacher-role created
clusterrolebinding.rbac.authorization.k8s.io/csi-attacher-binding created
clusterrole.rbac.authorization.k8s.io/csi-provisioner-role created
clusterrolebinding.rbac.authorization.k8s.io/csi-provisioner-binding created
clusterrole.rbac.authorization.k8s.io/csi-snapshotter-role created
clusterrolebinding.rbac.authorization.k8s.io/csi-snapshotter-binding created
--END--


    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        apply --filename https://github.com/kubernetes/cloud-provider-openstack/raw/release-1.15/manifests/cinder-csi-plugin/cinder-csi-nodeplugin-rbac.yaml

--START--
serviceaccount/csi-cinder-node-sa created
clusterrole.rbac.authorization.k8s.io/csi-nodeplugin-role created
clusterrolebinding.rbac.authorization.k8s.io/csi-nodeplugin-binding created
--END--

# -----------------------------------------------------
# Deploy the controller plugin.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        apply --filename /kubernetes/cinder-csi/cinder-csi-controllerplugin.yaml

--START--
service/csi-cinder-controller-service created
statefulset.apps/csi-cinder-controllerplugin created
--END--


# -----------------------------------------------------
# Deploy the node plugin.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        apply --filename /kubernetes/cinder-csi/cinder-csi-nodeplugin.yaml

--START--
daemonset.apps/csi-cinder-nodeplugin created
--END--


# -----------------------------------------------------
# Create a StorageClass.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        apply --filename /kubernetes/cinder-csi/cinder-csi-storageclass.yaml

--START--
storageclass.storage.k8s.io/csi-sc-cinderplugin created
--END--


# -----------------------------------------------------
# Create a PersistentVolumeClaim.
#[user@kubernator]

    cat > /tmp/test-pvc.yaml << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: test-volume
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: csi-sc-cinderplugin
EOF

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        apply --filename /tmp/test-pvc.yaml


--START--
persistentvolumeclaim/test-volume created
--END--


# -----------------------------------------------------
# List the PersistentVolumeClaims.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        get pvc

--START--
NAME          STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS          AGE
test-volume   Pending                                      csi-sc-cinderplugin   65s
--END--


# -----------------------------------------------------
# List the Cinder volumes.
#[user@kubernator]

    openstack \
        --os-cloud "${cloudname:?}" \
        volume list

--START--
-
--END--


# -----------------------------------------------------
# Create a Pod that uses the claim.
#[user@kubernator]

    cat > /tmp/test-pod.yaml << EOF
apiVersion: v1
kind: Pod
metadata:
  name: web
spec:
  containers:
    - name: web
      image: nginx
      ports:
        - name: web
          containerPort: 80
          hostPort: 8081
          protocol: TCP
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: mypd
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: test-volume
EOF

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        apply --filename /tmp/test-pod.yaml


--START--
pod/web created
--END--


# -----------------------------------------------------
# List the Pods.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        get pod

--START--
NAME   READY   STATUS    RESTARTS   AGE
web    0/1     Pending   0          62s
--END--


# -----------------------------------------------------
# List the PersistentVolumeClaims.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        get pvc

--START--
NAME          STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS          AGE
test-volume   Pending                                      csi-sc-cinderplugin   65s
--END--


# -----------------------------------------------------
# List the Cinder volumes.
#[user@kubernator]

    openstack \
        --os-cloud "${cloudname:?}" \
        volume list

--START--
-
--END--


# -----------------------------------------------------
# Error messages in the dashboard.


    kubelet drupal-one-x5mbegvpiycq-node-3
        MountVolume.SetUp failed for volume "pods-cloud-data" : hostPath type check failed: /var/lib/cloud/data is not a directory

    kubelet drupal-one-x5mbegvpiycq-node-0
        Unable to mount volumes for pod "csi-cinder-nodeplugin-54zjz_kube-system(16f32a87-c66d-4ab5-8b9c-e9d4a595d84f)":
            timeout expired waiting for volumes to attach or mount for pod "kube-system"/"csi-cinder-nodeplugin-54zjz".
                list of unmounted volumes=[pods-cloud-data secret-cinderplugin].
                list of unattached volumes=[socket-dir registration-dir kubelet-dir pods-mount-dir pods-cloud-data pods-probe-dir secret-cinderplugin ca-cert csi-cinder-node-sa-token-z7494]

    kubelet drupal-one-x5mbegvpiycq-node-0
        MountVolume.SetUp failed for volume "secret-cinderplugin" : secret "cloud-config" not found

    kubelet drupal-one-x5mbegvpiycq-node-0
        MountVolume.SetUp failed for volume "pods-cloud-data" : hostPath type check failed: /var/lib/cloud/data is not a directory


    #
    # The secret from ca.cert was a guess.
    # The plugin config assumed things are installed on the worker nodes.
    # First try .. lots still to figure out.
    #






