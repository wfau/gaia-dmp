#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname terraformer \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        --volume "${AGLAIS_CODE}/experiments/zrq/terraform:/terraform:z" \
        atolmis/terraform-client \
        bash


# -----------------------------------------------------
# Set the cloud, credentials and cluster names.
#[user@terraformer]

    cloudname=gaia-prod
    clustername=Tiberius
    keypairname=zrq-gaia-keypair


# -----------------------------------------------------
# Delete any old state.
#[user@terraformer]

    rm -rf /terraform/.terraform
    rm -f  /terraform/tfvars

    rm -f  /terraform/terraform.tfsate
    rm -f  /terraform/terraform.tfsate.backup

# -----------------------------------------------------
# Create our tfvars file.
#[user@terraformer]

    cat > "${HOME}/cluster.tfvars" << EOF
zrq_cloud_name   = "${cloudname:?}-super"
zrq_cluster_name = "${clustername:?}"
zrq_master_count = 2
zrq_worker_count = 4
zrq_max_worker_count = 10
EOF


# -----------------------------------------------------
# Run Terraform to deploy our cluster.
#[user@terraformer]

    pushd "/terraform"

        terraform init

    >   ....
    >   Initializing modules...
    >   ....
    >   Initializing the backend...
    >   ....
    >   Initializing provider plugins...
    >   ....
    >   Terraform has been successfully initialized!


        terraform plan \
            -var-file "${HOME}/cluster.tfvars"


    >   
    >     # module.cluster.null_resource.kubeconfig is tainted, so must be replaced
    >   -/+ resource "null_resource" "kubeconfig" {
    >       ....
    >       }
    >   
    >     # module.cluster.openstack_compute_keypair_v2.zrq_keypair must be replaced
    >   -/+ resource "openstack_compute_keypair_v2" "zrq_keypair" {
    >       ....
    >       }
    >   
    >     # module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster will be created
    >     + resource "openstack_containerinfra_cluster_v1" "zrq_cluster" {
    >       ....
    >       }
    >   
    >   Plan: 3 to add, 0 to change, 2 to destroy.


        terraform apply \
            -var-file "${HOME}/cluster.tfvars"

    >   module.cluster.null_resource.kubeconfig: Destroying... [id=869749692806911175]
    >   module.cluster.null_resource.kubeconfig: Destruction complete after 0s
    >   module.cluster.openstack_compute_keypair_v2.zrq_keypair: Destroying... [id=drupal-one-keypair]
    >   module.cluster.openstack_compute_keypair_v2.zrq_keypair: Destruction complete after 1s
    >   module.cluster.openstack_compute_keypair_v2.zrq_keypair: Creating...
    >   module.cluster.openstack_compute_keypair_v2.zrq_keypair: Creation complete after 0s [id=Tiberius-keypair]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Creating...
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [10s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [20s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [30s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [40s elapsed]
    >   ....
    >   ....
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [6m40s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [6m50s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [7m0s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [7m10s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Creation complete after 7m11s [id=6a706db6-2448-43dc-9026-649e96059925]
    >   module.cluster.null_resource.kubeconfig: Creating...
    >   module.cluster.null_resource.kubeconfig: Provisioning with 'local-exec'...
    >   module.cluster.null_resource.kubeconfig (local-exec): Executing: ["/bin/sh" "-c" "mkdir -p ~/.kube/Tiberius; openstack --os-cloud gaia-prod-super coe cluster config Tiberius --dir ~/.kube/Tiberius --force;"]
    >   module.cluster.null_resource.kubeconfig: Still creating... [10s elapsed]

    popd


# -----------------------------------------------------
# Check the kubectl config for our cluster.
#[user@terraformer]

    cat "${HOME}/.kube/${clustername:?}/config"

    >   apiVersion: v1
    >   clusters:
    >   - cluster:
    >       certificate-authority-data: LS0tLS1C........UtLS0tLQ==
    >       server: https://128.232.227.194:6443
    >     name: Tiberius
    >   contexts:
    >   - context:
    >       cluster: Tiberius
    >       user: admin
    >     name: default
    >   current-context: default
    >   kind: Config
    >   preferences: {}
    >   users:
    >   - name: admin
    >     user:
    >       client-certificate-data: LS0tLS1C........RS0tLS0t
    >       client-key-data: LS0tLS1C........tLS0tLQo=

# -----------------------------------------------------
# Use kubectl to the endpoint addresses.
#[user@terraformer]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        cluster-info

    >   Kubernetes master is running at https://128.232.227.194:6443
    >   Heapster is running at https://128.232.227.194:6443/api/v1/namespaces/kube-system/services/heapster/proxy
    >   CoreDNS is running at https://128.232.227.194:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy


