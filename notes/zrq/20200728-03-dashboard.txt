#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#


    Dashboard Helm charts.
    https://github.com/kubernetes/dashboard/tree/master/aio/deploy/helm-chart/kubernetes-dashboard#configuration


    Dashboard with external OAuth sign-in.
    https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/auth/oauth-external-auth



# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${MAGNUM_CLUSTER:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        --volume "${AGLAIS_CODE}/experiments/zrq/kubernetes:/kubernetes:z" \
        --volume "${ZEPPELIN_CODE}:/zeppelin:z" \
        atolmis/openstack-client \
        bash


# -----------------------------------------------------
# Get the connection details for our cluster.
#[user@kubernator]

    mkdir -p "${HOME}/.kube"
    openstack \
        --os-cloud "${cloudname:?}-super" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube"

    >   'SHELL'


# -----------------------------------------------------
# Check kubectl can get the connection details for our cluster.
#[user@kubernator]

    kubectl \
        cluster-info

    >   Kubernetes master is running at https://....
    >   Heapster is running at https://....
    >   CoreDNS is running at https://....


# -----------------------------------------------------
# Install the dashboard Helm chart.
#[user@kubernator]

    helm repo add \
        kubernetes-dashboard \
        https://kubernetes.github.io/dashboard/

    >   "kubernetes-dashboard" has been added to your repositories


    helm install \
        valeria \
        kubernetes-dashboard/kubernetes-dashboard \
        --set ingress.enabled=true

    >   NAME: valeria
    >   LAST DEPLOYED: Wed Jul 29 03:15:19 2020
    >   NAMESPACE: default
    >   STATUS: deployed
    >   REVISION: 1
    >   TEST SUITE: None
    >   NOTES:
    >   ..
    >   *** PLEASE BE PATIENT: kubernetes-dashboard may take a few minutes to install ***
    >   ..
    >   From outside the cluster, the server URL(s) are:


# -----------------------------------------------------
# Add an NGINX ingress service
#[user@kubernator]

    K8s HTTP ingress service
    https://kubernetes.io/docs/concepts/services-networking/ingress/

    K8s NGINX ingress controller
    https://kubernetes.github.io/ingress-nginx/kubectl-plugin/

    ----

    NGINX ingress controller
    https://docs.nginx.com/nginx-ingress-controller/overview/

    Install NGINX ingress iontroller using Helm
    https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-helm/#installing-via-helm-repository

    ----


    helm repo add nginx-stable https://helm.nginx.com/stable

    >   "nginx-stable" has been added to your repositories


    helm repo update

    >   Hang tight while we grab the latest from your chart repositories...
    >   ...Successfully got an update from the "nginx-stable" chart repository
    >   ...Successfully got an update from the "kubernetes-dashboard" chart repository
    >   Update Complete. ⎈ Happy Helming!⎈


    helm install \
        augusta \
        nginx-stable/nginx-ingress \
        --set extraArgs controller.enable-ssl-passthrough=""


https://github.com/helm/charts/issues/2072#issuecomment-384167453

    helm install \
        augusta \
        --set rbac.create=true \
        --set controller.stats.enabled=true \
        --set controller.service.type=NodePort \
        --set controller.service.nodePorts.http=80 \
        --set controller.service.nodePorts.https=443 \
        --set controller.service.externalTrafficPolicy=Local \
        --set controller.extraArgs.enable-ssl-passthrough="" \
        nginx-stable/nginx-ingress


    helm install \
        augusta \
        --set controller.extraArgs.enable-ssl-passthrough="" \
        nginx-stable/nginx-ingress





    >   NAME: augusta
    >   LAST DEPLOYED: Wed Jul 29 02:11:17 2020
    >   NAMESPACE: default
    >   STATUS: deployed
    >   REVISION: 1
    >   TEST SUITE: None
    >   NOTES:
    >   The NGINX Ingress Controller has been installed.


    kubectl get services

    >   NAME                    TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)                      AGE
    >   augusta-nginx-ingress   LoadBalancer   10.254.149.55    128.232.227.221   80:32390/TCP,443:31426/TCP   6m31s
    >   kubernetes              ClusterIP      10.254.0.1       <none>            443/TCP                      37h
    >   ....
    >   ....


    kubectl get service \
        augusta-nginx-ingress \
        --output json

    >   {
    >       "apiVersion": "v1",
    >       "kind": "Service",
    >       "metadata": {
    >           "annotations": {
    >               "meta.helm.sh/release-name": "augusta",
    >               "meta.helm.sh/release-namespace": "default"
    >           },
    >           "creationTimestamp": "2020-07-29T02:11:19Z",
    >           "labels": {
    >               "app.kubernetes.io/instance": "augusta",
    >               "app.kubernetes.io/managed-by": "Helm",
    >               "app.kubernetes.io/name": "augusta-nginx-ingress",
    >               "helm.sh/chart": "nginx-ingress-0.6.0"
    >           },
    >           "name": "augusta-nginx-ingress",
    >           "namespace": "default",
    >           "resourceVersion": "418508",
    >           "selfLink": "/api/v1/namespaces/default/services/augusta-nginx-ingress",
    >           "uid": "21471b75-813a-4f68-b59f-a5ce7d656812"
    >       },
    >       "spec": {
    >           "clusterIP": "10.254.149.55",
    >           "externalTrafficPolicy": "Local",
    >           "healthCheckNodePort": 31336,
    >           "ports": [
    >               {
    >                   "name": "http",
    >                   "nodePort": 32390,
    >                   "port": 80,
    >                   "protocol": "TCP",
    >                   "targetPort": 80
    >               },
    >               {
    >                   "name": "https",
    >                   "nodePort": 31426,
    >                   "port": 443,
    >                   "protocol": "TCP",
    >                   "targetPort": 443
    >               }
    >           ],
    >           "selector": {
    >               "app": "augusta-nginx-ingress"
    >           },
    >           "sessionAffinity": "None",
    >           "type": "LoadBalancer"
    >       },
    >       "status": {
    >           "loadBalancer": {
    >               "ingress": [
    >                   {
    >                       "ip": "128.232.227.221"
    >                   }
    >               ]
    >           }
    >       }
    >   }


    ----

    Zeppelin server deployment already has an NGINX proxy in it.
    We add a load balancer to the Zeppelin server deployment.

    So .. one way if doing things is to deploy an NGINX container,
    with an NGINX config file in a DataMap (as in zeppelin-server.yaml).
    Then explicitly add a LoadBalancer to connect this to external
    IP addresses.

    Abstract way of doing it is to deploy an NGINX ingress controller.
    Helm, Kubernetes and Magnum together take care of adding the
    LoadBalancer and external IP address.
    We connect Services to the ingress controller using Ingress
    resources and rules.

    If we do that, then the Zeppelin deployment becomes much simpler.


    NGINX with SSL passthrough
    https://blog.zuehlke.cloud/2019/02/setup-kubernetes-ingress-with-ssl-passthrough/


    cat << EOF > /tmp/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: ingress-augusta
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-passthrough: "true"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  rules:
  - host: aglais-001.metagrid.xyz
    http:
      paths:
      - path: /
        backend:
          serviceName: valeria-kubernetes-dashboard
          servicePort: 443
  - host: aglais-002.metagrid.xyz
    http:
      paths:
      - path: /
        backend:
          serviceName: valeria-kubernetes-dashboard
          servicePort: 443
EOF

    kubectl apply \
        --filename /tmp/ingress.yaml
















