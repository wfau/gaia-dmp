#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#

    Following suggestion from Nigel and Stelios
    Track the temp disc space available on each worker node.

    Conclusion - as far as we can tell, the nodes are not out of disc space.


# -----------------------------------------------------

    Using existing cluster, deleted Spark and Zeppelin deployments.
    TODO - document the process of deleting Spark and Zeppelin

    Installed Zeppelin
    notes/zrq/20200807-08-zeppelin-deploy.txt

# -----------------------------------------------------
# Import our resource testing note.
#[anon@zeppelin]

    experiments/zrq/zeppelin/notebooks/test-note-003.zpln


# -----------------------------------------------------
# List our deployed Pods.
#[user@zepplinator]

    kubectl get pod

    >   NAME                                                         READY   STATUS    RESTARTS   AGE
    >   augusta-20200814-ingress-nginx-controller-779bf4dbc7-vffmt   1/1     Running   0          6d9h
    >   md-frerqc                                                    1/1     Running   0          14m
    >   python-itotdt                                                1/1     Running   0          13m
    >   spark-ditrhz                                                 1/1     Running   0          3m30s
    >   valeria-20200814-kubernetes-dashboard-5f5644bc46-tbqp9       2/2     Running   0          6d9h
    >   zeppelin-b4dd1f740b65b46c-exec-1                             1/1     Running   0          3m15s
    >   zeppelin-b4dd1f740b65b46c-exec-2                             1/1     Running   0          3m15s
    >   zeppelin-b4dd1f740b65b46c-exec-3                             1/1     Running   0          3m15s
    >   zeppelin-b4dd1f740b65b46c-exec-4                             1/1     Running   0          3m15s
    >   zeppelin-server-d78dc55f9-sd6kk                              3/3     Running   0          17m


# -----------------------------------------------------
# Describe our Zeppelin server Pod.
#[user@zepplinator]

    kubectl get pod zeppelin-server-d78dc55f9-sd6kk

    >   Name:           zeppelin-server-d78dc55f9-sd6kk
    >   Namespace:      default
    >   Node:           tiberius-20200814-v7ysv35h66ur-node-5/10.0.0.203
    >   Start Time:     Thu, 20 Aug 2020 10:09:39 +0000
    >   Labels:         app.kubernetes.io/name=zeppelin-server
    >                   pod-template-hash=d78dc55f9
    >   Annotations:    <none>
    >   Status:         Running
    >   IP:             10.100.4.72
    >   Controlled By:  ReplicaSet/zeppelin-server-d78dc55f9
    >   Containers:
    >     zeppelin-server:
    >       Container ID:  docker://93f02da53f3b4d27b52b7b96b4603a3957cad0998db1293f07eeff332f6bd450
    >       Image:         aglais/zeppelin:latest
    >       Image ID:      docker-pullable://docker.io/aglais/zeppelin@sha256:e6ac6ead5a9c91f61809444a140b5d938a80bb38275bf19df0766eff703f4195
    >       Ports:         8080/TCP, 8443/TCP, 12320/TCP
    >       Host Ports:    0/TCP, 0/TCP, 0/TCP
    >       Command:
    >         sh
    >         -c
    >         $(ZEPPELIN_HOME)/bin/zeppelin.sh
    >       State:          Running
    >         Started:      Thu, 20 Aug 2020 10:09:44 +0000
    >       Ready:          True
    >       Restart Count:  0
    >       Environment Variables from:
    >         zeppelin-server-conf-map  ConfigMap  Optional: false
    >       Environment:
    >         POD_UID:    (v1:metadata.uid)
    >         POD_NAME:  zeppelin-server-d78dc55f9-sd6kk (v1:metadata.name)
    >       Mounts:
    >         /var/run/secrets/kubernetes.io/serviceaccount from zeppelin-server-token-wrf79 (ro)
    >     zeppelin-server-gateway:
    >       Container ID:  docker://4a5af65ed349f9453f02e1abc04ef30a05b93ab567fba54d5c04154e4f657160
    >       Image:         nginx:1.14.0
    >       Image ID:      docker-pullable://docker.io/nginx@sha256:8b600a4d029481cc5b459f1380b30ff6cb98e27544fc02370de836e397e34030
    >       Port:          <none>
    >       Host Port:     <none>
    >       Command:
    >         /bin/sh
    >         -c
    >       Args:
    >         cp -f /tmp/conf/nginx.conf /etc/nginx/nginx.conf; sed -i -e "s/SERVICE_DOMAIN/$SERVICE_DOMAIN/g" /etc/nginx/nginx.conf; sed -i -e "s/NAMESPACE/$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)/g" /etc/nginx/nginx.conf; cat /etc/nginx/nginx.conf; /usr/sbin/nginx
    >       State:          Running
    >         Started:      Thu, 20 Aug 2020 10:09:50 +0000
    >       Ready:          True
    >       Restart Count:  0
    >       Environment:
    >         SERVICE_DOMAIN:  <set to the key 'SERVICE_DOMAIN' of config map 'zeppelin-server-conf-map'>  Optional: false
    >       Mounts:
    >         /tmp/conf from nginx-conf (rw)
    >         /var/run/secrets/kubernetes.io/serviceaccount from zeppelin-server-token-wrf79 (ro)
    >     dnsmasq:
    >       Container ID:  docker://f531a01f05304574c9f609f8d78c60213c3e0a472856b102b4eacf5549cdb31a
    >       Image:         janeczku/go-dnsmasq:release-1.0.5
    >       Image ID:      docker-pullable://docker.io/janeczku/go-dnsmasq@sha256:56119a82f973247eda467303dabe1c04034b6ee75fb2c2534f516b3bfdf14123
    >       Port:          <none>
    >       Host Port:     <none>
    >       Args:
    >         --listen
    >         127.0.0.1:53
    >         --default-resolver
    >         --append-search-domains
    >         --hostsfile=/etc/hosts
    >         --verbose
    >       State:          Running
    >         Started:      Thu, 20 Aug 2020 10:09:53 +0000
    >       Ready:          True
    >       Restart Count:  0
    >       Environment:    <none>
    >       Mounts:
    >         /var/run/secrets/kubernetes.io/serviceaccount from zeppelin-server-token-wrf79 (ro)
    >   Conditions:
    >     Type              Status
    >     Initialized       True
    >     Ready             True
    >     ContainersReady   True
    >     PodScheduled      True
    >   Volumes:
    >     nginx-conf:
    >       Type:      ConfigMap (a volume populated by a ConfigMap)
    >       Name:      zeppelin-server-conf
    >       Optional:  false
    >     zeppelin-server-token-wrf79:
    >       Type:        Secret (a volume populated by a Secret)
    >       SecretName:  zeppelin-server-token-wrf79
    >       Optional:    false
    >   QoS Class:       BestEffort
    >   Node-Selectors:  <none>
    >   Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
    >                    node.kubernetes.io/unreachable:NoExecute for 300s
    >   Events:
    >     Type    Reason     Age   From                                            Message
    >     ----    ------     ----  ----                                            -------
    >     Normal  Scheduled  19m   default-scheduler                               Successfully assigned default/zeppelin-server-d78dc55f9-sd6kk to tiberius-20200814-v7ysv35h66ur-node-5
    >     Normal  Pulling    19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Pulling image "aglais/zeppelin:latest"
    >     Normal  Pulled     19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Successfully pulled image "aglais/zeppelin:latest"
    >     Normal  Created    19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Created container zeppelin-server
    >     Normal  Started    19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Started container zeppelin-server
    >     Normal  Pulling    19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Pulling image "nginx:1.14.0"
    >     Normal  Pulled     19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Successfully pulled image "nginx:1.14.0"
    >     Normal  Created    19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Created container zeppelin-server-gateway
    >     Normal  Started    19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Started container zeppelin-server-gateway
    >     Normal  Pulling    19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Pulling image "janeczku/go-dnsmasq:release-1.0.5"
    >     Normal  Pulled     19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Successfully pulled image "janeczku/go-dnsmasq:release-1.0.5"
    >     Normal  Created    19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Created container dnsmasq
    >     Normal  Started    19m   kubelet, tiberius-20200814-v7ysv35h66ur-node-5  Started container dnsmasq


# -----------------------------------------------------
# Describe our Spark driver (Zeppelin interpreter) Pod.
#[user@zepplinator]

    kubectl describe pod spark-ditrhz

    >   Name:         spark-ditrhz
    >   Namespace:    default
    >   Node:         tiberius-20200814-v7ysv35h66ur-node-3/10.0.0.47
    >   Start Time:   Thu, 20 Aug 2020 10:23:54 +0000
    >   Labels:       app=spark-ditrhz
    >                 interpreterGroupId=spark-shared_process
    >                 interpreterSettingName=spark
    >   Annotations:  <none>
    >   Status:       Running
    >   IP:           10.100.5.97
    >   Init Containers:
    >     spark-home-init:
    >       Container ID:  docker://ffe8c399e2aeb81e9725e24d80c0b227f7f67aef0c6a6723c06e21bcaca61d1d
    >       Image:         aglais/pyspark-mod:latest
    >       Image ID:      docker-pullable://docker.io/aglais/pyspark-mod@sha256:cf55a2fd0b60a0bcb5de4b6cf1b03db2cf66e5c62ae44c6b93c16e6bda506093
    >       Port:          <none>
    >       Host Port:     <none>
    >       Command:
    >         sh
    >         -c
    >         cp -r /opt/spark/* /spark/
    >       State:          Terminated
    >         Reason:       Completed
    >         Exit Code:    0
    >         Started:      Thu, 20 Aug 2020 10:23:59 +0000
    >         Finished:     Thu, 20 Aug 2020 10:23:59 +0000
    >       Ready:          True
    >       Restart Count:  0
    >       Environment:    <none>
    >       Mounts:
    >         /spark from spark-home (rw)
    >         /var/run/secrets/kubernetes.io/serviceaccount from default-token-kwn72 (ro)
    >   Containers:
    >     spark:
    >       Container ID:  docker://0e7a3d918629f114185fd174b18899096c000db52b1c567bb95bf9beacbc2901
    >       Image:         aglais/zeppelin:latest
    >       Image ID:      docker-pullable://docker.io/aglais/zeppelin@sha256:e6ac6ead5a9c91f61809444a140b5d938a80bb38275bf19df0766eff703f4195
    >       Port:          <none>
    >       Host Port:     <none>
    >       Command:
    >         sh
    >         -c
    >         $(ZEPPELIN_HOME)/bin/interpreter.sh -d $(ZEPPELIN_HOME)/interpreter/spark -r 12321:12321 -c zeppelin-server.default.svc -p 12320 -i spark-shared_process -l /tmp/local-repo -g spark
    >       State:          Running
    >         Started:      Thu, 20 Aug 2020 10:24:03 +0000
    >       Ready:          True
    >       Restart Count:  0
    >       Limits:
    >         cpu:  4
    >       Requests:
    >         cpu:     4
    >         memory:  4505Mi
    >       Environment:
    >         PYSPARK_PYTHON:         python2
    >         ZEPPELIN_HOME:          /zeppelin
    >         SPARK_SUBMIT_OPTIONS:   --master k8s://https://kubernetes.default.svc --deploy-mode client --driver-memory 4g --conf spark.kubernetes.namespace=default --conf spark.executor.instances=1 --conf spark.kubernetes.driver.pod.name=spark-ditrhz --conf spark.kubernetes.container.image=aglais/pyspark-mod:latest --conf spark.driver.bindAddress=0.0.0.0 --conf spark.driver.host=spark-ditrhz.default.svc --conf spark.driver.port=22321 --conf spark.blockManager.port=22322
    >         SPARK_HOME:             /spark
    >         PYSPARK_DRIVER_PYTHON:  python
    >         SERVICE_DOMAIN:         local.zeppelin-project.org:8080
    >         INTERPRETER_GROUP_ID:   spark-shared_process
    >       Mounts:
    >         /spark from spark-home (rw)
    >         /var/run/secrets/kubernetes.io/serviceaccount from default-token-kwn72 (ro)
    >   Conditions:
    >     Type              Status
    >     Initialized       True
    >     Ready             True
    >     ContainersReady   True
    >     PodScheduled      True
    >   Volumes:
    >     spark-home:
    >       Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    >       Medium:
    >       SizeLimit:  <unset>
    >     default-token-kwn72:
    >       Type:        Secret (a volume populated by a Secret)
    >       SecretName:  default-token-kwn72
    >       Optional:    false
    >   QoS Class:       Burstable
    >   Node-Selectors:  <none>
    >   Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
    >                    node.kubernetes.io/unreachable:NoExecute for 300s
    >   Events:
    >     Type    Reason     Age    From                                            Message
    >     ----    ------     ----   ----                                            -------
    >     Normal  Scheduled  8m14s  default-scheduler                               Successfully assigned default/spark-ditrhz to tiberius-20200814-v7ysv35h66ur-node-3
    >     Normal  Pulling    8m12s  kubelet, tiberius-20200814-v7ysv35h66ur-node-3  Pulling image "aglais/pyspark-mod:latest"
    >     Normal  Pulled     8m9s   kubelet, tiberius-20200814-v7ysv35h66ur-node-3  Successfully pulled image "aglais/pyspark-mod:latest"
    >     Normal  Created    8m9s   kubelet, tiberius-20200814-v7ysv35h66ur-node-3  Created container spark-home-init
    >     Normal  Started    8m9s   kubelet, tiberius-20200814-v7ysv35h66ur-node-3  Started container spark-home-init
    >     Normal  Pulling    8m8s   kubelet, tiberius-20200814-v7ysv35h66ur-node-3  Pulling image "aglais/zeppelin:latest"
    >     Normal  Pulled     8m5s   kubelet, tiberius-20200814-v7ysv35h66ur-node-3  Successfully pulled image "aglais/zeppelin:latest"
    >     Normal  Created    8m5s   kubelet, tiberius-20200814-v7ysv35h66ur-node-3  Created container spark
    >     Normal  Started    8m5s   kubelet, tiberius-20200814-v7ysv35h66ur-node-3  Started container spark


    #
    # EmptyDir volume mounted as /spark
    # SizeLimit:  <unset>
    #


# -----------------------------------------------------
# Describe one of our Spark executor Pods.
#[user@zepplinator]

    kubectl describe pod zeppelin-b4dd1f740b65b46c-exec-1

    >   Name:           zeppelin-b4dd1f740b65b46c-exec-1
    >   Namespace:      default
    >   Node:           tiberius-20200814-v7ysv35h66ur-node-1/10.0.0.184
    >   Start Time:     Thu, 20 Aug 2020 10:24:09 +0000
    >   Labels:         spark-app-selector=spark-application-1597919049519
    >                   spark-exec-id=1
    >                   spark-role=executor
    >   Annotations:    <none>
    >   Status:         Running
    >   IP:             10.100.2.74
    >   Controlled By:  Pod/spark-ditrhz
    >   Containers:
    >     spark-kubernetes-executor:
    >       Container ID:  docker://65d3caae33254b2ea80df620fa4f14015f65e09e7e39af555b12c596bed87b55
    >       Image:         aglais/pyspark-mod:latest
    >       Image ID:      docker-pullable://docker.io/aglais/pyspark-mod@sha256:cf55a2fd0b60a0bcb5de4b6cf1b03db2cf66e5c62ae44c6b93c16e6bda506093
    >       Port:          7079/TCP
    >       Host Port:     0/TCP
    >       Args:
    >         executor
    >       State:          Running
    >         Started:      Thu, 20 Aug 2020 10:24:11 +0000
    >       Ready:          True
    >       Restart Count:  0
    >       Limits:
    >         memory:  4505Mi
    >       Requests:
    >         cpu:     4
    >         memory:  4505Mi
    >       Environment:
    >         SPARK_USER:             zeppelin
    >         SPARK_DRIVER_URL:       spark://CoarseGrainedScheduler@spark-ditrhz.default.svc:22321
    >         SPARK_EXECUTOR_CORES:   4
    >         SPARK_EXECUTOR_MEMORY:  4g
    >         SPARK_APPLICATION_ID:   spark-application-1597919049519
    >         SPARK_CONF_DIR:         /opt/spark/conf
    >         SPARK_EXECUTOR_ID:      1
    >         SPARK_EXECUTOR_POD_IP:   (v1:status.podIP)
    >         SPARK_JAVA_OPT_0:       -Dspark.blockManager.port=22322
    >         SPARK_JAVA_OPT_1:       -Dspark.driver.port=22321
    >         SPARK_LOCAL_DIRS:       /var/data/spark-20aea843-55dc-46be-a064-3ef86a15b55b
    >       Mounts:
    >         /var/data/spark-20aea843-55dc-46be-a064-3ef86a15b55b from spark-local-dir-1 (rw)
    >         /var/run/secrets/kubernetes.io/serviceaccount from default-token-kwn72 (ro)
    >   Conditions:
    >     Type              Status
    >     Initialized       True
    >     Ready             True
    >     ContainersReady   True
    >     PodScheduled      True
    >   Volumes:
    >     spark-local-dir-1:
    >       Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    >       Medium:
    >       SizeLimit:  <unset>
    >     default-token-kwn72:
    >       Type:        Secret (a volume populated by a Secret)
    >       SecretName:  default-token-kwn72
    >       Optional:    false
    >   QoS Class:       Burstable
    >   Node-Selectors:  <none>
    >   Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
    >                    node.kubernetes.io/unreachable:NoExecute for 300s
    >   Events:
    >     Type    Reason     Age   From                                            Message
    >     ----    ------     ----  ----                                            -------
    >     Normal  Scheduled  12m   default-scheduler                               Successfully assigned default/zeppelin-b4dd1f740b65b46c-exec-1 to tiberius-20200814-v7ysv35h66ur-node-1
    >     Normal  Pulled     12m   kubelet, tiberius-20200814-v7ysv35h66ur-node-1  Container image "aglais/pyspark-mod:latest" already present on machine
    >     Normal  Created    12m   kubelet, tiberius-20200814-v7ysv35h66ur-node-1  Created container spark-kubernetes-executor
    >     Normal  Started    12m   kubelet, tiberius-20200814-v7ysv35h66ur-node-1  Started container spark-kubernetes-executor


    #
    # EmptyDir volume mounted as /var/data/spark-20aea843-55dc-46be-a064-3ef86a15b55b
    # Environment variable SPARK_LOCAL_DIRS ponts to the EmptyDir volume
    # SizeLimit:  <unset>
    #


# -----------------------------------------------------
# Login to the Spark executor Pod and check the disc space.
#[user@zepplinator]

    kubectl exec \
        --tty \
        --stdin \
        zeppelin-b4dd1f740b65b46c-exec-1 \
        -- \
            /bin/bash


# -----------------------------------------------------
# Poke around to find what we have.
#[user@exec-pod]

    pwd

    >   /opt/spark/work-dir

    #
    # While I was exploring the Pod terminated.
    #


# -----------------------------------------------------
# Check the Spark executor Pod logs.
#[user@zepplinator]

    kubectl logs  zeppelin-b4dd1f740b65b46c-exec-1

    >   ++ id -u
    >   + myuid=185
    >   ++ id -g
    >   + mygid=0
    >   + set +e
    >   ++ getent passwd 185
    >   + uidentry=
    >   + set -e
    >   + '[' -z '' ']'
    >   + '[' -w /etc/passwd ']'
    >   + echo '185:x:185:0:anonymous uid:/opt/spark:/bin/false'
    >   + SPARK_CLASSPATH=':/opt/spark/jars/*'
    >   + env
    >   + grep SPARK_JAVA_OPT_
    >   + sort -t_ -k4 -n
    >   + sed 's/[^=]*=\(.*\)/\1/g'
    >   + readarray -t SPARK_EXECUTOR_JAVA_OPTS
    >   + '[' -n '' ']'
    >   + '[' '' == 2 ']'
    >   + '[' '' == 3 ']'
    >   + '[' -n '' ']'
    >   + '[' -z ']'
    >   + case "$1" in
    >   + shift 1
    >   + CMD=(${JAVA_HOME}/bin/java "${SPARK_EXECUTOR_JAVA_OPTS[@]}" -Xms$SPARK_EXECUTOR_MEMORY -Xmx$SPARK_EXECUTOR_MEMORY -cp "$SPARK_CLASSPATH:$SPARK_DIST_CLASSPATH" org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url $SPARK_DRIVER_URL --executor-id $SPARK_EXECUTOR_ID --cores $SPARK_EXECUTOR_CORES --app-id $SPARK_APPLICATION_ID --hostname $SPARK_EXECUTOR_POD_IP)
    >   + exec /usr/bin/tini -s -- /usr/local/openjdk-8/bin/java -Dspark.blockManager.port=22322 -Dspark.driver.port=22321 -Xms4g -Xmx4g -cp ':/opt/spark/jars/*:' org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@spark-ditrhz.default.svc:22321 --executor-id 1 --cores 4 --app-id spark-application-1597919049519 --hostname 10.100.2.74
    >   Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
    >   20/08/20 10:24:12 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 15@zeppelin-b4dd1f740b65b46c-exec-1
    >   20/08/20 10:24:12 INFO SignalUtils: Registered signal handler for TERM
    >   20/08/20 10:24:12 INFO SignalUtils: Registered signal handler for HUP
    >   20/08/20 10:24:12 INFO SignalUtils: Registered signal handler for INT
    >   ....
    >   ....

    >   ....
    >   20/08/20 10:24:13 INFO SecurityManager: Changing view acls to: 185,zeppelin
    >   20/08/20 10:24:13 INFO SecurityManager: Changing modify acls to: 185,zeppelin
    >   20/08/20 10:24:13 INFO SecurityManager: Changing view acls groups to:
    >   20/08/20 10:24:13 INFO SecurityManager: Changing modify acls groups to:
    >   20/08/20 10:24:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(185, zeppelin); groups with view permissions: Set(); users  with modify permissions: Set(185, zeppelin); groups with modify permissions: Set()
    >   ....


    >   ....
    >   20/08/20 10:24:13 INFO DiskBlockManager: Created local directory at /var/data/spark-20aea843-55dc-46be-a064-3ef86a15b55b/blockmgr-95b95a42-3bcc-40d2-9ff5-bd5762397eb9
    >   20/08/20 10:24:13 INFO MemoryStore: MemoryStore started with capacity 2.1 GiB
    >   ....


    >   ....
    >   20/08/20 10:24:13 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@spark-ditrhz.default.svc:22321
    >   20/08/20 10:24:13 INFO ResourceUtils: ==============================================================
    >   20/08/20 10:24:13 INFO ResourceUtils: Resources for spark.executor:
    >   20/08/20 10:24:13 INFO ResourceUtils: ==============================================================
    >   20/08/20 10:24:13 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
    >   20/08/20 10:24:13 INFO Executor: Starting executor ID 1 on host 10.100.2.74
    >   20/08/20 10:24:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 22322.
    >   20/08/20 10:24:13 INFO NettyBlockTransferService: Server created on 10.100.2.74:22322
    >   ....


    >   ....
    >   20/08/20 10:24:25 INFO CoarseGrainedExecutorBackend: Got assigned task 3
    >   20/08/20 10:24:25 INFO CoarseGrainedExecutorBackend: Got assigned task 7
    >   20/08/20 10:24:25 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
    >   20/08/20 10:24:25 INFO CoarseGrainedExecutorBackend: Got assigned task 11
    >   20/08/20 10:24:25 INFO CoarseGrainedExecutorBackend: Got assigned task 15
    >   20/08/20 10:24:25 INFO Executor: Running task 10.0 in stage 1.0 (TID 11)
    >   20/08/20 10:24:25 INFO Executor: Running task 6.0 in stage 1.0 (TID 7)
    >   20/08/20 10:24:25 INFO Executor: Running task 14.0 in stage 1.0 (TID 15)
    >   20/08/20 10:24:25 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
    >   20/08/20 10:24:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 2.1 GiB)
    >   20/08/20 10:24:25 INFO TorrentBroadcast: Reading broadcast variable 2 took 12 ms
    >   20/08/20 10:24:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.6 KiB, free 2.1 GiB)
    >   20/08/20 10:24:25 INFO CodeGenerator: Code generated in 206.938435 ms
    >   20/08/20 10:24:25 INFO FileScanRDD: Reading File path: s3a://albert/part-00003-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet, range: 0-11218725, partition values: [empty row]
    >   20/08/20 10:24:25 INFO FileScanRDD: Reading File path: s3a://albert/part-00003-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet, range: 89749800-96996784, partition values: [empty row]
    >   20/08/20 10:24:25 INFO FileScanRDD: Reading File path: s3a://albert/part-00003-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet, range: 44874900-56093625, partition values: [empty row]
    >   20/08/20 10:24:25 INFO FileScanRDD: Reading File path: s3a://albert/part-00000-70392076-8b82-4457-8828-22069e7626e9-c000.snappy.parquet, range: 22437450-33656175, partition values: [empty row]
    >   20/08/20 10:24:25 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
    >   20/08/20 10:24:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 2.1 GiB)
    >   20/08/20 10:24:25 INFO TorrentBroadcast: Reading broadcast variable 1 took 34 ms
    >   20/08/20 10:24:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 441.7 KiB, free 2.1 GiB)
    >   20/08/20 10:24:25 INFO S3AInputStream: Switching to Random IO seek policy
    >   20/08/20 10:24:25 INFO S3AInputStream: Switching to Random IO seek policy
    >   20/08/20 10:24:26 INFO S3AInputStream: Switching to Random IO seek policy
    >   20/08/20 10:24:26 INFO S3AInputStream: Switching to Random IO seek policy
    >   20/08/20 10:24:26 INFO S3AInputStream: Switching to Random IO seek policy
    >   20/08/20 10:24:26 INFO S3AInputStream: Switching to Random IO seek policy
    >   20/08/20 10:24:26 INFO S3AInputStream: Switching to Random IO seek policy
    >   20/08/20 10:24:26 INFO S3AInputStream: Switching to Random IO seek policy
    >   20/08/20 10:24:26 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2130 bytes result sent to driver
    >   20/08/20 10:24:26 INFO Executor: Finished task 14.0 in stage 1.0 (TID 15). 2130 bytes result sent to driver
    >   20/08/20 10:24:26 INFO Executor: Finished task 6.0 in stage 1.0 (TID 7). 2130 bytes result sent to driver
    >   20/08/20 10:24:26 INFO Executor: Finished task 10.0 in stage 1.0 (TID 11). 2173 bytes result sent to driver
    >   ....


    >   ....
    >   20/08/20 10:24:39 INFO Executor: Running task 0.0 in stage 11.0 (TID 1332)
    >   20/08/20 10:24:39 INFO MapOutputTrackerWorker: Updating epoch to 4 and clearing cache
    >   20/08/20 10:24:39 INFO TorrentBroadcast: Started reading broadcast variable 18 with 1 pieces (estimated total size 4.0 MiB)
    >   20/08/20 10:24:39 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.1 GiB)
    >   20/08/20 10:24:39 INFO TorrentBroadcast: Reading broadcast variable 18 took 6 ms
    >   20/08/20 10:24:39 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 10.1 KiB, free 2.1 GiB)
    >   20/08/20 10:24:39 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 3, fetching them
    >   20/08/20 10:24:39 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@spark-ditrhz.default.svc:22321)
    >   20/08/20 10:24:39 INFO MapOutputTrackerWorker: Got the output locations
    >   20/08/20 10:24:39 INFO ShuffleBlockFetcherIterator: Getting 749 (43.9 KiB) non-empty blocks including 182 (10.7 KiB) local and 0 (0.0 B) host-local and 567 (33.2 KiB) remote blocks
    >   20/08/20 10:24:39 INFO ShuffleBlockFetcherIterator: Started 3 remote fetches in 7 ms
    >   20/08/20 10:24:39 INFO Executor: Finished task 0.0 in stage 11.0 (TID 1332). 2648 bytes result sent to driver
    >   ....


    >   ....
    >   20/08/20 10:30:34 WARN Executor: Issue communicating with driver in heartbeater
    >   org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
    >   	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
    >   	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
    >   	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
    >   ....
    >   Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
    >   	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
    >   	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
    >   	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:294)
    >   	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
    >   ....


    >   ....
    >   20/08/20 10:38:24 WARN Executor: Issue communicating with driver in heartbeater
    >   org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
    >   	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
    >   	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
    >   	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
    >   ....


    >   ....
    >   20/08/20 10:38:34 WARN TransportResponseHandler: Ignoring response for RPC 6873184931891603994 from spark-ditrhz.default.svc/10.100.5.97:22321 (81 bytes) since it is not outstanding
    >   20/08/20 10:38:34 WARN TransportResponseHandler: Ignoring response for RPC 8016983420409251214 from spark-ditrhz.default.svc/10.100.5.97:22321 (81 bytes) since it is not outstanding
    >   20/08/20 10:38:34 WARN TransportResponseHandler: Ignoring response for RPC 8480176520859937206 from spark-ditrhz.default.svc/10.100.5.97:22321 (81 bytes) since it is not outstanding
    >   20/08/20 10:38:34 WARN TransportResponseHandler: Ignoring response for RPC 7308192848812569616 from spark-ditrhz.default.svc/10.100.5.97:22321 (81 bytes) since it is not outstanding
    >   20/08/20 10:38:34 WARN TransportResponseHandler: Ignoring response for RPC 6160800272303480055 from spark-ditrhz.default.svc/10.100.5.97:22321 (81 bytes) since it is not outstanding
    >   ....


    >   ....
    >   20/08/20 10:50:04 WARN Executor: Issue communicating with driver in heartbeater
    >   org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
    >   	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
    >   	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
    >   	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
    >   ....


    >   ....
    >   20/08/20 10:50:14 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times
    >   20/08/20 10:50:24 INFO MemoryStore: MemoryStore cleared
    >   20/08/20 10:50:24 INFO BlockManager: BlockManager stopped
    >   20/08/20 10:50:24 INFO ShutdownHookManager: Shutdown hook called
    >   20/08/20 10:50:24 INFO ShutdownHookManager: Deleting directory /var/data/spark-20aea843-55dc-46be-a064-3ef86a15b55b/spark-a6cd4a5b-41f5-4c80-af6e-198e987c1a38
    >   20/08/20 10:50:24 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
    >   20/08/20 10:50:24 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
    >   20/08/20 10:50:24 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.

    #
    # Main task run smoothly .. until the driver stops responding.
    # Repeated hearbeat attepmts timeout.
    # Driver eventually responds, long after the client has timed out.
    # Driver responses discarded because the client timed out.
    # Executor gives up after 60 failed heartbeat requests.
    #


# -----------------------------------------------------
# Check the Spark driver (Zeppelin interpreter) Pod logs.
#[user@zepplinator]

    kubectl logs spark-ditrhz


    >   Interpreter launch command:  /spark/bin/spark-submit --class org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer --driver-class-path ":/zeppelin/interpreter/spark/*::/zeppelin/interpreter/zeppelin-interpreter-shaded-0.9.0-SNAPSHOT.jar:/zeppelin/interpreter/spark/spark-interpreter-0.9.0-SNAPSHOT.jar" --driver-java-options " -Dfile.encoding=UTF-8 -Dlog4j.configuration='file:///zeppelin/conf/log4j.properties' -Dlog4j.configurationFile='file:///zeppelin/conf/log4j2.properties' -Dzeppelin.log.file='/zeppelin/logs/zeppelin-interpreter-spark-shared_process--spark-ditrhz.log'" --master k8s://https://kubernetes.default.svc --deploy-mode client --driver-memory 4g --conf spark.kubernetes.namespace=default --conf spark.executor.instances=1 --conf spark.kubernetes.driver.pod.name=spark-ditrhz --conf spark.kubernetes.container.image=aglais/pyspark-mod:latest --conf spark.driver.bindAddress=0.0.0.0 --conf spark.driver.host=spark-ditrhz.default.svc --conf spark.driver.port=22321 --conf spark.blockManager.port=22322 /zeppelin/interpreter/spark/spark-interpreter-0.9.0-SNAPSHOT.jar zeppelin-server.default.svc 12320 "spark-shared_process" 12321:12321
    >   SLF4J: Class path contains multiple SLF4J bindings.
    >   SLF4J: Found binding in [jar:file:/zeppelin/interpreter/spark/spark-interpreter-0.9.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class]
    >   SLF4J: Found binding in [jar:file:/spark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
    >   SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
    >   SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
    >   ....
    >   ....


    >   ....
    >    INFO [2020-08-20 10:24:07,820] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - Running Spark version 3.0.0
    >    INFO [2020-08-20 10:24:07,858] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - ==============================================================
    >    INFO [2020-08-20 10:24:07,859] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - Resources for spark.driver:
    >    INFO [2020-08-20 10:24:07,859] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - ==============================================================
    >    INFO [2020-08-20 10:24:07,860] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - Submitted application: Zeppelin
    >    INFO [2020-08-20 10:24:07,911] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - Changing view acls to: zeppelin
    >    INFO [2020-08-20 10:24:07,912] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - Changing modify acls to: zeppelin
    >    INFO [2020-08-20 10:24:07,912] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - Changing view acls groups to:
    >    INFO [2020-08-20 10:24:07,912] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - Changing modify acls groups to:
    >    INFO [2020-08-20 10:24:07,912] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(zeppelin); groups with view permissions: Set(); users  with modify permissions: Set(zeppelin); groups with modify permissions: Set()
    >    INFO [2020-08-20 10:24:08,382] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - Successfully started service 'sparkDriver' on port 22321.
    >   ....


    >   ....
    >    INFO [2020-08-20 10:24:08,819] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - Auto-configuring K8S client using current context from users K8S config file
    >    WARN [2020-08-20 10:24:09,526] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logWarning]:69) - Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.
    >    INFO [2020-08-20 10:24:09,529] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - Created default pool: default, schedulingMode: FIFO, minShare: 0, weight: 1
    >    INFO [2020-08-20 10:24:09,565] ({kubernetes-executor-snapshots-subscribers-1} Logging.scala[logInfo]:57) - Going to request 4 executors from Kubernetes.
    >   ....


    >   ....
    >    INFO [2020-08-20 10:24:13,523] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.100.3.61:51022) with ID 2
    >    INFO [2020-08-20 10:24:13,627] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Registering block manager 10.100.3.61:22322 with 2.1 GiB RAM, BlockManagerId(2, 10.100.3.61, 22322, None)
    >    INFO [2020-08-20 10:24:13,908] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.100.2.74:33562) with ID 1
    >    INFO [2020-08-20 10:24:13,979] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.100.6.68:45422) with ID 3
    >    INFO [2020-08-20 10:24:14,009] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Registering block manager 10.100.2.74:22322 with 2.1 GiB RAM, BlockManagerId(1, 10.100.2.74, 22322, None)
    >    INFO [2020-08-20 10:24:14,081] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Registering block manager 10.100.6.68:22322 with 2.1 GiB RAM, BlockManagerId(3, 10.100.6.68, 22322, None)
    >    INFO [2020-08-20 10:24:14,199] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.100.4.75:38838) with ID 4
    >    INFO [2020-08-20 10:24:14,244] ({FIFOScheduler-interpreter_1486023039-Worker-1} Logging.scala[logInfo]:57) - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
    >    INFO [2020-08-20 10:24:14,299] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Registering block manager 10.100.4.75:22322 with 2.1 GiB RAM, BlockManagerId(4, 10.100.4.75, 22322, None)
    >   ....


    >   ....
    >    INFO [2020-08-20 10:24:25,183] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Adding task set 1.0 with 16 tasks
    >    INFO [2020-08-20 10:24:25,184] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Added task set TaskSet_1.0 tasks to pool default
    >   ....


    >   ....
    >    INFO [2020-08-20 10:24:25,188] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Starting task 0.0 in stage 1.0 (TID 1, 10.100.4.75, executor 4, partition 0, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2020-08-20 10:24:25,188] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Starting task 1.0 in stage 1.0 (TID 2, 10.100.3.61, executor 2, partition 1, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2020-08-20 10:24:25,188] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Starting task 2.0 in stage 1.0 (TID 3, 10.100.2.74, executor 1, partition 2, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2020-08-20 10:24:25,189] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Starting task 3.0 in stage 1.0 (TID 4, 10.100.6.68, executor 3, partition 3, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2020-08-20 10:24:25,189] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Starting task 4.0 in stage 1.0 (TID 5, 10.100.4.75, executor 4, partition 4, PROCESS_LOCAL, 7778 bytes)
    >   ....


    >   ....
    >    INFO [2020-08-20 10:24:26,127] ({task-result-getter-2} Logging.scala[logInfo]:57) - Finished task 14.0 in stage 1.0 (TID 15) in 935 ms on 10.100.2.74 (executor 1) (1/16)
    >    INFO [2020-08-20 10:24:26,128] ({task-result-getter-1} Logging.scala[logInfo]:57) - Finished task 2.0 in stage 1.0 (TID 3) in 940 ms on 10.100.2.74 (executor 1) (2/16)
    >    INFO [2020-08-20 10:24:26,129] ({task-result-getter-3} Logging.scala[logInfo]:57) - Finished task 6.0 in stage 1.0 (TID 7) in 940 ms on 10.100.2.74 (executor 1) (3/16)
    >    INFO [2020-08-20 10:24:26,132] ({task-result-getter-0} Logging.scala[logInfo]:57) - Finished task 10.0 in stage 1.0 (TID 11) in 942 ms on 10.100.2.74 (executor 1) (4/16)
    >   ....

    >   ....
    >    INFO [2020-08-20 10:24:30,371] ({task-result-getter-1} Logging.scala[logInfo]:57) - Finished task 7.0 in stage 1.0 (TID 8) in 5181 ms on 10.100.6.68 (executor 3) (15/16)
    >    INFO [2020-08-20 10:24:30,371] ({task-result-getter-0} Logging.scala[logInfo]:57) - Finished task 3.0 in stage 1.0 (TID 4) in 5182 ms on 10.100.6.68 (executor 3) (16/16)
    >    INFO [2020-08-20 10:24:30,371] ({task-result-getter-0} Logging.scala[logInfo]:57) - Removed TaskSet 1.0, whose tasks have all completed, from pool default
    >    INFO [2020-08-20 10:24:30,372] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 5.217 s
    >   ....


    >   ....
    >    INFO [2020-08-20 10:24:39,365] ({Thread-23} Logging.scala[logInfo]:57) - Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 3.412794 s
    >    INFO [2020-08-20 10:24:39,376] ({Thread-23} Logging.scala[logInfo]:57) - Pruning directories with:
    >    INFO [2020-08-20 10:24:39,377] ({Thread-23} Logging.scala[logInfo]:57) - Pushed Filters:
    >    INFO [2020-08-20 10:24:39,377] ({Thread-23} Logging.scala[logInfo]:57) - Post-Scan Filters:
    >    INFO [2020-08-20 10:24:39,378] ({Thread-23} Logging.scala[logInfo]:57) - Output Data Schema: struct<solution_id: bigint, designation: string, source_id: bigint, random_index: bigint, ref_epoch: double ... 92 more fields>
    >    INFO [2020-08-20 10:24:39,392] ({Thread-23} Logging.scala[logInfo]:57) - Block broadcast_19 stored as values in memory (estimated size 350.7 KiB, free 2002.3 MiB)
    >    INFO [2020-08-20 10:24:39,400] ({Thread-23} Logging.scala[logInfo]:57) - Block broadcast_19_piece0 stored as bytes in memory (estimated size 32.4 KiB, free 2002.2 MiB)
    >    INFO [2020-08-20 10:24:39,400] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Added broadcast_19_piece0 in memory on spark-ditrhz.default.svc:22322 (size: 32.4 KiB, free: 2004.4 MiB)
    >    INFO [2020-08-20 10:24:39,401] ({Thread-23} Logging.scala[logInfo]:57) - Created broadcast 19 from javaToPython at NativeMethodAccessorImpl.java:0
    >    INFO [2020-08-20 10:24:39,402] ({Thread-23} Logging.scala[logInfo]:57) - Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
    >    INFO [2020-08-20 10:24:39,415] ({FIFOScheduler-interpreter_1486023039-Worker-1} AbstractScheduler.java[runJob]:152) - Job paragraph_1597413659420_1753327719 finished by scheduler interpreter_1486023039
    >    INFO [2020-08-20 10:24:39,479] ({FIFOScheduler-interpreter_1486023039-Worker-1} AbstractScheduler.java[runJob]:125) - Job paragraph_1597413672091_148192074 started by scheduler interpreter_1486023039
    >   ....


    >   ....
    >    INFO [2020-08-20 10:24:41,127] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removed broadcast_9_piece0 on spark-ditrhz.default.svc:22322 in memory (size: 32.4 KiB, free: 2004.4 MiB)
    >    INFO [2020-08-20 10:24:41,132] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removed broadcast_11_piece0 on spark-ditrhz.default.svc:22322 in memory (size: 29.5 KiB, free: 2004.4 MiB)
    >    INFO [2020-08-20 10:24:41,133] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removed broadcast_11_piece0 on 10.100.2.74:22322 in memory (size: 29.5 KiB, free: 2.1 GiB)
    >    INFO [2020-08-20 10:24:41,133] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removed broadcast_11_piece0 on 10.100.6.68:22322 in memory (size: 29.5 KiB, free: 2.1 GiB)
    >    INFO [2020-08-20 10:24:41,133] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removed broadcast_11_piece0 on 10.100.4.75:22322 in memory (size: 29.5 KiB, free: 2.1 GiB)
    >    INFO [2020-08-20 10:24:41,134] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removed broadcast_11_piece0 on 10.100.3.61:22322 in memory (size: 29.5 KiB, free: 2.1 GiB)
    >   ....


    >   ....
    >    INFO [2020-08-20 10:24:41,182] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removed broadcast_15_piece0 on spark-ditrhz.default.svc:22322 in memory (size: 31.1 KiB, free: 2004.6 MiB)
    >    INFO [2020-08-20 10:24:41,182] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removed broadcast_15_piece0 on 10.100.2.74:22322 in memory (size: 31.1 KiB, free: 2.1 GiB)
    >    INFO [2020-08-20 10:24:41,186] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removed broadcast_13_piece0 on spark-ditrhz.default.svc:22322 in memory (size: 5.0 KiB, free: 2004.6 MiB)
    >    INFO [2020-08-20 10:24:41,186] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removed broadcast_13_piece0 on 10.100.6.68:22322 in memory (size: 5.0 KiB, free: 2.1 GiB)
    >   ....


    >   ....
    >    INFO [2020-08-20 10:38:19,143] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) - Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@33d9e393)) by listener AppStatusListener took 14.583941315s.
    >    WARN [2020-08-20 10:38:24,653] ({dispatcher-event-loop-2} Logging.scala[logWarning]:69) - Removing executor 2 with no recent heartbeats: 411295 ms exceeds timeout 120000 ms
    >    WARN [2020-08-20 10:38:29,551] ({dispatcher-event-loop-2} Logging.scala[logWarning]:69) - Removing executor 4 with no recent heartbeats: 357703 ms exceeds timeout 120000 ms
    >    WARN [2020-08-20 10:38:29,551] ({dispatcher-event-loop-2} Logging.scala[logWarning]:69) - Removing executor 3 with no recent heartbeats: 396711 ms exceeds timeout 120000 ms
    >    INFO [2020-08-20 10:38:29,552] ({kill-executor-thread} Logging.scala[logInfo]:57) - Requesting to kill executor(s) 2
    >    INFO [2020-08-20 10:38:34,598] ({kill-executor-thread} Logging.scala[logInfo]:57) - Actual list of executor(s) to be killed is 2
    >    INFO [2020-08-20 10:38:41,296] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Executor 2 on 10.100.3.61 killed by driver.
    >    INFO [2020-08-20 10:38:41,297] ({kill-executor-thread} Logging.scala[logInfo]:57) - Requesting to kill executor(s) 4
    >    INFO [2020-08-20 10:38:41,299] ({kill-executor-thread} Logging.scala[logInfo]:57) - Actual list of executor(s) to be killed is 4
    >    INFO [2020-08-20 10:38:41,299] ({kill-executor-thread} Logging.scala[logInfo]:57) - Requesting to kill executor(s) 3
    >    INFO [2020-08-20 10:38:41,299] ({kill-executor-thread} Logging.scala[logInfo]:57) - Actual list of executor(s) to be killed is 3
    >    INFO [2020-08-20 10:38:41,300] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Executor lost: 2 (epoch 4)
    >    INFO [2020-08-20 10:38:41,301] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Removal of executor 2 requested
    >    INFO [2020-08-20 10:38:41,301] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Trying to remove executor 2 from BlockManagerMaster.
    >    INFO [2020-08-20 10:38:41,302] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Asked to remove non-existent executor 2
    >    INFO [2020-08-20 10:38:41,302] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Executor 4 on 10.100.4.75 killed by driver.
    >    INFO [2020-08-20 10:38:41,302] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Removal of executor 4 requested
    >    INFO [2020-08-20 10:38:41,302] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Asked to remove non-existent executor 4
    >    INFO [2020-08-20 10:38:41,302] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Executor 3 on 10.100.6.68 killed by driver.
    >    INFO [2020-08-20 10:38:41,302] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Removal of executor 3 requested
    >    INFO [2020-08-20 10:38:41,302] ({dispatcher-CoarseGrainedScheduler} Logging.scala[logInfo]:57) - Asked to remove non-existent executor 3
    >    INFO [2020-08-20 10:38:41,302] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removing block manager BlockManagerId(2, 10.100.3.61, 22322, None)
    >    INFO [2020-08-20 10:38:41,303] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Trying to remove executor 2 from BlockManagerMaster.
    >    INFO [2020-08-20 10:38:41,303] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Trying to remove executor 4 from BlockManagerMaster.
    >    INFO [2020-08-20 10:38:41,303] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removing block manager BlockManagerId(4, 10.100.4.75, 22322, None)
    >    INFO [2020-08-20 10:38:41,303] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Trying to remove executor 3 from BlockManagerMaster.
    >    INFO [2020-08-20 10:38:41,303] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removing block manager BlockManagerId(3, 10.100.6.68, 22322, None)
    >    INFO [2020-08-20 10:38:41,303] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Removed 2 successfully in removeExecutor
    >    INFO [2020-08-20 10:38:41,303] ({kubernetes-executor-maintenance} Logging.scala[logInfo]:57) - Forcefully deleting 1 pods (out of 1) that are still running after graceful shutdown period.
    >    INFO [2020-08-20 10:38:41,304] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Shuffle files lost for executor: 2 (epoch 4)
    >    INFO [2020-08-20 10:38:50,656] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Executor lost: 4 (epoch 5)
    >    INFO [2020-08-20 10:38:50,656] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Trying to remove executor 4 from BlockManagerMaster.
    >    INFO [2020-08-20 10:38:50,656] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Removed 4 successfully in removeExecutor
    >    INFO [2020-08-20 10:38:50,657] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Shuffle files lost for executor: 4 (epoch 5)
    >    INFO [2020-08-20 10:38:50,657] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) - Process of event SparkListenerExecutorRemoved(1597919921299,2,Executor killed by driver.) by listener AppStatusListener took 9.356624495s.
    >    INFO [2020-08-20 10:38:50,657] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Executor lost: 3 (epoch 6)
    >    INFO [2020-08-20 10:38:57,187] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Registering block manager 10.100.3.61:22322 with 2.1 GiB RAM, BlockManagerId(2, 10.100.3.61, 22322, None)
    >    INFO [2020-08-20 10:38:57,188] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Registering block manager 10.100.4.75:22322 with 2.1 GiB RAM, BlockManagerId(4, 10.100.4.75, 22322, None)
    >    INFO [2020-08-20 10:38:57,188] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Registering block manager 10.100.6.68:22322 with 2.1 GiB RAM, BlockManagerId(3, 10.100.6.68, 22322, None)
    >    INFO [2020-08-20 10:38:57,188] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Trying to remove executor 3 from BlockManagerMaster.
    >    INFO [2020-08-20 10:38:57,189] ({dispatcher-BlockManagerMaster} Logging.scala[logInfo]:57) - Removing block manager BlockManagerId(3, 10.100.6.68, 22322, None)
    >    INFO [2020-08-20 10:38:57,189] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Removed 3 successfully in removeExecutor
    >    INFO [2020-08-20 10:38:57,189] ({dag-scheduler-event-loop} Logging.scala[logInfo]:57) - Shuffle files lost for executor: 3 (epoch 6)
    >    INFO [2020-08-20 10:39:09,573] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) - Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@1beeede7)) by listener SQLAppStatusListener took 6.248436698s.
    >    INFO [2020-08-20 10:39:16,079] ({kubernetes-executor-snapshots-subscribers-1} Logging.scala[logInfo]:57) - Going to request 3 executors from Kubernetes.
    >    INFO [2020-08-20 10:50:57,863] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) - Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@29e12807)) by listener AppStatusListener took 168.567255396s.
    >    WARN [2020-08-20 10:51:03,641] ({dispatcher-event-loop-2} Logging.scala[logWarning]:69) - Removing executor 1 with no recent heartbeats: 379342 ms exceeds timeout 120000 ms
    >    INFO [2020-08-20 10:51:13,855] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) - Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@6381374f)) by listener AppStatusListener took 5.489328751s.
    >    INFO [2020-08-20 10:52:48,650] ({kill-executor-thread} Logging.scala[logInfo]:57) - Requesting to kill executor(s) 1
    >    WARN [2020-08-20 10:53:07,970] ({dispatcher-event-loop-2} Logging.scala[logWarning]:69) - Ignored message: true
    >    INFO [2020-08-20 10:53:46,754] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) - Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@6381374f)) by listener SQLAppStatusListener took 34.548601224s.
    >    INFO [2020-08-20 10:53:13,189] ({kill-executor-thread} Logging.scala[logInfo]:57) - Actual list of executor(s) to be killed is 1
    >   ....



    >   ....
    >    INFO [2020-08-20 11:13:02,356] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) -
    >       Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) ->
    >           org.apache.spark.executor.ExecutorMetrics@1f2509ec)) by listener AppStatusListener
    >               took 398.079178621s
    >    .....

    >   ....
    >    WARN [2020-08-20 12:17:03,483] ({netty-rpc-env-timeout} Logging.scala[logWarning]:69) - Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from spark-ditrhz.default.svc:22321 in 120 seconds
    >    WARN [2020-08-20 12:51:13,438] ({netty-rpc-env-timeout} Logging.scala[logWarning]:69) - Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from spark-ditrhz.default.svc:22321 in 120 seconds....
    >   ....


    #
    # Looking at the end of this .. the driver seems to be removing executors because they are not responding.
    #

    >   ....
    >    WARN [2020-08-20 10:38:24,653] ({dispatcher-event-loop-2} Logging.scala[logWarning]:69) - Removing executor 2 with no recent heartbeats: 411295 ms exceeds timeout 120000 ms
    >   ....

    #
    # ... but the executors are shutting themselves down because they loose contact with the driver ..
    #

    #
    # All the executor nodes terminated with error status.
    # Driver node is stll there ... but.
    # Zeppelin notebook cell is listed as RUNNING, but UI is locked up.
    # No option to cancel or abort the job.
    #


    #
    # MetricsUpdate within the driver taking a long time (398sec = 6min)
    #

    >   ....
    >    INFO [2020-08-20 10:39:09,573] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) -
    >       Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) ->
    >           org.apache.spark.executor.ExecutorMetrics@1beeede7)) by listener SQLAppStatusListener
    >               took 6.248436698s.
    >   ....
    >    INFO [2020-08-20 10:50:57,863] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) -
    >       Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) ->
    >           org.apache.spark.executor.ExecutorMetrics@29e12807)) by listener AppStatusListener
    >               took 168.567255396s.
    >   ....
    >    INFO [2020-08-20 10:51:13,855] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) -
    >       Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) ->
    >           org.apache.spark.executor.ExecutorMetrics@6381374f)) by listener AppStatusListener
    >               took 5.489328751s.
    >   ....
    >    INFO [2020-08-20 10:53:46,754] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) -
    >       Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) ->
    >           org.apache.spark.executor.ExecutorMetrics@6381374f)) by listener SQLAppStatusListener took
    >               34.548601224s.
    >   ....
    >    INFO [2020-08-20 11:13:02,356] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) -
    >       Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) ->
    >           org.apache.spark.executor.ExecutorMetrics@1f2509ec)) by listener AppStatusListener
    >               took 398.079178621s.
    >   ....
    >    INFO [2020-08-20 11:22:56,213] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) -
    >       Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) ->
    >           org.apache.spark.executor.ExecutorMetrics@73c84e3a)) by listener AppStatusListener
    >               took 185.740402588s.
    >   ....
    >    INFO [2020-08-20 11:23:17,520] ({spark-listener-group-shared} Logging.scala[logInfo]:57) -
    >       Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) ->
    >           org.apache.spark.executor.ExecutorMetrics@65c9e938)) by listener ExecutionListenerBus
    >               took 14.239709664s.
    >   ....
    >    INFO [2020-08-20 11:23:33,858] ({spark-listener-group-shared} Logging.scala[logInfo]:57) -
    >       Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) ->
    >           org.apache.spark.executor.ExecutorMetrics@4449d56b)) by listener ExecutionListenerBus
    >               took 16.33616684s.
    >   ....
    >    INFO [2020-08-20 12:07:09,105] ({spark-listener-group-appStatus} Logging.scala[logInfo]:57) -
    >       Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) ->
    >           org.apache.spark.executor.ExecutorMetrics@53c9e154)) by listener AppStatusListener
    >               took 117.12563752s.
    >   ....

    #
    # Spark driver () unable to contact itself ?
    #

    >   ....
    >    WARN [2020-08-20 12:17:03,483] ({netty-rpc-env-timeout} Logging.scala[logWarning]:69) - Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from spark-ditrhz.default.svc:22321 in 120 seconds
    >    WARN [2020-08-20 12:51:13,438] ({netty-rpc-env-timeout} Logging.scala[logWarning]:69) - Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from spark-ditrhz.default.svc:22321 in 120 seconds....


# -----------------------------------------------------
# To free up the Zeppelin UI, kill the Spark driver (Zeppelin interpreter) Pod.
#[user@zepplinator]

    kubectl delete pod \
        spark-ditrhz

    #
    # As soon as the Pod is gone, Zeppelin notebook cell returns an error.
    # java.lang.RuntimeException: org.apache.thrift.transport.TTransportException: Socket is closed by peer.
    #
    # Which implies that the Zeppelin notebook cell was connected to the interpreter Pod.
    # We don't know if it was receiving anything, just that it was connected.
    #

    #
    # Still needed to click the [restart] interpreter link to get a new interpreter created.
    #

# -----------------------------------------------------
# Check the stats on the Spark driver (Zeppelin interpreter) Pod.
#[user@zepplinator]

    kubectl exec \
        --tty \
        --stdin \
        spark-dtjzqk \
        -- \
            /bin/bash


# -----------------------------------------------------
#[user@driver-pod]

    ps -ef

    >   UID        PID  PPID  C STIME TTY          TIME CMD
    >   zeppelin     1     0  0 13:37 ?        00:00:00 sh -c /zeppelin/bin/interpreter.sh -d /zeppelin/interpreter/spark -r 12321:12321 -c zeppelin-server.default.svc -p 12320 -i spark-shared_process -l /tmp/local-repo -g spark
    >   zeppelin     9     1  0 13:37 ?        00:00:00 /bin/bash /zeppelin/bin/interpreter.sh -d /zeppelin/interpreter/spark -r 12321:12321 -c zeppelin-server.default.svc -p 12320 -i spark-shared_process -l /tmp/local-repo -g spark
    >   zeppelin    56     9  0 13:37 ?        00:00:00 /bin/bash /zeppelin/bin/interpreter.sh -d /zeppelin/interpreter/spark -r 12321:12321 -c zeppelin-server.default.svc -p 12320 -i spark-shared_process -l /tmp/local-repo -g spark
    >   zeppelin    57    56 17 13:37 ?        00:00:29 /usr/lib/jvm/java-8-openjdk-amd64/bin/java -cp /zeppelin/interpreter/spark/*:/zeppelin/interpreter/zeppelin-interpreter-shaded-0.9.0-SNAPSHOT.jar:/zeppelin/interpreter/spark/spark-interpret
    >   zeppelin   161    57  0 13:37 ?        00:00:00 python2 /tmp/1597930666849-0/zeppelin_python.py 10.100.2.75 44371
    >   zeppelin   172     0  0 13:39 ?        00:00:00 /bin/bash
    >   zeppelin   184   172  0 13:40 ?        00:00:00 ps -ef


# -----------------------------------------------------
#[user@driver-pod]

    free -h

    >                 total        used        free      shared  buff/cache   available
    >   Mem:            44G        5.1G         29G        3.1M        9.8G         38G
    >   Swap:            0B          0B          0B


# -----------------------------------------------------
#[user@driver-pod]

    df -h

    >   Filesystem                 Size  Used Avail Use% Mounted on
    >   overlay                     19G   11G  8.7G  55% /
    >   tmpfs                       23G     0   23G   0% /dev
    >   tmpfs                       23G     0   23G   0% /sys/fs/cgroup
    >   /dev/mapper/atomicos-root   19G   11G  8.7G  55% /spark
    >   shm                         64M     0   64M   0% /dev/shm
    >   tmpfs                       23G   12K   23G   1% /run/secrets/kubernetes.io/serviceaccount
    >   tmpfs                       23G     0   23G   0% /proc/acpi
    >   tmpfs                       23G     0   23G   0% /proc/scsi
    >   tmpfs                       23G     0   23G   0% /sys/firmware


# -----------------------------------------------------
#[user@driver-pod]

    top

    >   Tasks:   9 total,   1 running,   8 sleeping,   0 stopped,   0 zombie
    >   %Cpu(s): 27.9 us,  0.1 sy,  0.0 ni, 70.9 id,  0.0 wa,  0.1 hi,  0.0 si,  0.9 st
    >   KiB Mem : 46255536 total, 30613024 free,  5361696 used, 10280816 buff/cache
    >   KiB Swap:        0 total,        0 free,        0 used. 39894044 avail Mem
    >
    >     PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
    >      57 zeppelin  20   0 12.768g 4.555g  47300 S 391.4 10.3  14:59.16 java
    >       1 zeppelin  20   0    4504    852    780 S   0.0  0.0   0:00.01 sh
    >       9 zeppelin  20   0   19848   3552   3144 S   0.0  0.0   0:00.00 interpreter.sh
    >      56 zeppelin  20   0   19848   2028   1616 S   0.0  0.0   0:00.00 interpreter.sh
    >     161 zeppelin  20   0  130472  20120   7372 S   0.0  0.0   0:00.32 python2
    >     172 zeppelin  20   0   19928   3788   3276 S   0.0  0.0   0:00.00 bash
    >     468 zeppelin  20   0   19928   3784   3276 S   0.0  0.0   0:00.01 bash
    >     482 zeppelin  20   0   19928   3776   3264 S   0.0  0.0   0:00.02 bash
    >     494 zeppelin  20   0   38300   3644   3152 R   0.0  0.0   0:00.00 top


# -----------------------------------------------------
# -----------------------------------------------------

    This time we got an OutOfMemoryError showing up in the Zeppelin notebook


    >   Exception in thread "spark-listener-group-appStatus" java.lang.OutOfMemoryError: GC overhead limit exceeded
    >   ....
    >   ....
    >   Exception in thread "Spark Context Cleaner" java.lang.OutOfMemoryError: GC overhead limit exceeded
    >   	at org.apache.spark.ContextCleaner$$Lambda$1408/176594381.get$Lambda(Unknown Source)
    >   	at java.lang.invoke.LambdaForm$DMH/2114694065.invokeStatic_L_L(LambdaForm$DMH)
    >   	at java.lang.invoke.LambdaForm$MH/1164371389.linkToTargetMethod(LambdaForm$MH)
    >   	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:186)
    >   	at org.apache.spark.ContextCleaner$$Lambda$1353/626233955.apply$mcV$sp(Unknown Source)
    >   	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1319)
    >   	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:180)
    >   	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:77)
    >   Exception in thread "stop-spark-context" java.lang.OutOfMemoryError: GC overhead limit exceeded



    ContextCleaner is a Spark service that is responsible for application-wide cleanup of shuffles, RDDs,
    broadcasts, accumulators and checkpointed RDDs that is aimed at reducing the memory requirements of
    long-running data-heavy Spark applications.

    ContextCleaner runs on the driver. It is created and immediately started when SparkContext starts
    (and spark.cleaner.referenceTracking Spark property is enabled, which it is by default).
    It is stopped when SparkContext is stopped.


# -----------------------------------------------------
# -----------------------------------------------------






