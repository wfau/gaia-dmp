#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#

    Follow on from cephfs provider
        notes/zrq/20200821-01-cephfs-provider.txt


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubenator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${CLUSTER_NAME:?}" \
        --volume "${AGLAIS_CODE}/experiments/zrq/kubernetes:/kubernetes:z" \
        atolmis/openstack-client \
        bash


# -----------------------------------------------------
# Get the connection details for our cluster.
#[user@kubernator]

    mkdir -p "${HOME}/.kube"
    openstack \
        --os-cloud "${cloudname:?}-super" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube"

    kubectl \
        cluster-info

    >   Kubernetes master is running at https://....
    >   Heapster is running at https://....
    >   CoreDNS is running at https://....



# -----------------------------------------------------
# Create a PersistentVolumeClaim for the Gaia DR2 data.
#[user@kubernator]

    kubectl \
        create \
            --filename /kubernetes/manila/cephfs/gaia-dr2-volume-claim.yaml

    >   persistentvolumeclaim/gaia-dr2-volume-claim created


    kubectl get \
        persistentvolumeclaim

    >   NAME                    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                  AGE
    >   gaia-dr2-volume-claim   Bound    pvc-10bb7a62-5fdf-4399-99c4-a37f01634f65   4399G      RWO            manila-cephfs-storage-class   2m27s


    kubectl get \
        persistentvolume

    >   NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                           STORAGECLASS                  REASON   AGE
    >   pvc-10bb7a62-5fdf-4399-99c4-a37f01634f65   4399G      RWO            Delete           Bound    default/gaia-dr2-volume-claim   manila-cephfs-storage-class            3m6s


    kubectl get \
        persistentvolume \
            --output json \
            "pvc-10bb7a62-5fdf-4399-99c4-a37f01634f65"

    >   {
    >       "apiVersion": "v1",
    >       "kind": "PersistentVolume",
    >       "metadata": {
    >           "annotations": {
    >               "manila.cloud-provider-openstack.kubernetes.io/ID": "503db06d-0a85-4d58-a771-76caabf66868",
    >               "manila.cloud-provider-openstack.kubernetes.io/OSSecretName": "os-trustee",
    >               "manila.cloud-provider-openstack.kubernetes.io/OSSecretNamespace": "kube-system",
    >               "manila.cloud-provider-openstack.kubernetes.io/ProvisionType": "dynamic",
    >               "manila.cloud-provider-openstack.kubernetes.io/ShareSecretName": "manila-16da93cd-e35b-11ea-9386-0a580a640251",
    >               "manila.cloud-provider-openstack.kubernetes.io/ShareSecretNamespace": "default",
    >               "pv.kubernetes.io/provisioned-by": "manila-provisioner"
    >           },
    >           "creationTimestamp": "2020-08-21T03:05:01Z",
    >           "finalizers": [
    >               "kubernetes.io/pv-protection"
    >           ],
    >           "name": "pvc-10bb7a62-5fdf-4399-99c4-a37f01634f65",
    >           "resourceVersion": "2126851",
    >           "selfLink": "/api/v1/persistentvolumes/pvc-10bb7a62-5fdf-4399-99c4-a37f01634f65",
    >           "uid": "5998da29-9fd3-444d-974a-0ccce5d7f4e8"
    >       },
    >       "spec": {
    >           "accessModes": [
    >               "ReadWriteOnce"
    >           ],
    >           "capacity": {
    >               "storage": "4399G"
    >           },
    >           "cephfs": {
    >               "monitors": [
    >                   "10.206.1.5:6789",
    >                   "10.206.1.6:6789",
    >                   "10.206.1.7:6789"
    >               ],
    >               "path": "/volumes/_nogroup/616d38f4-d4fe-4421-bd03-e8fe5ae3ddb0",
    >               "secretRef": {
    >                   "name": "manila-16da93cd-e35b-11ea-9386-0a580a640251",
    >                   "namespace": "default"
    >               },
    >               "user": "pvc-10bb7a62-5fdf-4399-99c4-a37f01634f65"
    >           },
    >           "claimRef": {
    >               "apiVersion": "v1",
    >               "kind": "PersistentVolumeClaim",
    >               "name": "gaia-dr2-volume-claim",
    >               "namespace": "default",
    >               "resourceVersion": "2126819",
    >               "uid": "10bb7a62-5fdf-4399-99c4-a37f01634f65"
    >           },
    >           "persistentVolumeReclaimPolicy": "Delete",
    >           "storageClassName": "manila-cephfs-storage-class",
    >           "volumeMode": "Filesystem"
    >       },
    >       "status": {
    >           "phase": "Bound"
    >       }
    >   }


    #
    # We have an persistent volume in Openstack.
    # https://cumulus.openstack.hpc.cam.ac.uk/project/shares/503db06d-0a85-4d58-a771-76caabf66868/
    #
    # Dynamic provisioning means the volume will be deleted when the claim is deleted.
    # We need to change the persistentVolumeReclaimPolicy to Retain.
    #

    # Old style - manila-provisioner
    # https://github.com/gman0/cloud-provider-openstack/blob/ef56215b90cac0cf92d1f750f2ab2e88e2ec01d5/docs/using-manila-provisioner.md#manila-external-provisioner
    # New style - manila-csi-plugin
    # https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-manila-csi-plugin.md


# -----------------------------------------------------
# Set the persistentVolumeReclaimPolicy to Retain.
# https://kubernetes.io/docs/tasks/administer-cluster/change-pv-reclaim-policy/
#[user@kubernator]

    kubectl patch \
        persistentvolume \
            "pvc-10bb7a62-5fdf-4399-99c4-a37f01634f65" \
            -p '{"spec":{"persistentVolumeReclaimPolicy":"Retain"}}'

    >   persistentvolume/pvc-10bb7a62-5fdf-4399-99c4-a37f01634f65 patched

    The volume should stay, even if we delete the claim.
    Don't know how to re-connect a new claim to the existing voluewm .. yet.

    TODO
    Can we create a volume and attach a claim manually ?

    TODO
    How do we mount this volume inside our Spark Pods.
    https://spark.apache.org/docs/latest/running-on-kubernetes.html#using-kubernetes-volumes

        spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.path=<mount path>
        spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.readOnly=<true|false>
        spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.subPath=<mount subPath>
        spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].options.[OptionName]=<value>



        spark.kubernetes.driver.volumes.persistentVolumeClaim.gaia-dr2.mount.path=/gaia-dr2
        spark.kubernetes.driver.volumes.persistentVolumeClaim.gaia-dr2.mount.readOnly=false
        spark.kubernetes.driver.volumes.persistentVolumeClaim.gaia-dr2.options.claimName=gaia-dr2-volume-claim

        spark.kubernetes.executor.volumes.persistentVolumeClaim.gaia-dr2.mount.path=/gaia-dr2
        spark.kubernetes.executor.volumes.persistentVolumeClaim.gaia-dr2.mount.readOnly=true
        spark.kubernetes.executor.volumes.persistentVolumeClaim.gaia-dr2.options.claimName=gaia-dr2-volume-claim

    Tried setting these in the interpreter settings and in the notebook.
    The executor.volumes settings worked, the driver.volumes are ignored.

    Guess is .. the Zeppelin interpreter launches Spark in client mode, in the same Pod container as the
    interpreter. So the interpreter can't add volumes to its own Pod.

    I think the way to get the volume into the driver/interpreter Pod is by editing the interpreter-spec template.
        ${zeppelin}/k8s/interpreter/100-interpreter-spec.yaml

    ... but before we do that, check to see if we need the data volume mounted in the driver/interpreter Pod.

    Change the setting to make the volume read/write to all.

        spark.kubernetes.executor.volumes.persistentVolumeClaim.gaia-dr2.mount.readOnly=false

    Also need to make the PersistentVolumeClaim read/write to many.

        spec:
          storageClassName: manila-cephfs-storage-class
          accessModes:
    -       - ReadWriteOnce
    +       - ReadWriteMany


# -----------------------------------------------------
# Patch the active persistent volume and claim.
#[user@kubernator]

    kubectl patch \
        persistentvolume \
            pvc-10bb7a62-5fdf-4399-99c4-a37f01634f65 \
                -p '{"spec": {"accessModes": ["ReadWriteMany"]}}'

    >   persistentvolume/pvc-10bb7a62-5fdf-4399-99c4-a37f01634f65 patched



    kubectl patch \
        persistentvolumeclaim \
            gaia-dr2-volume-claim \
                -p '{"spec": {"accessModes": ["ReadWriteMany"]}}'

    >   The PersistentVolumeClaim "gaia-dr2-volume-claim" is invalid: spec: Forbidden: is immutable after creation except resources.requests for bound claims

    #
    # Worth a try ...
    #

    #
    # OK, delete the claim, edit the source and create a new claim.
    #


# -----------------------------------------------------
# Delete, edit and create our persistent volume claim.
#[user@kubernator]

    kubectl delete \
        persistentvolumeclaim \
            gaia-dr2-volume-claim

    >   persistentvolumeclaim "gaia-dr2-volume-claim" deleted

    gedit \
        experiments/zrq/kubernetes/manila/cephfs/gaia-dr2-volume-claim.yaml

        accessModes:
    -     - ReadWriteOnce
    +     - ReadWriteMany


    kubectl \
        create \
            --filename /kubernetes/manila/cephfs/gaia-dr2-volume-claim.yaml

    >   persistentvolumeclaim/gaia-dr2-volume-claim created

    #
    # Deleting and creating the claim created a new 4Ti byte share.
    # Good enough for now, but not what we want in the final system.
    #



# -----------------------------------------------------
# Login to one of our executor Pods.
#[user@kubernator]

    kubectl exec \
        --tty \
        --stdin \
        zeppelin-96178f74127f514e-exec-1 \
        -- \
            /bin/bash

        id

    >   uid=185(185) gid=0(root) groups=0(root)

        ls -al /gaia-dr2

    >   total 0
    >   drwxr-xr-x. 2 root root  0 Aug 21 19:26 .
    >   drwxr-xr-x. 1 root root 55 Aug 21 19:29 ..


    #
    # The directory is owned by root,
    # and we are uid 185.
    #

    #
    # The fix seems to be using an initContainer.
    # https://stackoverflow.com/questions/43544370/kubernetes-how-to-set-volumemount-user-group-and-file-permissions

    # Not sure if we have that option.



