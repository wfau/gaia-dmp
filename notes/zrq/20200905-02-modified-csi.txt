#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#

    Install a new Magnum cluster with Ceph CSI installed.
    20200904-01-test-base.txt

    Install a modified version of the Manila CSI plugin.
    Binary version created by Bharat Kunwar (brtknr).
    Includes proposed fix for application credentials.


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${CLUSTER_NAME:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        atolmis/openstack-client \
        bash


# -----------------------------------------------------
# Get the connection details for our cluster.
#[user@kubernator]

    mkdir -p "${HOME}/.kube"
    openstack \
        --os-cloud "${cloudname:?}" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube"


    kubectl \
        cluster-info

    >   Kubernetes master is running at https://....
    >   Heapster is running at https://....
    >   CoreDNS is running at https://....


# -----------------------------------------------------
# Install the git client.
#[user@kubernator]

    dnf install -y git

    >   Installed:
    >       git-2.26.2-1.fc32.x86_64
    >       ....
    >       ....


# -----------------------------------------------------
# Checkout a copy of the Cloud Provider OpenStack repo.
#[user@kubernator]

    pushd "${HOME}"

        git clone 'https://github.com/kubernetes/cloud-provider-openstack.git'

        git fetch --all --tags

        git checkout tags/openstack-manila-csi-0.1.2

    popd


# -----------------------------------------------------
# Install the Manila CSI plugin using Helm.
# https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-manila-csi-plugin.md#kubernetes-115
#[user@kubernator]

    # Default install is NFS only.
    # We can use a local values.yaml to install the CephFS driver.

    # We also want to control the version of manila-cephfs that we install.
    # For this test we explicitly want Bahrat's modified version.
    # https://hub.docker.com/r/brtknr/manila-csi-plugin-amd64


    cat > "/tmp/csi-manila-cephfs-helm-values.yaml" << EOF
# Set the version to install
csimanila:
  image:
    repository: brtknr/manila-csi-plugin-amd64
    tag: appcred
    pullPolicy: IfNotPresent

# Enabled Manila share protocols
shareProtocols:
   - protocolSelector: CEPHFS
     fwdNodePluginEndpoint:
       dir: /var/lib/kubelet/plugins/cephfs.csi.ceph.com
       sockFile: csi.sock

nameOverride: csi-manila-cephfs
EOF


    helm install \
        csi-manila-cephfs \
        "${HOME}/cloud-provider-openstack/charts/manila-csi-plugin" \
        --values "/tmp/csi-manila-cephfs-helm-values.yaml"

    >   NAME: csi-manila-cephfs
    >   LAST DEPLOYED: Sun Sep  6 02:53:43 2020
    >   NAMESPACE: default
    >   STATUS: deployed
    >   REVISION: 1
    >   TEST SUITE: None


# -----------------------------------------------------
# Check all the parts are in place.
# https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-manila-csi-plugin.md#verifying-the-deployment
#[user@kubernator]

    kubectl get all

    >   NAME                                                             READY   STATUS    RESTARTS   AGE
    >   pod/csi-manila-cephfs-controllerplugin-0                         3/3     Running   0          28s
    >   pod/csi-manila-cephfs-nodeplugin-mvjqs                           2/2     Running   0          29s
    >   pod/csi-manila-cephfs-nodeplugin-nw4pv                           2/2     Running   0          29s
    >   pod/csi-manila-cephfs-nodeplugin-rlv4k                           2/2     Running   0          29s
    >   pod/csi-manila-cephfs-nodeplugin-xzlp2                           2/2     Running   0          29s
    >   ....
    >   
    >   
    >   NAME                                                          TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)                      AGE
    >   service/csi-manila-cephfs-controllerplugin                    ClusterIP      10.254.202.229   <none>            12345/TCP                    29s
    >   ....
    >   
    >   NAME                                          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
    >   daemonset.apps/csi-manila-cephfs-nodeplugin   4         4         4       4            4           <none>          29s
    >   ....
    >   
    >   NAME                                                  READY   AGE
    >   statefulset.apps/csi-manila-cephfs-controllerplugin   1/1     28s
    >   ....


# -----------------------------------------------------
# Setup a separate shell tailing the logs on a CephFS provisioner Pod.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${CLUSTER_NAME:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        atolmis/openstack-client \
        bash

    mkdir -p "${HOME}/.kube"
    openstack \
        --os-cloud "${cloudname:?}" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube"

    kubectl \
        cluster-info

    >   Kubernetes master is running at https://....
    >   Heapster is running at https://....
    >   CoreDNS is running at https://....


    podname=$(
        kubectl get \
            --output json \
            --namespace 'default' \
            --selector 'app=csi-manila-cephfs,component=controllerplugin' \
                Pods \
        | jq -r '.items[0].metadata.name'
        )

    echo "Pod [${podname}]"

    >   Pod [csi-manila-cephfs-controllerplugin-0]


    kubectl get \
        --output json \
        --namespace 'default' \
        Pod \
           "${podname:?}" \
    | jq -r '.spec.containers | .[] | .name'

    >   cephfs-provisioner
    >   cephfs-snapshotter
    >   cephfs-nodeplugin


    kubectl \
        logs \
            --follow \
            --namespace 'default' \
           "${podname:?}" \
            --container \
                'cephfs-provisioner'

    >   I0904 18:36:59.460465       1 feature_gate.go:216] feature gates: &{map[]}
    >   I0904 18:36:59.460524       1 csi-provisioner.go:98] Version: v1.4.0-0-g1d9bad3
    >   I0904 18:36:59.460537       1 csi-provisioner.go:112] Building kube configs for running in cluster...
    >   I0904 18:36:59.476897       1 connection.go:151] Connecting to unix:///var/lib/kubelet/plugins/cephfs.manila.csi.openstack.org/csi-controllerplugin.sock
    >   I0904 18:37:08.531156       1 connection.go:261] Probing CSI driver for readiness
    >   I0904 18:37:08.531184       1 connection.go:180] GRPC call: /csi.v1.Identity/Probe
    >   I0904 18:37:08.531196       1 connection.go:181] GRPC request: {}
    >   I0904 18:37:08.535309       1 connection.go:183] GRPC response: {}
    >   I0904 18:37:08.535737       1 connection.go:184] GRPC error: <nil>
    >   I0904 18:37:08.535761       1 connection.go:180] GRPC call: /csi.v1.Identity/GetPluginInfo
    >   I0904 18:37:08.535787       1 connection.go:181] GRPC request: {}
    >   I0904 18:37:08.537816       1 connection.go:183] GRPC response: {"name":"cephfs.manila.csi.openstack.org","vendor_version":"0.9.0"}
    >   I0904 18:37:08.538818       1 connection.go:184] GRPC error: <nil>
    >   I0904 18:37:08.538830       1 csi-provisioner.go:152] Detected CSI driver cephfs.manila.csi.openstack.org
    >   I0904 18:37:08.538903       1 connection.go:180] GRPC call: /csi.v1.Identity/GetPluginCapabilities
    >   I0904 18:37:08.538923       1 connection.go:181] GRPC request: {}
    >   I0904 18:37:08.541014       1 connection.go:183] GRPC response: {"capabilities":[{"Type":{"Service":{"type":1}}}]}
    >   I0904 18:37:08.541689       1 connection.go:184] GRPC error: <nil>
    >   I0904 18:37:08.541709       1 connection.go:180] GRPC call: /csi.v1.Controller/ControllerGetCapabilities
    >   I0904 18:37:08.541738       1 connection.go:181] GRPC request: {}
    >   I0904 18:37:08.543657       1 connection.go:183] GRPC response: {"capabilities":[{"Type":{"Rpc":{"type":1}}},{"Type":{"Rpc":{"type":5}}}]}
    >   I0904 18:37:08.544544       1 connection.go:184] GRPC error: <nil>
    >   I0904 18:37:08.544851       1 controller.go:680] Using saving PVs to API server in background
    >   I0904 18:37:08.544871       1 controller.go:770] Starting provisioner controller cephfs.manila.csi.openstack.org_csi-manila-cephfs-controllerplugin-0_6efaf702-6367-42ce-ac0d-bd662d082dd8!
    >   I0904 18:37:08.544909       1 volume_store.go:97] Starting save volume queue
    >   I0904 18:37:08.545136       1 reflector.go:122] Starting reflector *v1.PersistentVolumeClaim (15m0s) from sigs.k8s.io/sig-storage-lib-external-provisioner/controller/controller.go:801
    >   I0904 18:37:08.545160       1 reflector.go:160] Listing and watching *v1.PersistentVolumeClaim from sigs.k8s.io/sig-storage-lib-external-provisioner/controller/controller.go:801
    >   I0904 18:37:08.545214       1 reflector.go:122] Starting reflector *v1.StorageClass (15m0s) from sigs.k8s.io/sig-storage-lib-external-provisioner/controller/controller.go:807
    >   I0904 18:37:08.545247       1 reflector.go:160] Listing and watching *v1.StorageClass from sigs.k8s.io/sig-storage-lib-external-provisioner/controller/controller.go:807
    >   I0904 18:37:08.545237       1 reflector.go:122] Starting reflector *v1.PersistentVolume (15m0s) from sigs.k8s.io/sig-storage-lib-external-provisioner/controller/controller.go:804
    >   I0904 18:37:08.545262       1 reflector.go:160] Listing and watching *v1.PersistentVolume from sigs.k8s.io/sig-storage-lib-external-provisioner/controller/controller.go:804
    >   I0904 18:37:08.645326       1 shared_informer.go:177] caches populated
    >   I0904 18:37:08.645528       1 controller.go:819] Started provisioner controller cephfs.manila.csi.openstack.org_csi-manila-cephfs-controllerplugin-0_6efaf702-6367-42ce-ac0d-bd662d082dd8!
    >   I0904 18:44:19.553709       1 reflector.go:389] sigs.k8s.io/sig-storage-lib-external-provisioner/controller/controller.go:804: Watch close - *v1.PersistentVolume total 0 items received
    >   I0904 18:45:27.552666       1 reflector.go:389] sigs.k8s.io/sig-storage-lib-external-provisioner/controller/controller.go:801: Watch close - *v1.PersistentVolumeClaim total 0 items received
    >   I0904 18:46:50.551521       1 reflector.go:389] sigs.k8s.io/sig-storage-lib-external-provisioner/controller/controller.go:807: Watch close - *v1.StorageClass total 0 items received
    >   ....
    >   ....


# -----------------------------------------------------
# Setup a separate shell tailing the logs on a CephFS provisioner Pod.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${CLUSTER_NAME:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        atolmis/openstack-client \
        bash

    mkdir -p "${HOME}/.kube"
    openstack \
        --os-cloud "${cloudname:?}" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube"

    kubectl \
        cluster-info

    >   Kubernetes master is running at https://....
    >   Heapster is running at https://....
    >   CoreDNS is running at https://....


    podname=$(
        kubectl get \
            --output json \
            --namespace 'default' \
            --selector 'app=csi-manila-cephfs,component=nodeplugin' \
                Pods \
        | jq -r '.items[0].metadata.name'
        )

    echo "Pod [${podname}]"

    >   Pod [csi-manila-cephfs-nodeplugin-frjtm]


    kubectl get \
        --output json \
        --namespace 'default' \
        Pod \
           "${podname:?}" \
    | jq -r '.spec.containers | .[] | .name'

    >   cephfs-registrar
    >   cephfs-nodeplugin


    kubectl \
        logs \
            --follow \
            --namespace 'default' \
           "${podname:?}" \
            --container \
                'cephfs-nodeplugin'

    >   I0904 18:37:02.430160       1 driver.go:109] Driver: cephfs.manila.csi.openstack.org version: 0.9.0 CSI spec version: 1.2.0
    >   I0904 18:37:02.430208       1 driver.go:125] Operating on CEPHFS shares
    >   I0904 18:37:02.430218       1 driver.go:130] Topology awareness disabled
    >   I0904 18:37:02.430244       1 driver.go:193] Enabling controller service capability: CREATE_DELETE_VOLUME
    >   I0904 18:37:02.430251       1 driver.go:193] Enabling controller service capability: CREATE_DELETE_SNAPSHOT
    >   I0904 18:37:02.430255       1 driver.go:212] Enabling volume access mode: MULTI_NODE_MULTI_WRITER
    >   I0904 18:37:02.430259       1 driver.go:212] Enabling volume access mode: MULTI_NODE_SINGLE_WRITER
    >   I0904 18:37:02.430262       1 driver.go:212] Enabling volume access mode: MULTI_NODE_READER_ONLY
    >   I0904 18:37:02.430267       1 driver.go:212] Enabling volume access mode: SINGLE_NODE_WRITER
    >   I0904 18:37:02.430271       1 driver.go:212] Enabling volume access mode: SINGLE_NODE_READER_ONLY
    >   I0904 18:37:02.431193       1 connection.go:261] Probing CSI driver for readiness
    >   I0904 18:37:02.431213       1 builder.go:39] [ID:1] FWD GRPC call: /csi.v1.Identity/Probe
    >   I0904 18:37:02.431218       1 builder.go:40] [ID:1] FWD GRPC request: {}
    >   I0904 18:37:02.433740       1 builder.go:46] [ID:1] FWD GRPC response: {}
    >   I0904 18:37:02.434231       1 builder.go:39] [ID:2] FWD GRPC call: /csi.v1.Identity/GetPluginInfo
    >   I0904 18:37:02.434238       1 builder.go:40] [ID:2] FWD GRPC request: {}
    >   I0904 18:37:02.436062       1 builder.go:46] [ID:2] FWD GRPC response: {"name":"cephfs.csi.ceph.com","vendor_version":"v3.1.0"}
    >   I0904 18:37:02.437619       1 driver.go:258] proxying CSI driver cephfs.csi.ceph.com version v3.1.0
    >   I0904 18:37:02.437626       1 builder.go:39] [ID:3] FWD GRPC call: /csi.v1.Node/NodeGetCapabilities
    >   I0904 18:37:02.437631       1 builder.go:40] [ID:3] FWD GRPC request: {}
    >   I0904 18:37:02.440788       1 builder.go:46] [ID:3] FWD GRPC response: {"capabilities":[{"Type":{"Rpc":{"type":1}}},{"Type":{"Rpc":{"type":2}}}]}
    >   I0904 18:37:02.443175       1 driver.go:223] Enabling node service capability: STAGE_UNSTAGE_VOLUME
    >   I0904 18:37:02.443242       1 driver.go:223] Enabling node service capability: GET_VOLUME_STATS
    >   I0904 18:37:02.443690       1 driver.go:322] listening for connections on &net.UnixAddr{Name:"/var/lib/kubelet/plugins/cephfs.manila.csi.openstack.org/csi.sock", Net:"unix"}
    >   I0904 18:37:02.822956       1 driver.go:305] [ID:1] GRPC call: /csi.v1.Identity/GetPluginInfo
    >   I0904 18:37:02.822977       1 driver.go:306] [ID:1] GRPC request: {}
    >   I0904 18:37:02.823420       1 driver.go:311] [ID:1] GRPC response: {"name":"cephfs.manila.csi.openstack.org","vendor_version":"0.9.0"}
    >   I0904 18:37:03.634818       1 driver.go:305] [ID:2] GRPC call: /csi.v1.Node/NodeGetInfo
    >   I0904 18:37:03.634844       1 driver.go:306] [ID:2] GRPC request: {}
    >   I0904 18:37:03.635373       1 driver.go:311] [ID:2] GRPC response: {"node_id":"tiberius-20200904-nj46yxjgkhty-node-2"}
    >   ....
    >   ....







