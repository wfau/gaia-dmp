#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#


    Target:

        Live system failed twice at repartitioning the data to 8192 partitions.
        See what evidence we have in the logs on the live services.

    Result:

        Not many clues.
        Only thing of note was Cinder disc on the worker node was close to 90%.


# -----------------------------------------------------
# Create a new branch branch.
#[user@desktop]

    prevbranch=20210511-zrq-hdfs
    nextbranch=$(date '+%Y%m%d')-zrq-postmortem

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        # Start fom master.
        git checkout master

        # Fetch upstream changes
        git fetch upstream
        git merge upstream/master


    >   Already up to date.


        # Create a new branch
        git checkout -b "${nextbranch:?}"

    >   Switched to a new branch '20210516-zrq-postmortem'


        # Add changes from previous branch
        git merge "${prevbranch:?}"

    >   Updating 54c5255..61d4120
    >   Fast-forward
    >    deployments/common/manila/datashares.yaml                |  79 ++++++++++++--
    >    deployments/common/manila/usershares.yaml                |   2 +-
    >    ....
    >    ....
    >    create mode 100644 notes/zrq/20210514-03-git-fetch-pr.txt
    >    create mode 100644 notes/zrq/20210514-04-small-06-deploy.txt


        # Push the new branch
        git push --set-upstream origin "${nextbranch:?}"

    >   ....
    >   Branch '20210516-zrq-postmortem' set up to track remote branch '20210516-zrq-postmortem' from 'origin'.

    popd


# -----------------------------------------------------
# -----------------------------------------------------
# Login to the live server and see what we can find.
#[user@zeppelin]

    # Disc space looks OK
    df -h

    >   Filesystem      Size  Used Avail Use% Mounted on
    >   ....
    >   /dev/vda1        20G  6.8G   12G  37% /
    >   tmpfs           4.5G     0  4.5G   0% /run/user/1000
    >   /dev/vdb         59G   65M   56G   1% /mnt/local/vdb
    >   /dev/vdc        512G   17M  510G   1% /mnt/cinder/vdc
    >   ceph-fuse       512G  473G   40G  93% /data/gaia/dr2
    >   ceph-fuse       540G  533G  7.9G  99% /data/gaia/edr3
    >   ceph-fuse       350G  341G  9.9G  98% /data/wise/allwise
    >   ceph-fuse       300G  270G   31G  90% /data/panstarrs/dr1
    >   ceph-fuse        40G   37G  3.5G  92% /data/twomass/allsky
    >   ceph-fuse        10T  6.5T  3.6T  65% /user/nch
    >   ceph-fuse       1.0T  960G   65G  94% /user/zrq
    >   ceph-fuse       1.0T     0  1.0T   0% /user/stv
    >   ceph-fuse       1.0T     0  1.0T   0% /user/dcr


    # Hadoop files all mounted on local disc
    ls -alh /var/hadoop

    >   ....
    >   lrwxrwxrwx.  1 root root   26 Apr 28 00:51 data -> /mnt/local/vdb/hadoop/data
    >   lrwxrwxrwx.  1 root root   26 Apr 28 00:51 logs -> /mnt/local/vdb/hadoop/logs
    >   lrwxrwxrwx.  1 root root   26 Apr 28 00:52 temp -> /mnt/local/vdb/hadoop/temp


    # Disc space looks OK
    df -h /mnt/local/vdb/hadoop

    >   ....
    >   ....


    # Spark temp mounted on a Cinder volume
    ls -alh /var/spark

    >   lrwxrwxrwx.  1 root root   26 Apr 28 00:56 temp -> /mnt/cinder/vdc/spark/temp


    # Disc space looks OK
    df -h /mnt/cinder/vdc/spark

    >   Filesystem      Size  Used Avail Use% Mounted on
    >   /dev/vdc        512G   17M  510G   1% /mnt/cinder/vdc


    # Spark warehouse files are stored in home directory
    ls -al /home/fedora/spark-warehouse/

    >   total 16
    >   drwxrwxr-x.  3 fedora fedora 4096 May  4 14:14 .
    >   drwx------. 10 fedora fedora 4096 Apr 28 16:57 ..
    >   drwxrwxr-x.  2 fedora fedora 4096 May  4 14:14 gaiaedr3.db


    du -h /home/fedora/spark-warehouse/

    >   4.0K	/home/fedora/spark-warehouse/gaiaedr3.db
    >   8.0K	/home/fedora/spark-warehouse/


    # Spark logs are stored in home directory
    ls -al /home/fedora/zeppelin/logs

    >   -rw-rw-r--.  1 fedora fedora     40804 May 16 12:18 zeppelin-fedora-gaia-prod-20210428-zeppelin.novalocal.log
    >   -rw-rw-r--.  1 fedora fedora    470971 Apr 28 23:47 zeppelin-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-04-28
    >   -rw-rw-r--.  1 fedora fedora    284343 Apr 29 23:25 zeppelin-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-04-29
    >   ....
    >   ....
    >   -rw-rw-r--.  1 fedora fedora    161809 May 14 23:18 zeppelin-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-05-14
    >   -rw-rw-r--.  1 fedora fedora     87942 May 15 23:59 zeppelin-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-05-15
    >   -rw-rw-r--.  1 fedora fedora     33243 May 13 16:05 zeppelin-fedora-gaia-prod-20210428-zeppelin.novalocal.out
    >   
    >   -rw-rw-r--.  1 fedora fedora       382 May 15 13:56 zeppelin-interpreter-md-fedora-gaia-prod-20210428-zeppelin.novalocal.log
    >   -rw-rw-r--.  1 fedora fedora      6658 Apr 28 10:49 zeppelin-interpreter-md-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-04-28
    >   -rw-rw-r--.  1 fedora fedora      2298 Apr 29 15:28 zeppelin-interpreter-md-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-04-29
    >   ....
    >   ....
    >   -rw-rw-r--.  1 fedora fedora      2233 May 13 16:06 zeppelin-interpreter-md-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-05-13
    >   -rw-rw-r--.  1 fedora fedora       382 May 14 19:19 zeppelin-interpreter-md-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-05-14
    >   
    >   -rw-rw-r--.  1 fedora fedora       114 May 13 12:31 zeppelin-interpreter-sh-fedora-gaia-prod-20210428-zeppelin.novalocal.log
    >   -rw-rw-r--.  1 fedora fedora      3815 Apr 30 12:47 zeppelin-interpreter-sh-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-04-30
    >   
    >   -rw-rw-r--.  1 fedora fedora     11932 May 16 10:27 zeppelin-interpreter-spark-fedora-gaia-prod-20210428-zeppelin.novalocal.log
    >   -rw-rw-r--.  1 fedora fedora 357601877 Apr 28 17:59 zeppelin-interpreter-spark-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-04-28
    >   -rw-rw-r--.  1 fedora fedora 350349724 Apr 29 16:16 zeppelin-interpreter-spark-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-04-29
    >   ....
    >   ....
    >   -rw-rw-r--.  1 fedora fedora   6211767 May 14 20:49 zeppelin-interpreter-spark-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-05-14
    >   -rw-rw-r--.  1 fedora fedora   6339713 May 15 15:27 zeppelin-interpreter-spark-fedora-gaia-prod-20210428-zeppelin.novalocal.log.2021-05-15

# -----------------------------------------------------
# Check the Sparkl logs for clues ...
#[user@zeppelin]

    pushd /home/fedora/zeppelin/logs

        logname=$(id -un)-$(hostname)


        less "zeppelin-interpreter-spark-${logname:?}.log.2021-05-15"

    >   ....
    >    WARN [2021-05-15 14:05:44,203] ({ResponseProcessor for block BP-957535726-10.10.2.63-1619571742704:blk_1073767529_26713} DFSOutputStream.java[run]:738)
    >    - Slow ReadProcessor read fields took 55156ms (threshold=30000ms); ack: seqno: 390 reply: SUCCESS reply: SUCCESS reply: SUCCESS
    >       downstreamAckTimeNanos: 63784551509 flag: 0 flag: 0 flag: 0, targets:
    >           [
    >           DatanodeInfoWithStorage[
    >               10.10.2.218:9866,DS-a2eacb54-6354-42b6-9109-cb5d3964df85,DISK
    >               ],
    >           DatanodeInfoWithStorage[
    >               10.10.3.80:9866,DS-0575b691-36e1-4985-9d36-0d2daf7bd90c,DISK
    >               ],
    >           DatanodeInfoWithStorage[
    >               10.10.1.255:9866,DS-91baca01-0653-4178-9663-93761c26c553,DISK
    >               ]
    >           ]
    >   ....
    >    WARN [2021-05-15 14:17:17,385] ({ResponseProcessor for block BP-957535726-10.10.2.63-1619571742704:blk_1073767529_26713} DFSOutputStream.java[run]:738)
    >    - Slow ReadProcessor read fields took 32835ms (threshold=30000ms); ack: seqno: 452 reply: SUCCESS reply: SUCCESS reply: SUCCESS
    >       downstreamAckTimeNanos: 2827092 flag: 0 flag: 0 flag: 0, targets:
    >           [
    >           DatanodeInfoWithStorage[
    >               10.10.2.218:9866,DS-a2eacb54-6354-42b6-9109-cb5d3964df85,DISK
    >               ],
    >           DatanodeInfoWithStorage[
    >               10.10.3.80:9866,DS-0575b691-36e1-4985-9d36-0d2daf7bd90c,DISK
    >               ],
    >           DatanodeInfoWithStorage[
    >               10.10.1.255:9866,DS-91baca01-0653-4178-9663-93761c26c553,DISK
    >               ]
    >           ]
    >   ....
    >    INFO [2021-05-15 14:30:07,380] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 2962.0 in stage 2.0 (TID 12963) in 4203 ms on worker03 (executor 3) (2954/5720)
    >    WARN [2021-05-15 14:30:08,070] ({ResponseProcessor for block BP-957535726-10.10.2.63-1619571742704:blk_1073767529_26713} DFSOutputStream.java[run]:738) - Slow ReadProcessor read fields took 42958ms (threshold=30000ms); ack: seqno: 515 r
    >   eply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 22968221109 flag: 0 flag: 0 flag: 0, targets: [DatanodeInfoWithStorage[10.10.2.218:9866,DS-a2eacb54-6354-42b6-9109-cb5d3964df85,DISK], DatanodeInfoWithStorage[10.10.3.80
    >   :9866,DS-0575b691-36e1-4985-9d36-0d2daf7bd90c,DISK], DatanodeInfoWithStorage[10.10.1.255:9866,DS-91baca01-0653-4178-9663-93761c26c553,DISK]]
    >    INFO [2021-05-15 14:30:08,231] ({dispatcher-event-loop-8} Logging.scala[logInfo]:54) - Starting task 2966.0 in stage 2.0 (TID 12967, worker03, executor 3, partition 2966, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-05-15 14:30:08,232] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 2961.0 in stage 2.0 (TID 12962) in 5115 ms on worker03 (executor 3) (2955/5720)
    >   
    >   
    >   
    >    INFO [2021-05-15 14:37:46,817] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Starting task 3630.0 in stage 2.0 (TID 13631, worker02, executor 1, partition 3630, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-05-15 14:37:46,817] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 3591.0 in stage 2.0 (TID 13592) in 40129 ms on worker02 (executor 1) (3618/5720)
    >    INFO [2021-05-15 14:37:46,818] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 3593.0 in stage 2.0 (TID 13594) in 39136 ms on worker02 (executor 1) (3619/5720)
    >    WARN [2021-05-15 14:37:46,828] ({ResponseProcessor for block BP-957535726-10.10.2.63-1619571742704:blk_1073767529_26713} DFSOutputStream.java[run]:738) - Slow ReadProcessor read fields took 31021ms (threshold=30000ms); ack: seqno: 553 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 2830216 flag: 0 flag: 0 flag: 0, targets: [DatanodeInfoWithStorage[10.10.2.218:9866,DS-a2eacb54-6354-42b6-9109-cb5d3964df85,DISK], DatanodeInfoWithStorage[10.10.3.80:9866,DS-0575b691-36e1-4985-9d36-0d2daf7bd90c,DISK], DatanodeInfoWithStorage[10.10.1.255:9866,DS-91baca01-0653-4178-9663-93761c26c553,DISK]]
    >    INFO [2021-05-15 14:37:48,434] ({dispatcher-event-loop-5} Logging.scala[logInfo]:54) - Starting task 3631.0 in stage 2.0 (TID 13632, worker01, executor 2, partition 3631, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-05-15 14:37:48,434] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 3623.0 in stage 2.0 (TID 13624) in 11036 ms on worker01 (executor 2) (3620/5720)
    >    INFO [2021-05-15 14:37:49,567] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 3632.0 in stage 2.0 (TID 13633, worker02, executor 1, partition 3632, PROCESS_LOCAL, 8450 bytes)
    >   
    >   
    >   
    >   
    >   
    >    INFO [2021-05-15 15:14:33,589] ({dispatcher-event-loop-10} Logging.scala[logInfo]:54) - Starting task 456.0 in stage 3.0 (TID 16177, worker02, executor 1, partition 456, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2021-05-15 15:14:33,589] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 444.0 in stage 3.0 (TID 16165) in 9606 ms on worker02 (executor 1) (445/8192)
    >    INFO [2021-05-15 15:14:35,633] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 457.0 in stage 3.0 (TID 16178, worker01, executor 2, partition 457, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2021-05-15 15:14:35,633] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 445.0 in stage 3.0 (TID 16166) in 10349 ms on worker01 (executor 2) (446/8192)
    >    INFO [2021-05-15 15:14:38,028] ({dispatcher-event-loop-6} Logging.scala[logInfo]:54) - Starting task 458.0 in stage 3.0 (TID 16179, worker02, executor 1, partition 458, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2021-05-15 15:14:38,028] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 446.0 in stage 3.0 (TID 16167) in 12437 ms on worker02 (executor 1) (447/8192)
    >    WARN [2021-05-15 15:14:39,174] ({dispatcher-event-loop-13} Logging.scala[logWarning]:66) - Requesting driver to remove executor 3 for reason Container marked as failed: container_1619571756695_0024_01_000005 on host: worker03. Exit stat
    >   us: -100. Diagnostics: Container released on a *lost* node.
    >   ERROR [2021-05-15 15:14:39,181] ({dispatcher-event-loop-13} Logging.scala[logError]:70) - Lost executor 3 on worker03: Container marked as failed: container_1619571756695_0024_01_000005 on host: worker03. Exit status: -100. Diagnostics:
    >   Container released on a *lost* node.
    >    INFO [2021-05-15 15:14:39,188] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Task 16172 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the
    >    maximum number of failures for the task.
    >    INFO [2021-05-15 15:14:39,188] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Task 16175 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the
    >    maximum number of failures for the task.
    >    INFO [2021-05-15 15:14:39,189] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Task 16171 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the
    >    maximum number of failures for the task.
    >    INFO [2021-05-15 15:14:39,189] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Task 16173 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the
    >    maximum number of failures for the task.
    >    INFO [2021-05-15 15:14:39,192] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Executor lost: 3 (epoch 1)
    >    INFO [2021-05-15 15:14:39,193] ({dispatcher-event-loop-9} Logging.scala[logInfo]:54) - Trying to remove executor 3 from BlockManagerMaster.
    >    INFO [2021-05-15 15:14:39,195] ({dispatcher-event-loop-9} Logging.scala[logInfo]:54) - Removing block manager BlockManagerId(3, worker03, 35869, None)
    >    INFO [2021-05-15 15:14:39,196] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Removed 3 successfully in removeExecutor
    >    INFO [2021-05-15 15:14:39,197] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Shuffle files lost for executor: 3 (epoch 1)
    >    INFO [2021-05-15 15:14:39,636] ({dispatcher-event-loop-5} Logging.scala[logInfo]:54) - Starting task 452.1 in stage 3.0 (TID 16180, worker02, executor 1, partition 452, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2021-05-15 15:14:39,637] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 448.0 in stage 3.0 (TID 16169) in 12816 ms on worker02 (executor 1) (448/8192)
    >    INFO [2021-05-15 15:14:40,931] ({dispatcher-event-loop-8} Logging.scala[logInfo]:54) - Starting task 450.1 in stage 3.0 (TID 16181, worker02, executor 1, partition 450, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2021-05-15 15:14:40,931] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 453.0 in stage 3.0 (TID 16174) in 12154 ms on worker02 (executor 1) (449/8192)
    >    INFO [2021-05-15 15:14:41,712] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Starting task 454.1 in stage 3.0 (TID 16182, worker01, executor 2, partition 454, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2021-05-15 15:14:41,712] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 447.0 in stage 3.0 (TID 16168) in 15031 ms on worker01 (executor 2) (450/8192)
    >   
    >   
    >   
    >   TID 16177) in 10479 ms on worker02 (executor 1) (453/8192)
    >    INFO [2021-05-15 15:14:46,587] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 461.0 in stage 3.0 (TID 16186, worker01, executor 2, partition 461, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2021-05-15 15:14:46,587] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 457.0 in stage 3.0 (TID 16178) in 10955 ms on worker01 (executor 2) (454/8192)
    >    INFO [2021-05-15 15:14:49,129] ({dispatcher-event-loop-11} Logging.scala[logInfo]:54) - Starting task 462.0 in stage 3.0 (TID 16187, worker02, executor 1, partition 462, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2021-05-15 15:14:49,129] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 458.0 in stage 3.0 (TID 16179) in 11101 ms on worker02 (executor 1) (455/8192)
    >    INFO [2021-05-15 15:14:55,249] ({dispatcher-event-loop-9} Logging.scala[logInfo]:54) - Starting task 463.0 in stage 3.0 (TID 16188, worker02, executor 1, partition 463, PROCESS_LOCAL, 7778 bytes)
    >    WARN [2021-05-15 15:14:55,252] ({task-result-getter-1} Logging.scala[logWarning]:66) - Lost task 452.1 in stage 3.0 (TID 16180, worker02, executor 1): FetchFailed(BlockManagerId(3, worker03, 35869, None), shuffleId=0, mapId=3327, reduceId=452, message=
    >   org.apache.spark.shuffle.FetchFailedException: Failed to connect to worker03/10.10.3.14:35869
    >   
    >   
    >   )
    >    INFO [2021-05-15 15:14:55,254] ({task-result-getter-1} Logging.scala[logInfo]:54) - Task 452.1 in stage 3.0 (TID 16180) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
    >    INFO [2021-05-15 15:14:55,254] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Marking ResultStage 3 (saveAsTable at NativeMethodAccessorImpl.java:0) as failed due to a fetch failure from ShuffleMapStage 2 (saveAsTable at NativeMethodAccessorImpl.java:0)
    >    INFO [2021-05-15 15:14:55,264] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 3 (saveAsTable at NativeMethodAccessorImpl.java:0) failed in 790.495 s due to org.apache.spark.shuffle.FetchFailedException: Failed to connect to worker03/10.10.3.14:35869
    >           at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:554)
    >       ...
    >       Caused by: java.io.IOException: Failed to connect to worker03/10.10.3.14:35869
    >   
    >   
    >   
    >   
    >   
    >    INFO [2021-05-15 15:14:55,496] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 2.1 with 1842 tasks
    >    INFO [2021-05-15 15:14:55,960] ({dispatcher-event-loop-6} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 2.1 (TID 16189, worker02, executor 1, partition 2, PROCESS_LOCAL, 8450 bytes)
    >    WARN [2021-05-15 15:14:55,960] ({task-result-getter-0} Logging.scala[logWarning]:66) - Lost task 450.1 in stage 3.0 (TID 16181, worker02, executor 1): FetchFailed(BlockManagerId(3, worker03, 35869, None), shuffleId=0, mapId=1556, reduceId=450, message=
    >   org.apache.spark.shuffle.FetchFailedException: Failed to connect to worker03/10.10.3.14:35869
    >           at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:554)
    >   
    >   
    >    INFO [2021-05-15 15:15:10,276] ({task-result-getter-3} Logging.scala[logInfo]:54) - Task 463.0 in stage 3.0 (TID 16188) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so t
    >   he previous stage needs to be re-run, or because a different copy of the task has already succeeded).
    >    INFO [2021-05-15 15:15:10,276] ({task-result-getter-3} Logging.scala[logInfo]:54) - Removed TaskSet 3.0, whose tasks have all completed, from pool
    >    INFO [2021-05-15 15:15:10,276] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitting ShuffleMapStage 2 (saveAsTable at NativeMethodAccessorImpl.java:0) and ResultStage 3 (saveAsTable at NativeMethodAccessorImpl.java:0) d
    >   ue to fetch failure
    >    INFO [2021-05-15 15:15:10,477] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitting failed stages
    >    INFO [2021-05-15 15:15:11,604] ({dispatcher-event-loop-9} Logging.scala[logInfo]:54) - Starting task 18.0 in stage 2.1 (TID 16207, worker02, executor 1, partition 46, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-05-15 15:15:11,604] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 13.0 in stage 2.1 (TID 16202) in 5695 ms on worker02 (executor 1) (11/1842)
    >    INFO [2021-05-15 15:15:11,691] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 19.0 in stage 2.1 (TID 16208, worker02, executor 1, partition 47, PROCESS_LOCAL, 8450 bytes)
    >   
    >   
    >   
    >    INFO [2021-05-15 15:18:37,770] ({dispatcher-event-loop-12} Logging.scala[logInfo]:54) - Starting task 266.0 in stage 2.1 (TID 16455, worker02, executor 1, partition 729, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-05-15 15:18:37,771] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 262.0 in stage 2.1 (TID 16451) in 3733 ms on worker02 (executor 1) (259/1842)
    >    INFO [2021-05-15 15:18:38,762] ({dispatcher-event-loop-10} Logging.scala[logInfo]:54) - Starting task 267.0 in stage 2.1 (TID 16456, worker02, executor 1, partition 730, PROCESS_LOCAL, 8450 bytes)
    >    INFO [2021-05-15 15:18:38,763] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 263.0 in stage 2.1 (TID 16452) in 4381 ms on worker02 (executor 1) (260/1842)
    >    WARN [2021-05-15 15:18:39,334] ({dispatcher-event-loop-1} Logging.scala[logWarning]:66) - Requesting driver to remove executor 1 for reason Container marked as failed: container_1619571756695_0024_01_000003 on host: worker02. Exit status: -100. Diagnostics: Container released on a *lost* node.
    >    WARN [2021-05-15 15:18:39,334] ({dispatcher-event-loop-1} Logging.scala[logWarning]:66) - Requesting driver to remove executor 2 for reason Container marked as failed: container_1619571756695_0024_01_000004 on host: worker01. Exit status: -100. Diagnostics: Container released on a *lost* node.
    >   ERROR [2021-05-15 15:18:39,334] ({dispatcher-event-loop-1} Logging.scala[logError]:70) - Lost executor 1 on worker02: Container marked as failed: container_1619571756695_0024_01_000003 on host: worker02. Exit status: -100. Diagnostics: Container released on a *lost* node.
    >    INFO [2021-05-15 15:18:39,338] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Task 16453 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
    >    INFO [2021-05-15 15:18:39,338] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Task 16456 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
    >    INFO [2021-05-15 15:18:39,338] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Task 16455 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
    >    INFO [2021-05-15 15:18:39,338] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Task 16454 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
    >   ERROR [2021-05-15 15:18:39,339] ({dispatcher-event-loop-1} Logging.scala[logError]:70) - Lost executor 2 on worker01: Container marked as failed: container_1619571756695_0024_01_000004 on host: worker01. Exit status: -100. Diagnostics: Container released on a *lost* node.
    >    INFO [2021-05-15 15:18:39,341] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Task 16430 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
    >    INFO [2021-05-15 15:18:39,341] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Task 16433 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
    >    INFO [2021-05-15 15:18:39,341] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Task 16432 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
    >    INFO [2021-05-15 15:18:39,341] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Task 16431 failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
    >    INFO [2021-05-15 15:18:39,348] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 609), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,348] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 659), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,348] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 525), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,348] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 629), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,348] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 692), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,348] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 710), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,348] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 481), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,348] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 515), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,349] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 698), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,349] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 345), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,349] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 448), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,352] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 663), so marking it as still running.
    >   
    >   
    >   .
    >    INFO [2021-05-15 15:18:39,388] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 123), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,388] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 265), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,389] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 8), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,389] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 106), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,389] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 579), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,389] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Resubmitted ShuffleMapTask(2, 38), so marking it as still running.
    >    INFO [2021-05-15 15:18:39,389] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Executor lost: 2 (epoch 12)
    >    INFO [2021-05-15 15:18:39,389] ({dispatcher-event-loop-12} Logging.scala[logInfo]:54) - Trying to remove executor 2 from BlockManagerMaster.
    >    INFO [2021-05-15 15:18:39,389] ({dispatcher-event-loop-12} Logging.scala[logInfo]:54) - Removing block manager BlockManagerId(2, worker01, 37767, None)
    >    INFO [2021-05-15 15:18:39,390] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Removed 2 successfully in removeExecutor
    >    INFO [2021-05-15 15:18:39,390] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Shuffle files lost for executor: 2 (epoch 12)
    >    WARN [2021-05-15 15:18:53,576] ({ResponseProcessor for block BP-957535726-10.10.2.63-1619571742704:blk_1073767529_26713} DFSOutputStream.java[run]:738) - Slow ReadProcessor read fields took 32318ms (threshold=30000ms); ack: seqno: 716 reply: SUCCESS reply: SUCCESS reply: SUCCESS downstreamAckTimeNanos: 31600495132 flag: 0 flag: 0 flag: 0, targets: [DatanodeInfoWithStorage[10.10.2.218:9866,DS-a2eacb54-6354-42b6-9109-cb5d3964df85,DISK], DatanodeInfoWithStorage[10.10.3.80:9866,DS-0575b691-36e1-4985-9d36-0d2daf7bd90c,DISK], DatanodeInfoWithStorage[10.10.1.255:9866,DS-91baca01-0653-4178-9663-93761c26c553,DISK]]
    >    INFO [2021-05-15 15:25:58,693] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on zeppelin:37873 in memory (size: 177.2 KB, free: 6.8 GB)
    >    INFO [2021-05-15 15:27:05,984] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 92
    >    INFO [2021-05-15 15:27:05,984] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 79
    >    INFO [2021-05-15 15:27:05,984] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 84


        less "zeppelin-interpreter-spark-${logname:?}.log"

    #
    # This looks like the stalled task was killed by restarting the interpreter at 10:00 on the 16th
    #

    >    INFO [2021-05-16 10:01:42,708] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Cancelling stage 2
    >    INFO [2021-05-16 10:01:42,710] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Killing all running tasks in stage 2: Stage cancelled
    >    INFO [2021-05-16 10:01:42,713] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Removed TaskSet 2.1, whose tasks have all completed, from pool
    >    INFO [2021-05-16 10:01:42,714] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Stage 2 was cancelled
    >    INFO [2021-05-16 10:01:42,714] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ShuffleMapStage 2 (saveAsTable at NativeMethodAccessorImpl.java:0) failed in 67607.233 s due to Job 2 cancelled because killed via the Web UI
    >    INFO [2021-05-16 10:01:42,716] ({Thread-39} Logging.scala[logInfo]:54) - Job 2 failed: saveAsTable at NativeMethodAccessorImpl.java:0, took 72202.532535 s
    >   ERROR [2021-05-16 10:01:42,734] ({Thread-39} Logging.scala[logError]:91) - Aborting job 823c5ef6-72b4-49a9-b94e-0a4b2962fa02.
    >   org.apache.spark.SparkException: Job 2 cancelled because killed via the Web UI
    >   
    >    INFO [2021-05-16 10:01:42,852] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20201211-154540_1478769495 finished by scheduler interpreter_38059344

    #
    # New run started at 10:02 on the 16th ..
    #

    >    INFO [2021-05-16 10:02:51,280] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.2.218:42412) with ID 4
    >    INFO [2021-05-16 10:02:51,385] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Registering block manager worker02:33683 with 6.8 GB RAM, BlockManagerId(4, worker02, 33683, None)
    >    ....
    >    INFO [2021-05-16 10:02:53,306] ({dispatcher-event-loop-11} Logging.scala[logInfo]:54) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.1.255:42908) with ID 6
    >    INFO [2021-05-16 10:02:53,411] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Registering block manager worker01:39441 with 6.8 GB RAM, BlockManagerId(6, worker01, 39441, None)
    >    ....
    >    INFO [2021-05-16 10:02:54,173] ({dispatcher-event-loop-12} Logging.scala[logInfo]:54) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.3.14:55316) with ID 5
    >    INFO [2021-05-16 10:02:54,283] ({dispatcher-event-loop-6} Logging.scala[logInfo]:54) - Registering block manager worker03:41621 with 6.8 GB RAM, BlockManagerId(5, worker03, 41621, None)

    #
    # and Spark tidying things up at 10:27
    #

    >    INFO [2021-05-16 10:27:06,157] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 55
    >    INFO [2021-05-16 10:27:06,159] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 52
    >    ....
    >    ....
    >    INFO [2021-05-16 10:27:06,241] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 54
    >    INFO [2021-05-16 10:27:06,241] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 98
    >    INFO [2021-05-16 10:27:06,241] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 108

    #
    # Then nothing ...
    #


# -----------------------------------------------------
# -----------------------------------------------------
# Login a worker and see what we can find.
#[user@worker03]

    # Cinder volume is at 90%
    df -h

    >   Filesystem      Size  Used Avail Use% Mounted on
    >   ....
    >   /dev/vda1        20G  3.7G   16G  20% /
    >   /dev/vdb         59G   53M   56G   1% /mnt/local/vdb
    >   /dev/vdc        1.0T  903G  121G  89% /mnt/cinder/vdc
    >   ....


    # Hadoop files all mounted on Cinder
    ls -alh /var/hadoop

    >   lrwxrwxrwx.  1 root root   27 Apr 28 00:51 data -> /mnt/cinder/vdc/hadoop/data
    >   lrwxrwxrwx.  1 root root   27 Apr 28 00:51 logs -> /mnt/cinder/vdc/hadoop/logs
    >   lrwxrwxrwx.  1 root root   27 Apr 28 00:52 temp -> /mnt/cinder/vdc/hadoop/temp


    # Disc space is taken up by the temp directory
    du -h -d 1 /mnt/cinder/vdc/hadoop

    >   0       /mnt/cinder/vdc/hadoop/data
    >   34M     /mnt/cinder/vdc/hadoop/logs
    >   253G    /mnt/cinder/vdc/hadoop/temp
    >   253G    /mnt/cinder/vdc/hadoop


    du -h -d 1 /mnt/cinder/vdc/hadoop/temp/

    >   253G    /mnt/cinder/vdc/hadoop/temp/nm-local-dir
    >   253G    /mnt/cinder/vdc/hadoop/temp/


    du -h -d 1 /mnt/cinder/vdc/hadoop/temp/nm-local-dir/

    >   0       /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache_DEL_1620911858767
    >   253G    /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache
    >   24K     /mnt/cinder/vdc/hadoop/temp/nm-local-dir/nmPrivate
    >   0       /mnt/cinder/vdc/hadoop/temp/nm-local-dir/filecache
    >   253G    /mnt/cinder/vdc/hadoop/temp/nm-local-dir/


    du -h -d 1 /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/

    >   252G    /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache
    >   937M    /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/filecache
    >   253G    /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/


    du -h -d 1 /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/

    >   252G    /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024
    >   252G    /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/


    du -h -d 1 /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/

    >   0       /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/filecache
    >   252G    /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/blockmgr-c36be45a-7d91-4062-be7e-07677f66b80a
    >   21M     /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/spark-8864947d-f809-4b6e-a120-47e965fe1fa4
    >   56K     /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/container_1619571756695_0024_01_000008
    >   0       /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/blockmgr-b6e17925-89d1-4720-83c1-80155df60293
    >   252G    /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/


    # HDFS data files mounted on Cinder
    ls -alh /var/hdfs

    >   ....
    >   lrwxrwxrwx.  1 root root   25 Apr 28 00:53 data -> /mnt/cinder/vdc/hdfs/data
    >   lrwxrwxrwx.  1 root root   24 Apr 28 00:54 logs -> /mnt/local/vdc/hdfs/logs

    # Logs directory is empty
    du -h -d 1 /mnt/local/vdc/hdfs

    >   4.0K    /mnt/local/vdc/hdfs/logs
    >   8.0K    /mnt/local/vdc/hdfs


    # 600G of data in HDFS data directory
    du -h -d 1 /mnt/cinder/vdc/hdfs/data

    >   648G	/mnt/cinder/vdc/hdfs/data/current
    >   648G	/mnt/cinder/vdc/hdfs/data


    du -h -d 1 /mnt/cinder/vdc/hdfs/data/current

    >   648G	/mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704
    >   648G	/mnt/cinder/vdc/hdfs/data/current


    du -h /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704

    >   38G     /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704/current/finalized/subdir0/subdir0
    >   33G     /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704/current/finalized/subdir0/subdir1
    >   ....
    >   ....
    >   33G     /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704/current/finalized/subdir0/subdir30
    >   31G     /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704/current/finalized/subdir0/subdir31
    >   648G    /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704/current/finalized/subdir0
    >   648G    /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704/current/finalized
    >   0       /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704/current/rbw
    >   648G    /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704/current
    >   0       /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704/tmp
    >   648G    /mnt/cinder/vdc/hdfs/data/current/BP-957535726-10.10.2.63-1619571742704


    #
    # Combined disk use between HDFS and Hadoop/temp could push the disc out of space.
    #


    du -h -d 1 /mnt/cinder/vdc/

    >   253G    /mnt/cinder/vdc/hadoop
    >   648G    /mnt/cinder/vdc/hdfs
    >   900G    /mnt/cinder/vdc/

    df -h /mnt/cinder/vdc/

    >   Filesystem      Size  Used Avail Use% Mounted on
    >   /dev/vdc        1.0T  903G  121G  89% /mnt/cinder/vdc


# -----------------------------------------------------
# Check the worker logs to see what we can find
#[user@worker03]

    pushd /var/hadoop/logs

        ls -al

    >   ....
    >   -rw-rw-r--. 1 fedora fedora 28740569 May 16 13:04 hadoop-fedora-datanode-gaia-prod-20210428-worker03.novalocal.log
    >   -rw-rw-r--. 1 fedora fedora      702 May 13 13:17 hadoop-fedora-datanode-gaia-prod-20210428-worker03.novalocal.out
    >   -rw-rw-r--. 1 fedora fedora      702 Apr 28 01:02 hadoop-fedora-datanode-gaia-prod-20210428-worker03.novalocal.out.1
    >   -rw-rw-r--. 1 fedora fedora   889481 May 16 13:22 hadoop-fedora-nodemanager-gaia-prod-20210428-worker03.novalocal.log
    >   -rw-rw-r--. 1 fedora fedora      702 May 13 13:17 hadoop-fedora-nodemanager-gaia-prod-20210428-worker03.novalocal.out
    >   -rw-rw-r--. 1 fedora fedora     2211 Apr 28 01:02 hadoop-fedora-nodemanager-gaia-prod-20210428-worker03.novalocal.out.1
    >   -rw-rw-r--. 1 fedora fedora        0 Apr 28 01:02 SecurityAuth-fedora.audit
    >   drwxr-xr-x. 1 fedora fedora       60 May 16 13:26 userlogs


    less "hadoop-$(id -un)-datanode-$(hostname).log"

    >   ....
    >   ....


    less "hadoop-$(id -un)-nodemanager-$(hostname).log"

    >   ....
    >   ....


        ls -al userlogs/application_1619571756695_0024

    >   ....
    >   drwx--x---. 1 fedora fedora 142 May 15 13:57 container_1619571756695_0024_01_000005
    >   drwx--x---. 1 fedora fedora 142 May 16 10:02 container_1619571756695_0024_01_000008


        #
        # Yarn container run on the 15th
        #

        ls -al userlogs/application_1619571756695_0024/container_1619571756695_0024_01_000005

    >   ....
    >   -rw-rw-r--. 1 fedora fedora   36170 May 15 13:57 directory.info
    >   -rw-r-----. 1 fedora fedora    5486 May 15 13:57 launch_container.sh
    >   -rw-rw-r--. 1 fedora fedora       0 May 15 13:57 prelaunch.err
    >   -rw-rw-r--. 1 fedora fedora     100 May 15 13:57 prelaunch.out
    >   -rw-rw-r--. 1 fedora fedora 5081432 May 15 15:14 stderr
    >   -rw-rw-r--. 1 fedora fedora       0 May 15 13:57 stdout


        less userlogs/application_1619571756695_0024/container_1619571756695_0024_01_000005/stderr

    >   2021-05-15 13:57:10,548 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 20626@gaia-prod-20210428-worker03.novalocal
    >   2021-05-15 13:57:10,551 INFO util.SignalUtils: Registered signal handler for TERM
    >   2021-05-15 13:57:10,552 INFO util.SignalUtils: Registered signal handler for HUP
    >   2021-05-15 13:57:10,552 INFO util.SignalUtils: Registered signal handler for INT
    >   2021-05-15 13:57:11,023 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    >   2021-05-15 13:57:11,131 INFO spark.SecurityManager: Changing view acls to: fedora
    >   2021-05-15 13:57:11,131 INFO spark.SecurityManager: Changing modify acls to: fedora
    >   2021-05-15 13:57:11,132 INFO spark.SecurityManager: Changing view acls groups to:
    >   2021-05-15 13:57:11,132 INFO spark.SecurityManager: Changing modify acls groups to:
    >   2021-05-15 13:57:11,133 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fedora); groups with view permissions: Set(); users  with modify permissions: Set(fedora); groups with modify permissions: Set()
    >   2021-05-15 13:57:11,450 INFO client.TransportClientFactory: Successfully created connection to zeppelin/10.10.2.227:38331 after 53 ms (0 ms spent in bootstraps)
    >   2021-05-15 13:57:11,564 INFO spark.SecurityManager: Changing view acls to: fedora
    >   2021-05-15 13:57:11,564 INFO spark.SecurityManager: Changing modify acls to: fedora
    >   2021-05-15 13:57:11,564 INFO spark.SecurityManager: Changing view acls groups to:
    >   2021-05-15 13:57:11,564 INFO spark.SecurityManager: Changing modify acls groups to:
    >   2021-05-15 13:57:11,564 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fedora); groups with view permissions: Set(); users  with modify permissions: Set(fedora); groups with modify permissions: Set()
    >   2021-05-15 13:57:11,625 INFO client.TransportClientFactory: Successfully created connection to zeppelin/10.10.2.227:38331 after 1 ms (0 ms spent in bootstraps)
    >   2021-05-15 13:57:11,667 INFO storage.DiskBlockManager: Created local directory at /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/blockmgr-c36be45a-7d91-4062-be7e-07677f66b80a
    >   2021-05-15 13:57:11,685 INFO memory.MemoryStore: MemoryStore started with capacity 6.8 GB
    >   2021-05-15 13:57:11,876 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@zeppelin:38331
    >   2021-05-15 13:57:11,897 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
    >   2021-05-15 13:57:11,899 INFO executor.Executor: Starting executor ID 3 on host worker03
    >   2021-05-15 13:57:11,966 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35869.
    >   2021-05-15 13:57:11,966 INFO netty.NettyBlockTransferService: Server created on worker03:35869
    >   2021-05-15 13:57:11,967 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
    >   2021-05-15 13:57:11,983 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(3, worker03, 35869, None)
    >   2021-05-15 13:57:11,991 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(3, worker03, 35869, None)
    >   2021-05-15 13:57:11,991 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(3, worker03, 35869, None)
    >   2021-05-15 13:57:11,994 INFO executor.Executor: Using REPL class URI: spark://zeppelin:38331/classes
    >   2021-05-15 13:58:08,404 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2
    >   2021-05-15 13:58:08,407 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 5
    >   2021-05-15 13:58:08,408 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 8
    >   2021-05-15 13:58:08,412 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 11
    >   2021-05-15 13:58:08,416 INFO executor.Executor: Running task 5.0 in stage 0.0 (TID 5)
    >   2021-05-15 13:58:08,416 INFO executor.Executor: Running task 2.0 in stage 0.0 (TID 2)
    >   2021-05-15 13:58:08,416 INFO executor.Executor: Running task 8.0 in stage 0.0 (TID 8)
    >   2021-05-15 13:58:08,416 INFO executor.Executor: Running task 11.0 in stage 0.0 (TID 11)
    >   2021-05-15 13:58:08,444 INFO executor.Executor: Fetching spark://zeppelin:38331/jars/spark-interpreter-0.8.2.jar with timestamp 1621086995186
    >   2021-05-15 13:58:08,476 INFO client.TransportClientFactory: Successfully created connection to zeppelin/10.10.2.227:38331 after 2 ms (0 ms spent in bootstraps)
    >   2021-05-15 13:58:08,478 INFO util.Utils: Fetching spark://zeppelin:38331/jars/spark-interpreter-0.8.2.jar to /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/spark-8864947d-f809-4b6e-a120-47e965fe1fa4/fetchFileTemp2895624933761605862.tmp
    >   2021-05-15 13:58:08,562 INFO util.Utils: Copying /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/spark-8864947d-f809-4b6e-a120-47e965fe1fa4/-14479375101621086995186_cache to /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/container_1619571756695_0024_01_000005/./spark-interpreter-0.8.2.jar
    >   2021-05-15 13:58:08,595 INFO executor.Executor: Adding file:/mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/container_1619571756695_0024_01_000005/./spark-interpreter-0.8.2.jar to class loader
    >   2021-05-15 13:58:08,657 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
    >   2021-05-15 13:58:08,702 INFO client.TransportClientFactory: Successfully created connection to zeppelin/10.10.2.227:37873 after 2 ms (0 ms spent in bootstraps)
    >   2021-05-15 13:58:08,747 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.2 KB, free 6.8 GB)
    >   2021-05-15 13:58:08,756 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 99 ms
    >   ....
    >   ....
    >   
    >   2021-05-15 15:14:34,682 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
    >   2021-05-15 15:14:34,683 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
    >   2021-05-15 15:14:34,683 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
    >   2021-05-15 15:14:34,683 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
    >   2021-05-15 15:14:34,687 INFO codec.CodecConfig: Compression: SNAPPY
    >   2021-05-15 15:14:34,687 INFO codec.CodecConfig: Compression: SNAPPY
    >   2021-05-15 15:14:34,687 INFO hadoop.ParquetOutputFormat: Parquet block size to 134217728
    >   2021-05-15 15:14:34,687 INFO hadoop.ParquetOutputFormat: Parquet page size to 1048576
    >   2021-05-15 15:14:34,687 INFO hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
    >   2021-05-15 15:14:34,688 INFO hadoop.ParquetOutputFormat: Dictionary is on
    >   2021-05-15 15:14:34,688 INFO hadoop.ParquetOutputFormat: Validation is off
    >   2021-05-15 15:14:34,688 INFO hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
    >   2021-05-15 15:14:34,688 INFO hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
    >   2021-05-15 15:14:34,688 INFO hadoop.ParquetOutputFormat: Page size checking is: estimated
    >   2021-05-15 15:14:34,688 INFO hadoop.ParquetOutputFormat: Min row count for page size check is: 100
    >   2021-05-15 15:14:34,688 INFO hadoop.ParquetOutputFormat: Max row count for page size check is: 10000
    >   2021-05-15 15:14:34,688 INFO parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
    >   {
    >     "type" : "struct",
    >     "fields" : [ {
    >       "name" : "solution_id",
    >       "type" : "long",
    >       "nullable" : true,
    >       "metadata" : { }
    >     }, {
    >       "name" : "designation",
    >       "type" : "string",
    >       "nullable" : true,
    >       "metadata" : { }
    >     }, {
    >     ....
    >     ....
    >     }, {
    >       "name" : "ecl_lon",
    >       "type" : "double",
    >       "nullable" : true,
    >       "metadata" : { }
    >     }, {
    >       "name" : "ecl_lat",
    >       "type" : "double",
    >       "nullable" : true,
    >       "metadata" : { }
    >     } ]
    >   }
    >   and corresponding Parquet message type:
    >   message spark_schema {
    >     optional int64 solution_id;
    >     optional binary designation (UTF8);
    >     optional int64 source_id;
    >     optional int64 random_index;
    >     ....
    >     ....
    >     optional double l;
    >     optional double b;
    >     optional double ecl_lon;
    >     optional double ecl_lat;
    >   }
    >   
    >   2021-05-15 15:14:39,426 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
    >   2021-05-15 15:14:39,755 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM


        #
        # Yarn container run on the 16th
        #

        ls -al userlogs/application_1619571756695_0024/container_1619571756695_0024_01_000008

    >   ....
    >   -rw-rw-r--. 1 fedora fedora 36170 May 16 10:02 directory.info
    >   -rw-r-----. 1 fedora fedora  5486 May 16 10:02 launch_container.sh
    >   -rw-rw-r--. 1 fedora fedora     0 May 16 10:02 prelaunch.err
    >   -rw-rw-r--. 1 fedora fedora   100 May 16 10:02 prelaunch.out
    >   -rw-rw-r--. 1 fedora fedora  4126 May 16 10:02 stderr
    >   -rw-rw-r--. 1 fedora fedora     0 May 16 10:02 stdout






        # Not much in here ...
        less userlogs/application_1619571756695_0024/container_1619571756695_0024_01_000008/stderr

    >   2021-05-16 10:02:51,350 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 22397@gaia-prod-20210428-worker03.novalocal
    >   2021-05-16 10:02:51,412 INFO util.SignalUtils: Registered signal handler for TERM
    >   2021-05-16 10:02:51,414 INFO util.SignalUtils: Registered signal handler for HUP
    >   2021-05-16 10:02:51,414 INFO util.SignalUtils: Registered signal handler for INT
    >   2021-05-16 10:02:52,230 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    >   2021-05-16 10:02:52,413 INFO spark.SecurityManager: Changing view acls to: fedora
    >   2021-05-16 10:02:52,418 INFO spark.SecurityManager: Changing modify acls to: fedora
    >   2021-05-16 10:02:52,420 INFO spark.SecurityManager: Changing view acls groups to:
    >   2021-05-16 10:02:52,422 INFO spark.SecurityManager: Changing modify acls groups to:
    >   2021-05-16 10:02:52,424 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fedora); groups with view permissions: Set(); users  with modify permissions: Set(fedora); groups with modify permissions: Set()
    >   2021-05-16 10:02:53,144 INFO client.TransportClientFactory: Successfully created connection to zeppelin/10.10.2.227:38331 after 60 ms (0 ms spent in bootstraps)
    >   2021-05-16 10:02:53,314 INFO spark.SecurityManager: Changing view acls to: fedora
    >   2021-05-16 10:02:53,315 INFO spark.SecurityManager: Changing modify acls to: fedora
    >   2021-05-16 10:02:53,315 INFO spark.SecurityManager: Changing view acls groups to:
    >   2021-05-16 10:02:53,315 INFO spark.SecurityManager: Changing modify acls groups to:
    >   2021-05-16 10:02:53,315 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fedora); groups with view permissions: Set(); users  with modify permissions: Set(fedora); groups with modify permissions: Set()
    >   2021-05-16 10:02:53,389 INFO client.TransportClientFactory: Successfully created connection to zeppelin/10.10.2.227:38331 after 3 ms (0 ms spent in bootstraps)
    >   2021-05-16 10:02:53,766 INFO storage.DiskBlockManager: Created local directory at /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0024/blockmgr-b6e17925-89d1-4720-83c1-80155df60293
    >   2021-05-16 10:02:53,949 INFO memory.MemoryStore: MemoryStore started with capacity 6.8 GB
    >   2021-05-16 10:02:54,150 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@zeppelin:38331
    >   2021-05-16 10:02:54,177 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
    >   2021-05-16 10:02:54,179 INFO executor.Executor: Starting executor ID 5 on host worker03
    >   2021-05-16 10:02:54,255 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41621.
    >   2021-05-16 10:02:54,255 INFO netty.NettyBlockTransferService: Server created on worker03:41621
    >   2021-05-16 10:02:54,257 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
    >   2021-05-16 10:02:54,276 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(5, worker03, 41621, None)
    >   2021-05-16 10:02:54,286 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(5, worker03, 41621, None)
    >   2021-05-16 10:02:54,287 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(5, worker03, 41621, None)
    >   2021-05-16 10:02:54,291 INFO executor.Executor: Using REPL class URI: spark://zeppelin:38331/classes

    # Starts at 10:02 ... nothing after that


