#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Live system failed twice at repartitioning the data to 8192 partitions.
        Try running the standard RandomForest test case ..

    Result:

        Log analysis suggests something in Zeppelin stalled rather than issues with disc access ?
        Go figure ...


# -----------------------------------------------------
# -----------------------------------------------------

    Good astrometric solutions via ML Random Forest classifier
    https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2FRPC4BFS/note.json


        #
        # Use the original 11932 partition data.
        gs_parquet = sqlContext.read.parquet('file:////data/gaia/edr3/GEDR3_11932_GAIASOURCE')


    #
    # Starting a new test, (500 trees on 100% data)
    #

    First cell - Took 0 sec. Last updated by zrq at May 16 2021, 2:57:19 PM.
    Last cell  - Incomplete; Zeppelin cell stuck at 100%


    #
    # Zeppelin Spark logs looks good to start with ...
    #

    >   ....
    >    INFO [2021-05-16 14:02:25,919] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Starting task 1847.0 in stage 1.0 (TID 1848, worker04, executor 3, partition 1847, PROCESS_LOCAL, 8472 bytes)
    >    INFO [2021-05-16 14:02:25,919] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 1834.0 in stage 1.0 (TID 1835) in 1565 ms on worker04 (executor 3) (1836/5720)
    >    INFO [2021-05-16 14:02:26,069] ({dispatcher-event-loop-9} Logging.scala[logInfo]:54) - Added rdd_4_1833 in memory on worker04:33729 (size: 23.8 KB, free: 6.7 GB)
    >    INFO [2021-05-16 14:02:26,072] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 1848.0 in stage 1.0 (TID 1849, worker04, executor 3, partition 1848, PROCESS_LOCAL, 8472 bytes)
    >    INFO [2021-05-16 14:02:26,072] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 1833.0 in stage 1.0 (TID 1834) in 1744 ms on worker04 (executor 3) (1837/5720)
    >    INFO [2021-05-16 14:02:26,156] ({dispatcher-event-loop-12} Logging.scala[logInfo]:54) - Added rdd_4_1838 in memory on worker03:33159 (size: 38.6 KB, free: 6.7 GB)
    >    INFO [2021-05-16 14:02:26,160] ({dispatcher-event-loop-11} Logging.scala[logInfo]:54) - Starting task 1849.0 in stage 1.0 (TID 1850, worker03, executor 2, partition 1849, PROCESS_LOCAL, 8472 bytes)
    >    INFO [2021-05-16 14:02:26,160] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 1838.0 in stage 1.0 (TID 1839) in 1581 ms on worker03 (executor 2) (1838/5720)
    >    INFO [2021-05-16 14:02:26,321] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Added rdd_4_1836 in memory on worker04:33729 (size: 19.1 KB, free: 6.7 GB)
    >    INFO [2021-05-16 14:02:26,324] ({dispatcher-event-loop-10} Logging.scala[logInfo]:54) - Starting task 1850.0 in stage 1.0 (TID 1851, worker04, executor 3, partition 1850, PROCESS_LOCAL, 8472 bytes)
    >    INFO [2021-05-16 14:02:26,324] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 1836.0 in stage 1.0 (TID 1837) in 1784 ms on worker04 (executor 3) (1839/5720)
    >    INFO [2021-05-16 14:02:26,326] ({dispatcher-event-loop-9} Logging.scala[logInfo]:54) - Added rdd_4_1839 in memory on worker03:33159 (size: 15.9 KB, free: 6.7 GB)
    >    INFO [2021-05-16 14:02:26,329] ({dispatcher-event-loop-8} Logging.scala[logInfo]:54) - Starting task 1851.0 in stage 1.0 (TID 1852, worker03, executor 2, partition 1851, PROCESS_LOCAL, 8472 bytes)
    >    INFO [2021-05-16 14:02:26,329] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 1839.0 in stage 1.0 (TID 1840) in 1594 ms on worker03 (executor 2) (1840/5720)
    >    INFO [2021-05-16 14:02:26,590] ({dispatcher-event-loop-11} Logging.scala[logInfo]:54) - Added rdd_4_1841 in memory on worker01:43281 (size: 21.1 KB, free: 6.7 GB)
    >   ....

    #
    # Worker container log looks good ..
    #

    >   ....
    >   2021-05-16 14:02:15,307 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1767
    >   2021-05-16 14:02:15,307 INFO executor.Executor: Running task 1766.0 in stage 1.0 (TID 1767)
    >   2021-05-16 14:02:15,313 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/edr3/GEDR3_11932_GAIASOURCE/part-02363-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet, range: 0-49979748, partition values: [empty row]
    >   2021-05-16 14:02:15,344 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,349 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,354 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,368 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/edr3/GEDR3_11932_GAIASOURCE/part-00610-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet, range: 0-49980505, partition values: [empty row]
    >   2021-05-16 14:02:15,398 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,403 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,407 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,804 INFO memory.MemoryStore: Block rdd_4_1756 stored as values in memory (estimated size 40.3 KB, free 6.7 GB)
    >   2021-05-16 14:02:15,808 INFO executor.Executor: Finished task 1756.0 in stage 1.0 (TID 1757). 2298 bytes result sent to driver
    >   2021-05-16 14:02:15,809 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1771
    >   2021-05-16 14:02:15,810 INFO executor.Executor: Running task 1770.0 in stage 1.0 (TID 1771)
    >   2021-05-16 14:02:15,815 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/edr3/GEDR3_11932_GAIASOURCE/part-00016-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet, range: 0-49978955, partition values: [empty row]
    >   2021-05-16 14:02:15,824 INFO memory.MemoryStore: Block rdd_4_1760 stored as values in memory (estimated size 17.2 KB, free 6.7 GB)
    >   2021-05-16 14:02:15,826 INFO executor.Executor: Finished task 1760.0 in stage 1.0 (TID 1761). 2298 bytes result sent to driver
    >   2021-05-16 14:02:15,828 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1772
    >   2021-05-16 14:02:15,828 INFO executor.Executor: Running task 1771.0 in stage 1.0 (TID 1772)
    >   2021-05-16 14:02:15,833 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/edr3/GEDR3_11932_GAIASOURCE/part-00615-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet, range: 0-49978845, partition values: [empty row]
    >   2021-05-16 14:02:15,885 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/edr3/GEDR3_11932_GAIASOURCE/part-03887-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet, range: 0-49979665, partition values: [empty row]
    >   2021-05-16 14:02:15,891 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,891 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,897 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,897 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,901 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,902 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,909 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,914 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:15,919 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,099 INFO memory.MemoryStore: Block rdd_4_1761 stored as values in memory (estimated size 24.8 KB, free 6.7 GB)
    >   2021-05-16 14:02:16,102 INFO executor.Executor: Finished task 1761.0 in stage 1.0 (TID 1762). 2298 bytes result sent to driver
    >   2021-05-16 14:02:16,104 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1775
    >   2021-05-16 14:02:16,104 INFO executor.Executor: Running task 1774.0 in stage 1.0 (TID 1775)
    >   2021-05-16 14:02:16,109 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/edr3/GEDR3_11932_GAIASOURCE/part-05454-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet, range: 0-49978070, partition values: [empty row]
    >   2021-05-16 14:02:16,136 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,142 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,146 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,455 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/edr3/GEDR3_11932_GAIASOURCE/part-02992-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet, range: 0-49978744, partition values: [empty row]
    >   2021-05-16 14:02:16,479 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,483 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,487 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,653 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/edr3/GEDR3_11932_GAIASOURCE/part-05265-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet, range: 0-49978855, partition values: [empty row]
    >   2021-05-16 14:02:16,680 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,684 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,688 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,691 INFO memory.MemoryStore: Block rdd_4_1766 stored as values in memory (estimated size 55.4 KB, free 6.7 GB)
    >   2021-05-16 14:02:16,694 INFO executor.Executor: Finished task 1766.0 in stage 1.0 (TID 1767). 2298 bytes result sent to driver
    >   2021-05-16 14:02:16,695 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1779
    >   2021-05-16 14:02:16,695 INFO executor.Executor: Running task 1778.0 in stage 1.0 (TID 1779)
    >   2021-05-16 14:02:16,700 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/edr3/GEDR3_11932_GAIASOURCE/part-01266-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet, range: 0-49977226, partition values: [empty row]
    >   2021-05-16 14:02:16,723 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,728 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:16,732 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-05-16 14:02:17,161 INFO memory.MemoryStore: Block rdd_4_1770 stored as values in memory (estimated size 34.1 KB, free 6.7 GB)
    >   2021-05-16 14:02:17,164 INFO executor.Executor: Finished task 1770.0 in stage 1.0 (TID 1771). 2298 bytes result sent to driver
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------

    Zeppelin notebook gets stuck at the end of the misclassifications cell.
    Print statements completed ..


        true_positives = positives[1.0]
        false_positives = positives[0.0]
        true_negatives = negatives[0.0]
        false_negatives = negatives[1.0]
        print('   |%7d%7d'%(1,2))
        print('------------------------------')
        print(' 1 |%7d%7d'%(true_positives, false_positives))
        print(' 2 |%7d%7d'%(false_negatives, true_negatives))
        print()

    >      |      1      2
    >   ------------------------------
    >    1 |  80320    553
    >    2 |     10  80422



        num_misclassified = false_positives + false_negatives
        total_num_in_test = true_positives + true_negatives + num_misclassified
        misclassified_pc = 100.0 * float(num_misclassified) / float(total_num_in_test)
        print('Misclassifications for the test set: %.2f %%'%(misclassified_pc))

    >   Misclassifications for the test set: 0.35 %


    The cell status is shown as [RUNNING 100%] .. but Zeppelin hasn't moved on to the next cell.

    Last log message from PySpark interpreter was over half an hour ago

    >   ....
    >   ....
    >    INFO [2021-05-16 14:36:18,485] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[132] at toPandas at <ipython-input-18-526bf827e3c5>:6) (first 15 tasks are for partitions Vector(0))
    >    INFO [2021-05-16 14:36:18,485] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 40.0 with 1 tasks
    >    INFO [2021-05-16 14:36:18,485] ({dispatcher-event-loop-6} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 40.0 (TID 131597, worker04, executor 3, partition 0, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2021-05-16 14:36:18,491] ({dispatcher-event-loop-12} Logging.scala[logInfo]:54) - Added broadcast_38_piece0 in memory on worker04:33729 (size: 926.1 KB, free: 6.7 GB)
    >    INFO [2021-05-16 14:36:18,531] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Asked to send map output locations for shuffle 14 to 10.10.3.80:41892
    >    INFO [2021-05-16 14:36:25,164] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 40.0 (TID 131597) in 6679 ms on worker04 (executor 3) (1/1)
    >    INFO [2021-05-16 14:36:25,164] ({task-result-getter-0} Logging.scala[logInfo]:54) - Removed TaskSet 40.0, whose tasks have all completed, from pool
    >    INFO [2021-05-16 14:36:25,164] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 40 (toPandas at <ipython-input-18-526bf827e3c5>:6) finished in 6.727 s
    >    INFO [2021-05-16 14:36:25,165] ({Thread-38} Logging.scala[logInfo]:54) - Job 18 finished: toPandas at <ipython-input-18-526bf827e3c5>:6, took 9.789824 s


    Last log message on the worker was over half an hour ago

    >   ....
    >   ....
    >   2021-05-16 14:36:18,433 INFO columnar.InMemoryTableScanExec: Predicate isnotnull(parallax#9) generates partition filter: ((parallax.count#2692 - parallax.nullCount#2691) > 0)
    >   2021-05-16 14:36:18,433 INFO columnar.InMemoryTableScanExec: Predicate isnotnull(random_index#3L) generates partition filter: ((random_index.count#2667 - random_index.nullCount#2666) > 0)
    >   2021-05-16 14:36:18,433 INFO columnar.InMemoryTableScanExec: Predicate (parallax#9 < -8.0) generates partition filter: (parallax.lowerBound#2690 < -8.0)
    >   2021-05-16 14:36:18,435 INFO executor.Executor: Finished task 5717.0 in stage 39.0 (TID 131596). 1829 bytes result sent to driver


    #
    # Checksum test is around 0.90
    #

    >   ....
    >   2021-05-16T15:10:16+00:00
    >   a03b7053a636486d6285d7b80999b263  part-00132-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet
    >   real 0.87
    >   user 0.07
    >   sys 0.01
    >   ----
    >   2021-05-16T15:10:37+00:00
    >   f07c04aebda978b9c3a8b9928e754e14  part-00133-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet
    >   real 0.88
    >   user 0.07
    >   sys 0.01
    >   ----
    >   2021-05-16T15:10:58+00:00
    >   f98ea5bdcdffc980423994d276cda660  part-00134-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet
    >   real 0.89
    >   user 0.07
    >   sys 0.01
    >   ----
    >   2021-05-16T15:11:19+00:00
    >   b68c0ae96791ee25eebea73e04beee17  part-00135-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet
    >   real 0.99
    >   user 0.07
    >   sys 0.01
    >   ----
    >   2021-05-16T15:11:40+00:00
    >   74ccad7f09aa0214938a25ece29074a4  part-00136-59b9273a-2ef1-4988-8778-e00f67e65264-c000.snappy.parquet
    >   real 0.95
    >   user 0.07
    >   sys 0.01
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------


    Turns out the SSH connection to the zeppelin and worker nodes had broken, so logs were out of date.


# -----------------------------------------------------
# Checking the Zeppelin log ..
#[user@zeppelin]

    pushd /home/fedora/zeppelin/logs

        logname=$(id -un)-$(hostname)

        tail -f zeppelin-interpreter-spark-${logname:?}.log


    >   ....
    >   ms on worker03 (executor 2) (5712/5720)
    >    INFO [2021-05-16 14:36:18,427] ({dispatcher-event-loop-6} Logging.scala[logInfo]:54) - Starting task 5713.0 in stage 39.0 (TID 131593, worker03, executor 2, partition 5713, PROCESS_LOCAL, 8758 bytes)
    >    INFO [2021-05-16 14:36:18,428] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 5699.0 in stage 39.0 (TID 131589) in 5 ms on worker03 (executor 2) (5713/5720)
    >    INFO [2021-05-16 14:36:18,428] ({dispatcher-event-loop-7} Logging.scala[logInfo]:54) - Starting task 5714.0 in stage 39.0 (TID 131594, worker03, executor 2, partition 5714, PROCESS_LOCAL, 8758 bytes)
    >    INFO [2021-05-16 14:36:18,428] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 5701.0 in stage 39.0 (TID 131590) in 4 ms on worker03 (executor 2) (5714/5720)
    >    INFO [2021-05-16 14:36:18,430] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 5715.0 in stage 39.0 (TID 131595, worker03, executor 2, partition 5715, PROCESS_LOCAL, 8758 bytes)
    >    INFO [2021-05-16 14:36:18,430] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 5705.0 in stage 39.0 (TID 131591) in 4 ms on worker03 (executor 2) (5715/5720)
    >    INFO [2021-05-16 14:36:18,432] ({dispatcher-event-loop-5} Logging.scala[logInfo]:54) - Starting task 5717.0 in stage 39.0 (TID 131596, worker03, executor 2, partition 5717, PROCESS_LOCAL, 8758 bytes)
    >    INFO [2021-05-16 14:36:18,432] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 5713.0 in stage 39.0 (TID 131593) in 5 ms on worker03 (executor 2) (5716/5720)
    >    INFO [2021-05-16 14:36:18,432] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 5706.0 in stage 39.0 (TID 131592) in 5 ms on worker03 (executor 2) (5717/5720)
    >    INFO [2021-05-16 14:36:18,433] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 5714.0 in stage 39.0 (TID 131594) in 5 ms on worker03 (executor 2) (5718/5720)
    >    INFO [2021-05-16 14:36:18,434] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 5715.0 in stage 39.0 (TID 131595) in 4 ms on worker03 (executor 2) (5719/5720)
    >    INFO [2021-05-16 14:36:18,436] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 5717.0 in stage 39.0 (TID 131596) in 5 ms on worker03 (executor 2) (5720/5720)
    >    INFO [2021-05-16 14:36:18,436] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 39.0, whose tasks have all completed, from pool
    >    INFO [2021-05-16 14:36:18,436] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ShuffleMapStage 39 (toPandas at <ipython-input-18-526bf827e3c5>:6) finished in 3.027 s
    >    INFO [2021-05-16 14:36:18,436] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - looking for newly runnable stages
    >    INFO [2021-05-16 14:36:18,436] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - running: Set()
    >    INFO [2021-05-16 14:36:18,436] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - waiting: Set(ResultStage 40)
    >    INFO [2021-05-16 14:36:18,436] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - failed: Set()
    >    INFO [2021-05-16 14:36:18,437] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 40 (MapPartitionsRDD[132] at toPandas at <ipython-input-18-526bf827e3c5>:6), which has no missing parents
    >    INFO [2021-05-16 14:36:18,477] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_38 stored as values in memory (estimated size 2.1 MB, free 6.8 GB)
    >    INFO [2021-05-16 14:36:18,484] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_38_piece0 stored as bytes in memory (estimated size 926.1 KB, free 6.8 GB)
    >    INFO [2021-05-16 14:36:18,484] ({dispatcher-event-loop-11} Logging.scala[logInfo]:54) - Added broadcast_38_piece0 in memory on zeppelin:45853 (size: 926.1 KB, free: 6.8 GB)
    >    INFO [2021-05-16 14:36:18,484] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 38 from broadcast at DAGScheduler.scala:1184
    >    INFO [2021-05-16 14:36:18,485] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[132] at toPandas at <ipython-input-18-526bf827e3c5>:6) (first 15 tasks are for partitions Vector(0))
    >    INFO [2021-05-16 14:36:18,485] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 40.0 with 1 tasks
    >    INFO [2021-05-16 14:36:18,485] ({dispatcher-event-loop-6} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 40.0 (TID 131597, worker04, executor 3, partition 0, PROCESS_LOCAL, 7778 bytes)
    >    INFO [2021-05-16 14:36:18,491] ({dispatcher-event-loop-12} Logging.scala[logInfo]:54) - Added broadcast_38_piece0 in memory on worker04:33729 (size: 926.1 KB, free: 6.7 GB)
    >    INFO [2021-05-16 14:36:18,531] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Asked to send map output locations for shuffle 14 to 10.10.3.80:41892
    >    INFO [2021-05-16 14:36:25,164] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 40.0 (TID 131597) in 6679 ms on worker04 (executor 3) (1/1)
    >    INFO [2021-05-16 14:36:25,164] ({task-result-getter-0} Logging.scala[logInfo]:54) - Removed TaskSet 40.0, whose tasks have all completed, from pool
    >    INFO [2021-05-16 14:36:25,164] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 40 (toPandas at <ipython-input-18-526bf827e3c5>:6) finished in 6.727 s
    >    INFO [2021-05-16 14:36:25,165] ({Thread-38} Logging.scala[logInfo]:54) - Job 18 finished: toPandas at <ipython-input-18-526bf827e3c5>:6, took 9.789824 s
    >    INFO [2021-05-16 14:57:37,148] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 938
    >    INFO [2021-05-16 14:57:37,148] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 984
    >   ....
    >    INFO [2021-05-16 14:57:37,231] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 822
    >    INFO [2021-05-16 14:57:37,231] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 365

    Stopped after the toPandas() call at 14:57
    Then we restarted the PySpark interpreter at 15:19

    >    INFO [2021-05-16 15:19:38,455] ({pool-1-thread-4} RemoteInterpreterServer.java[cancel]:681) - cancel org.apache.zeppelin.spark.PySparkInterpreter 20201016-154755_24366630
    >    INFO [2021-05-16 15:19:38,525] ({pool-1-thread-4} Logging.scala[logInfo]:54) - Asked to cancel job group zeppelin-zrq-2G77GX2A5-20201016-154755_24366630
    >    INFO [2021-05-16 15:19:38,685] ({pool-1-thread-3} RemoteInterpreterServer.java[cancel]:681) - cancel org.apache.zeppelin.spark.PySparkInterpreter 20201016-154755_24366630
    >   ERROR [2021-05-16 15:19:38,688] ({pool-1-thread-3} TThreadPoolServer.java[run]:296) - Error occurred during processing of message.
    >   io.grpc.StatusRuntimeException: UNAVAILABLE: Channel shutdown invoked
    >   	at io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
    >   	at io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
    >   	at io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
    >   	at org.apache.zeppelin.python.proto.IPythonGrpc$IPythonBlockingStub.cancel(IPythonGrpc.java:334)
    >   	at org.apache.zeppelin.python.IPythonClient.cancel(IPythonClient.java:194)
    >   	at org.apache.zeppelin.python.IPythonInterpreter.cancel(IPythonInterpreter.java:364)
    >   	at org.apache.zeppelin.spark.IPySparkInterpreter.cancel(IPySparkInterpreter.java:120)
    >   	at org.apache.zeppelin.spark.PySparkInterpreter.cancel(PySparkInterpreter.java:519)
    >   	at org.apache.zeppelin.interpreter.LazyOpenInterpreter.cancel(LazyOpenInterpreter.java:112)
    >   	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer.cancel(RemoteInterpreterServer.java:690)
    >   	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Processor$cancel.getResult(RemoteInterpreterService.java:1879)
    >   	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Processor$cancel.getResult(RemoteInterpreterService.java:1864)
    >   	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
    >   	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
    >   	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)
    >   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    >   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    >   	at java.lang.Thread.run(Thread.java:748)
    >    INFO [2021-05-16 15:19:38,879] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20201016-154755_24366630 finished by scheduler interpreter_2016348950
    >   ERROR [2021-05-16 15:19:38,915] ({grpc-default-executor-3} SerializingExecutor.java[run]:126) - Exception while executing runnable io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable@49d28381
    >   java.lang.NullPointerException
    >   	at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
    >   	at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
    >   	at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
    >   	at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
    >   	at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
    >   	at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
    >   	at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
    >   	at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
    >   	at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:403)
    >   	at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
    >   	at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
    >   	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
    >   	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
    >   	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1MessagesAvailable.runInContext(ClientCallImpl.java:531)
    >   	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
    >   	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
    >   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    >   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    >   	at java.lang.Thread.run(Thread.java:748)
    >    INFO [2021-05-16 15:19:38,917] ({pool-1-thread-4} NewSparkInterpreter.java[close]:134) - Close SparkInterpreter
    >    WARN [2021-05-16 15:19:38,922] ({Exec Default Executor} IPythonInterpreter.java[onProcessFailed]:408) - Exception happens in Python Process
    >   org.apache.commons.exec.ExecuteException: Process exited with an error: 143 (Exit value: 143)
    >   	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
    >   	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
    >   	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
    >   	at java.lang.Thread.run(Thread.java:748)
    >    INFO [2021-05-16 15:19:38,933] ({pool-1-thread-4} AbstractConnector.java[doStop]:318) - Stopped Spark@6de3874f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
    >    INFO [2021-05-16 15:19:38,937] ({pool-1-thread-4} Logging.scala[logInfo]:54) - Stopped Spark web UI at http://zeppelin:4040
    >    INFO [2021-05-16 15:19:38,943] ({YARN application state monitor} Logging.scala[logInfo]:54) - Interrupting monitor thread
    >    INFO [2021-05-16 15:19:38,969] ({pool-1-thread-4} Logging.scala[logInfo]:54) - Shutting down all executors
    >    INFO [2021-05-16 15:19:38,970] ({dispatcher-event-loop-13} Logging.scala[logInfo]:54) - Asking each executor to shut down
    >    INFO [2021-05-16 15:19:38,973] ({pool-1-thread-4} Logging.scala[logInfo]:54) - Stopping SchedulerExtensionServices
    >   (serviceOption=None,
    >    services=List(),
    >    started=false)
    >    INFO [2021-05-16 15:19:38,975] ({pool-1-thread-4} Logging.scala[logInfo]:54) - Stopped
    >    INFO [2021-05-16 15:19:39,009] ({dispatcher-event-loop-11} Logging.scala[logInfo]:54) - MapOutputTrackerMasterEndpoint stopped!
    >    INFO [2021-05-16 15:19:39,024] ({pool-1-thread-4} Logging.scala[logInfo]:54) - MemoryStore cleared
    >    INFO [2021-05-16 15:19:39,025] ({pool-1-thread-4} Logging.scala[logInfo]:54) - BlockManager stopped
    >    INFO [2021-05-16 15:19:39,025] ({pool-1-thread-4} Logging.scala[logInfo]:54) - BlockManagerMaster stopped
    >    INFO [2021-05-16 15:19:39,030] ({dispatcher-event-loop-9} Logging.scala[logInfo]:54) - OutputCommitCoordinator stopped!
    >    INFO [2021-05-16 15:19:39,034] ({pool-1-thread-4} Logging.scala[logInfo]:54) - Successfully stopped SparkContext
    >    INFO [2021-05-16 15:19:39,035] ({pool-1-thread-4} Logging.scala[logInfo]:54) - SparkContext already stopped.
    >    INFO [2021-05-16 15:19:39,048] ({pool-1-thread-4} RemoteInterpreterServer.java[shutdown]:209) - Shutting down...
    >    INFO [2021-05-16 15:19:39,048] ({pool-1-thread-4} NewSparkInterpreter.java[close]:134) - Close SparkInterpreter
    >    INFO [2021-05-16 15:19:41,153] ({Thread-1} Logging.scala[logInfo]:54) - Shutdown hook called
    >    INFO [2021-05-16 15:19:41,155] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /mnt/cinder/vdc/spark/temp/spark-9b480991-a24e-45db-bfde-641c9939eb61
    >    INFO [2021-05-16 15:19:41,157] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /mnt/cinder/vdc/spark/temp/spark-9b480991-a24e-45db-bfde-641c9939eb61/pyspark-b13b1258-3abd-4760-a1bd-2bf15028f731
    >    INFO [2021-05-16 15:19:41,159] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-58feba93-11b2-4c14-a40c-0fc005f4d3a8


# -----------------------------------------------------
# Checking the worker log ..
#[user@worker03]

    pushd /var/hadoop/logs

        cat userlogs/application_1619571756695_0025/container_1619571756695_0025_01_000004/stderr


        #
        # Worker finish the last task it was sent
        #

    >   ....
    >   2021-05-16 14:36:18,430 INFO executor.Executor: Running task 5715.0 in stage 39.0 (TID 131595)
    >   2021-05-16 14:36:18,430 INFO executor.Executor: Finished task 5706.0 in stage 39.0 (TID 131592). 1829 bytes result sent to driver
    >   2021-05-16 14:36:18,430 INFO executor.Executor: Finished task 5713.0 in stage 39.0 (TID 131593). 1829 bytes result sent to driver
    >   2021-05-16 14:36:18,431 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 131596
    >   2021-05-16 14:36:18,431 INFO executor.Executor: Running task 5717.0 in stage 39.0 (TID 131596)
    >   2021-05-16 14:36:18,431 INFO executor.Executor: Finished task 5714.0 in stage 39.0 (TID 131594). 1829 bytes result sent to driver
    >   2021-05-16 14:36:18,432 INFO storage.BlockManager: Found block rdd_4_5715 locally
    >   2021-05-16 14:36:18,432 INFO columnar.InMemoryTableScanExec: Predicate isnotnull(parallax#9) generates partition filter: ((parallax.count#2692 - parallax.nullCount#2691) > 0)
    >   2021-05-16 14:36:18,432 INFO columnar.InMemoryTableScanExec: Predicate isnotnull(random_index#3L) generates partition filter: ((random_index.count#2667 - random_index.nullCount#2666) > 0)
    >   2021-05-16 14:36:18,432 INFO columnar.InMemoryTableScanExec: Predicate (parallax#9 < -8.0) generates partition filter: (parallax.lowerBound#2690 < -8.0)
    >   2021-05-16 14:36:18,433 INFO storage.BlockManager: Found block rdd_4_5717 locally
    >   2021-05-16 14:36:18,433 INFO executor.Executor: Finished task 5715.0 in stage 39.0 (TID 131595). 1829 bytes result sent to driver
    >   2021-05-16 14:36:18,433 INFO columnar.InMemoryTableScanExec: Predicate isnotnull(parallax#9) generates partition filter: ((parallax.count#2692 - parallax.nullCount#2691) > 0)
    >   2021-05-16 14:36:18,433 INFO columnar.InMemoryTableScanExec: Predicate isnotnull(random_index#3L) generates partition filter: ((random_index.count#2667 - random_index.nullCount#2666) > 0)
    >   2021-05-16 14:36:18,433 INFO columnar.InMemoryTableScanExec: Predicate (parallax#9 < -8.0) generates partition filter: (parallax.lowerBound#2690 < -8.0)
    >   2021-05-16 14:36:18,435 INFO executor.Executor: Finished task 5717.0 in stage 39.0 (TID 131596). 1829 bytes result sent to driver
    >   2021-05-16 14:57:37,224 INFO storage.BlockManager: Removing RDD 103
    >   ....

    #
    # Then waits until restarting the PySpark interpreter on the Zeppelin node sends a shutdown command.
    #

    >   ....
    >   2021-05-16 15:19:39,006 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
    >   2021-05-16 15:19:39,030 INFO executor.CoarseGrainedExecutorBackend: Driver from zeppelin:43123 disconnected during shutdown
    >   2021-05-16 15:19:39,031 INFO executor.CoarseGrainedExecutorBackend: Driver from zeppelin:43123 disconnected during shutdown
    >   2021-05-16 15:19:39,098 INFO memory.MemoryStore: MemoryStore cleared
    >   2021-05-16 15:19:39,098 INFO storage.BlockManager: BlockManager stopped
    >   2021-05-16 15:19:39,137 INFO util.ShutdownHookManager: Shutdown hook called
    >   2021-05-16 15:19:39,138 INFO util.ShutdownHookManager: Deleting directory /mnt/cinder/vdc/hadoop/temp/nm-local-dir/usercache/fedora/appcache/application_1619571756695_0025/spark-cddfa5c6-bdb7-48b2-a2e6-af3bd3f3bbe5


# -----------------------------------------------------
# -----------------------------------------------------

    So this looks like something in Zeppelin stalled rather than issues with disc access ?



