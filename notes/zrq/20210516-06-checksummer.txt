#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#



    Target:

        Simple test to monitor data access speed.

    Result:

        Work in progress ....

# -----------------------------------------------------
# Login to the live service master node
#[user@master01]

    ssh zeppelin
        ssh master01


# -----------------------------------------------------
# List the Parquet files in HDFS
#[user@master01]

    hadoop fs -ls -C hdfs://master01:9000/partitioned/GEDR3-4096 | head

    >   hdfs://master01:9000/partitioned/GEDR3-4096/_SUCCESS
    >   hdfs://master01:9000/partitioned/GEDR3-4096/part-00000-dc9b579c-2247-48f9-8f92-6ffbc0384845_00000.c000.snappy.parquet
    >   hdfs://master01:9000/partitioned/GEDR3-4096/part-00001-dc9b579c-2247-48f9-8f92-6ffbc0384845_00001.c000.snappy.parquet
    >   hdfs://master01:9000/partitioned/GEDR3-4096/part-00002-dc9b579c-2247-48f9-8f92-6ffbc0384845_00002.c000.snappy.parquet
    >   ....
    >   ....


    hadoop fs -ls -C hdfs://master01:9000/partitioned/GEDR3-4096 | tail

    >   ....
    >   ....
    >   hdfs://master01:9000/partitioned/GEDR3-4096/part-04092-dc9b579c-2247-48f9-8f92-6ffbc0384845_04092.c000.snappy.parquet
    >   hdfs://master01:9000/partitioned/GEDR3-4096/part-04093-dc9b579c-2247-48f9-8f92-6ffbc0384845_04093.c000.snappy.parquet
    >   hdfs://master01:9000/partitioned/GEDR3-4096/part-04094-dc9b579c-2247-48f9-8f92-6ffbc0384845_04094.c000.snappy.parquet
    >   hdfs://master01:9000/partitioned/GEDR3-4096/part-04095-dc9b579c-2247-48f9-8f92-6ffbc0384845_04095.c000.snappy.parquet

# -----------------------------------------------------
# Create our checksum timing loop
#[user@master01]

    mkdir /tmp/parquet

    timeget()
        {
        hdfspath=${1}
        tempfile=/tmp/parquet/$(basename ${hdfspath})
        hadoop fs -get "${hdfspath}" "${tempfile}"
        md5sum "${tempfile}"
        }

    timestep()
        {
        echo "----"
        date --iso-8601=s
        time -p timeget "${1}"
        sleep 20
        }

    # better to do the checksum inside HDFS

    timestep()
        {
        echo "----"
        date --iso-8601=s
        time -p hadoop fs -checksum "${1}"
        sleep 20
        }

    hdfsbase=hdfs://master01:9000/partitioned/GEDR3-4096/

    while true
    do
        for hdfspath in $(hadoop fs -ls -C ${hdfsbase})
        do
            timestep "${hdfspath}"
        done
    done





