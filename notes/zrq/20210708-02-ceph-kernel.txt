#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:
    
        Change CephFS mounts from fuse to kernel client.

    Result:
    
        Success, all the data shares are mounted using the kernel driver.
        No significant impact on performance.
        Working with cached data in Spark context runs very slow.

    Context:
    
        Desktop restarted, need to re-connect client.
        

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman rm ansibler

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2020.12.02 \
        bash


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudname=gaia-dev


# -----------------------------------------------------
# Create the deployment status.
#[root@ansibler]

    cat > '/tmp/aglais-status.yml' << EOF
aglais:
 status:
   deployment:
     type: hadoop-yarn
     conf: cclake-medium-04
     name: gaia-dev-20210708
     date: 20210708T025418
 spec:
   openstack:
     cloud: gaia-dev
EOF


    ln -sf '/tmp/aglais-status.yml' '/tmp/ansible-vars.yml'


# -----------------------------------------------------
# Run the ssh config script.
#[root@ansibler]

    config=cclake-medium-04
    inventory="config/${config:?}.yml"

    pushd "/deployments/hadoop-yarn/ansible"

        ansible-playbook \
            --verbose \
            --verbose \
            --inventory "${inventory:?}" \
            "05-config-ssh.yml"

        ansible-playbook \
            --verbose \
            --verbose \
            --inventory "${inventory:?}" \
            "08-ping-test.yml"

    popd


# -----------------------------------------------------
# Login to the Zeppelin node and add the notebooks from github.
#[root@ansibler]

    ssh zeppelin

        pushd /home/fedora/zeppelin

            mv notebook \
               notebook-origin

	        git clone https://github.com/wfau/aglais-notebooks.git notebook

	        bin/zeppelin-daemon.sh restart

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]


# -----------------------------------------------------
# -----------------------------------------------------
# Login via Firefox
#[user@desktop]

    firefox --new-window "http://zeppelin.gaia-dev.aglais.uk:8080/" &


# -----------------------------------------------------
# -----------------------------------------------------

    Run the test ....

    AglaisPublicExamples/SetUp
    http://zeppelin.gaia-dev.aglais.uk:8080/#/notebook/2G7GZKWUH

    AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier
    http://zeppelin.gaia-dev.aglais.uk:8080/#/notebook/2G5NU6HTK
    

        #
        # Starting a new test, (500 trees on 100% data)
        #

        First cell - Took 0 sec. Last updated by zrq at July 09 2021, 5:03:05 AM.
        Last cell  - Took 6 sec. Last updated by zrq at July 09 2021, 5:13:32 AM.

        datediff --format '%Hhr %Mmin %Ssec' '5:03:05' '5:13:32'

        10min 27sec

        #
        # Run the same test again (without restarting the Spark Context)
        #

        First cell - Took 0 sec. Last updated by zrq at July 09 2021, 5:20:40 AM.
        Last cell  - Took 5 sec. Last updated by zrq at July 09 2021, 6:03:03 AM.

        datediff --format '%Hhr %Mmin %Ssec' '5:20:40' '6:03:03'

        42min 23sec


# -----------------------------------------------------
# -----------------------------------------------------
# Login via podman exec and tail the logs.
#[user@desktop]


    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash        
            
                ssh zeppelin
        
                    tail -f /home/fedora/zeppelin/logs/zeppelin-interpreter-spark-fedora-gaia-dev-20210708-zeppelin.novalocal.log


    # Second run - re-used context

    >   ....
    >   INFO [2021-07-09 04:26:56,878] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Starting task 734.0 in stage 64.0 (TID 98571, worker03, executor 7, partition 734, PROCESS_LOCAL, 8439 bytes)
    >   INFO [2021-07-09 04:26:56,879] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 686.0 in stage 64.0 (TID 98523) in 2285 ms on worker03 (executor 7) (691/4609)
    >   INFO [2021-07-09 04:26:56,911] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Starting task 735.0 in stage 64.0 (TID 98572, worker01, executor 3, partition 735, PROCESS_LOCAL, 8439 bytes)
    >   INFO [2021-07-09 04:26:56,911] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 691.0 in stage 64.0 (TID 98528) in 1832 ms on worker01 (executor 3) (692/4609)
    >   INFO [2021-07-09 04:26:56,936] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 736.0 in stage 64.0 (TID 98573, worker02, executor 6, partition 736, PROCESS_LOCAL, 8439 bytes)
    >   INFO [2021-07-09 04:26:56,936] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 693.0 in stage 64.0 (TID 98530) in 1629 ms on worker02 (executor 6) (693/4609)
    >   INFO [2021-07-09 04:26:56,950] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Starting task 737.0 in stage 64.0 (TID 98574, worker02, executor 2, partition 737, PROCESS_LOCAL, 8439 bytes)
    >   INFO [2021-07-09 04:26:56,950] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 708.0 in stage 64.0 (TID 98545) in 1362 ms on worker02 (executor 2) (694/4609)
    >   INFO [2021-07-09 04:26:56,968] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Starting task 738.0 in stage 64.0 (TID 98575, worker03, executor 7, partition 738, PROCESS_LOCAL, 8439 bytes)
    >   INFO [2021-07-09 04:26:56,969] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 696.0 in stage 64.0 (TID 98533) in 1614 ms on worker03 (executor 7) (695/4609)
    >   ....

    >   ....
    >   INFO [2021-07-09 04:31:08,638] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 3107.0 in stage 66.0 (TID 105554) in 1814 ms on worker02 (executor 10) (3126/4608)
    >   INFO [2021-07-09 04:31:08,638] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 3115.0 in stage 66.0 (TID 105562) in 1661 ms on worker02 (executor 10) (3127/4608)
    >   INFO [2021-07-09 04:31:08,638] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 3124.0 in stage 66.0 (TID 105571) in 1435 ms on worker03 (executor 7) (3128/4608)
    >   INFO [2021-07-09 04:31:08,638] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 3118.0 in stage 66.0 (TID 105565) in 1531 ms on worker01 (executor 11) (3129/4608)
    >   INFO [2021-07-09 04:31:08,638] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 3122.0 in stage 66.0 (TID 105569) in 1483 ms on worker01 (executor 8) (3130/4608)
    >   INFO [2021-07-09 04:31:08,639] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 3113.0 in stage 66.0 (TID 105560) in 1684 ms on worker04 (executor 9) (3131/4608)
    >   INFO [2021-07-09 04:31:08,639] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 3176.0 in stage 66.0 (TID 105623, worker01, executor 8, partition 3176, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,639] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 3136.0 in stage 66.0 (TID 105583) in 1108 ms on worker04 (executor 9) (3132/4608)
    >   INFO [2021-07-09 04:31:08,639] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 3129.0 in stage 66.0 (TID 105576) in 1234 ms on worker01 (executor 8) (3133/4608)
    >   INFO [2021-07-09 04:31:08,639] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 3177.0 in stage 66.0 (TID 105624, worker01, executor 3, partition 3177, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,639] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 3112.0 in stage 66.0 (TID 105559) in 1685 ms on worker01 (executor 3) (3134/4608)
    >   INFO [2021-07-09 04:31:08,639] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 3178.0 in stage 66.0 (TID 105625, worker01, executor 3, partition 3178, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,640] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 3179.0 in stage 66.0 (TID 105626, worker01, executor 3, partition 3179, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,640] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 3180.0 in stage 66.0 (TID 105627, worker01, executor 3, partition 3180, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,640] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 3181.0 in stage 66.0 (TID 105628, worker03, executor 4, partition 3181, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,640] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 3182.0 in stage 66.0 (TID 105629, worker03, executor 4, partition 3182, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,640] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 3183.0 in stage 66.0 (TID 105630, worker03, executor 4, partition 3183, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,640] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 3111.0 in stage 66.0 (TID 105558) in 1695 ms on worker01 (executor 3) (3135/4608)
    >   INFO [2021-07-09 04:31:08,640] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 3131.0 in stage 66.0 (TID 105578) in 1229 ms on worker01 (executor 3) (3136/4608)
    >   INFO [2021-07-09 04:31:08,641] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 3128.0 in stage 66.0 (TID 105575) in 1239 ms on worker03 (executor 4) (3137/4608)
    >   INFO [2021-07-09 04:31:08,641] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 3105.0 in stage 66.0 (TID 105552) in 1837 ms on worker03 (executor 4) (3138/4608)
    >   INFO [2021-07-09 04:31:08,641] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 3127.0 in stage 66.0 (TID 105574) in 1247 ms on worker03 (executor 4) (3139/4608)
    >   INFO [2021-07-09 04:31:08,641] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 3146.0 in stage 66.0 (TID 105593) in 881 ms on worker01 (executor 3) (3140/4608)
    >   INFO [2021-07-09 04:31:08,643] ({dispatcher-event-loop-5} Logging.scala[logInfo]:54) - Starting task 3184.0 in stage 66.0 (TID 105631, worker02, executor 2, partition 3184, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,643] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 3145.0 in stage 66.0 (TID 105592) in 889 ms on worker02 (executor 2) (3141/4608)
    >   INFO [2021-07-09 04:31:08,645] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned RDD 6
    >   INFO [2021-07-09 04:31:08,645] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 125
    >   INFO [2021-07-09 04:31:08,646] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker02:35245 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,647] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker01:40567 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,647] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker01:43571 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,647] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on zeppelin:43285 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,647] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker04:41781 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,647] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker02:37667 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,647] ({dispatcher-event-loop-5} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker04:33319 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,647] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker01:39009 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,648] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker04:34333 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,648] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker02:40783 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,651] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker03:36787 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,658] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Starting task 3185.0 in stage 66.0 (TID 105632, worker01, executor 8, partition 3185, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,658] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 3137.0 in stage 66.0 (TID 105584) in 1102 ms on worker01 (executor 8) (3142/4608)
    >   INFO [2021-07-09 04:31:08,667] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on worker03:34783 in memory (size: 26.7 KB, free: 6.2 GB)
    >   INFO [2021-07-09 04:31:08,668] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 104
    >   INFO [2021-07-09 04:31:08,668] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 124
    >   INFO [2021-07-09 04:31:08,669] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 126
    >   INFO [2021-07-09 04:31:08,669] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 122
    >   INFO [2021-07-09 04:31:08,669] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 121
    >   INFO [2021-07-09 04:31:08,669] ({Spark Context Cleaner} Logging.scala[logInfo]:54) - Cleaned accumulator 123
    >   INFO [2021-07-09 04:31:08,962] ({dispatcher-event-loop-5} Logging.scala[logInfo]:54) - Starting task 3186.0 in stage 66.0 (TID 105633, worker03, executor 4, partition 3186, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:08,962] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 3140.0 in stage 66.0 (TID 105587) in 1353 ms on worker03 (executor 4) (3143/4608)
    >   INFO [2021-07-09 04:31:09,101] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Starting task 3187.0 in stage 66.0 (TID 105634, worker02, executor 2, partition 3187, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:09,101] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 3139.0 in stage 66.0 (TID 105586) in 1504 ms on worker02 (executor 2) (3144/4608)
    >   INFO [2021-07-09 04:31:09,115] ({dispatcher-event-loop-4} Logging.scala[logInfo]:54) - Starting task 3188.0 in stage 66.0 (TID 105635, worker02, executor 6, partition 3188, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:09,115] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 3135.0 in stage 66.0 (TID 105582) in 1603 ms on worker02 (executor 6) (3145/4608)
    >   INFO [2021-07-09 04:31:09,298] ({dispatcher-event-loop-5} Logging.scala[logInfo]:54) - Starting task 3189.0 in stage 66.0 (TID 105636, worker02, executor 10, partition 3189, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 04:31:09,298] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 3134.0 in stage 66.0 (TID 105581) in 1795 ms on worker02 (executor 10) (3146/4608)
    >   ....



# -----------------------------------------------------
# -----------------------------------------------------
# Login via podman exec and tail the worker logs.
#[user@desktop]


    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash        
            
                ssh worker01

                    tail -f /var/hadoop/logs/userlogs/application_1625714931998_0001/container_1625714931998_0001_01_000012/stderr 

    #
    # Second run - re-used context
    # First few cells are fast.
    # Training the random forest is slower than before.
    # Going back to the Parquet files and re-running the ra/dec selection.
    # SLOW

    >   ....
    >   2021-07-09 04:27:19,233 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 99048
    >   2021-07-09 04:27:19,233 INFO executor.Executor: Running task 1211.0 in stage 64.0 (TID 99048)
    >   2021-07-09 04:27:19,238 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/GEDR3/GEDR3_GAIASOURCE/part-00663-061dbeeb-75b5-41c3-9d01-422766759ddd_00663.c000.snappy.parquet, range: 134217728-268435456, partition values: [empty row]
    >   2021-07-09 04:27:19,256 INFO compat.FilterCompat: Filtering using predicate: and(and(and(and(noteq(b, null), noteq(parallax, null)), gt(parallax, 8.0)), or(or(lt(dec, -80.0), gt(dec, -65.0)), and(lt(ra, 350.0), gt(ra, 40.0)))), or(or(lt(dec, -80.0), gt(dec, -55.0)), or(lt(ra, 40.0), gt(ra, 120.0))))
    >   2021-07-09 04:27:19,258 INFO compat.FilterCompat: Filtering using predicate: and(and(and(and(noteq(b, null), noteq(parallax, null)), gt(parallax, 8.0)), or(or(lt(dec, -80.0), gt(dec, -65.0)), and(lt(ra, 350.0), gt(ra, 40.0)))), or(or(lt(dec, -80.0), gt(dec, -55.0)), or(lt(ra, 40.0), gt(ra, 120.0))))
    >   2021-07-09 04:27:19,259 INFO compat.FilterCompat: Filtering using predicate: and(and(and(and(noteq(b, null), noteq(parallax, null)), gt(parallax, 8.0)), or(or(lt(dec, -80.0), gt(dec, -65.0)), and(lt(ra, 350.0), gt(ra, 40.0)))), or(or(lt(dec, -80.0), gt(dec, -55.0)), or(lt(ra, 40.0), gt(ra, 120.0))))
    >   2021-07-09 04:27:20,330 INFO executor.Executor: Finished task 1160.0 in stage 64.0 (TID 98997). 3214 bytes result sent to driver
    >   ....
    >   2021-07-09 04:29:35,928 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 102374
    >   2021-07-09 04:29:35,928 INFO executor.Executor: Running task 4537.0 in stage 64.0 (TID 102374)
    >   2021-07-09 04:29:35,933 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/GEDR3/GEDR3_GAIASOURCE/part-00981-061dbeeb-75b5-41c3-9d01-422766759ddd_00981.c000.snappy.parquet, range: 268435456-293635365, partition values: [empty row]
    >   2021-07-09 04:29:35,937 INFO compat.FilterCompat: Filtering using predicate: and(and(and(and(noteq(b, null), noteq(parallax, null)), gt(parallax, 8.0)), or(or(lt(dec, -80.0), gt(dec, -65.0)), and(lt(ra, 350.0), gt(ra, 40.0)))), or(or(lt(dec, -80.0), gt(dec, -55.0)), or(lt(ra, 40.0), gt(ra, 120.0))))
    >   2021-07-09 04:29:35,938 INFO compat.FilterCompat: Filtering using predicate: and(and(and(and(noteq(b, null), noteq(parallax, null)), gt(parallax, 8.0)), or(or(lt(dec, -80.0), gt(dec, -65.0)), and(lt(ra, 350.0), gt(ra, 40.0)))), or(or(lt(dec, -80.0), gt(dec, -55.0)), or(lt(ra, 40.0), gt(ra, 120.0))))
    >   2021-07-09 04:29:35,940 INFO compat.FilterCompat: Filtering using predicate: and(and(and(and(noteq(b, null), noteq(parallax, null)), gt(parallax, 8.0)), or(or(lt(dec, -80.0), gt(dec, -65.0)), and(lt(ra, 350.0), gt(ra, 40.0)))), or(or(lt(dec, -80.0), gt(dec, -55.0)), or(lt(ra, 40.0), gt(ra, 120.0))))
    >   2021-07-09 04:29:35,940 INFO compat.FilterCompat: Filtering using predicate: and(and(and(and(noteq(b, null), noteq(parallax, null)), gt(parallax, 8.0)), or(or(lt(dec, -80.0), gt(dec, -65.0)), and(lt(ra, 350.0), gt(ra, 40.0)))), or(or(lt(dec, -80.0), gt(dec, -55.0)), or(lt(ra, 40.0), gt(ra, 120.0))))
    >   2021-07-09 04:29:35,941 INFO compat.FilterCompat: Filtering using predicate: and(and(and(and(noteq(b, null), noteq(parallax, null)), gt(parallax, 8.0)), or(or(lt(dec, -80.0), gt(dec, -65.0)), and(lt(ra, 350.0), gt(ra, 40.0)))), or(or(lt(dec, -80.0), gt(dec, -55.0)), or(lt(ra, 40.0), gt(ra, 120.0))))
    >   2021-07-09 04:29:35,941 INFO compat.FilterCompat: Filtering using predicate: and(and(and(and(noteq(b, null), noteq(parallax, null)), gt(parallax, 8.0)), or(or(lt(dec, -80.0), gt(dec, -65.0)), and(lt(ra, 350.0), gt(ra, 40.0)))), or(or(lt(dec, -80.0), gt(dec, -55.0)), or(lt(ra, 40.0), gt(ra, 120.0))))
    >   2021-07-09 04:29:35,942 INFO executor.Executor: Finished task 4500.0 in stage 64.0 (TID 102337). 3214 bytes result sent to driver
    >   ....

    #
    #
    
    



