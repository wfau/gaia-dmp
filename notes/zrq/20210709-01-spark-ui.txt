#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#


    Target:
    
        Add a tunnel for Spark UI to our client container.

    Result:
    
        Work in progress ...

        

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman rm ansibler

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --publish 8088:8088 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2020.12.02 \
        bash


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudname=gaia-dev


# -----------------------------------------------------
# Create the deployment status.
#[root@ansibler]

    cat > '/tmp/aglais-status.yml' << EOF
aglais:
 status:
   deployment:
     type: hadoop-yarn
     conf: cclake-medium-04
     name: gaia-dev-20210708
     date: 20210708T025418
 spec:
   openstack:
     cloud: gaia-dev
EOF


    ln -sf '/tmp/aglais-status.yml' '/tmp/ansible-vars.yml'


# -----------------------------------------------------
# Run the ssh config script.
#[root@ansibler]

    config=cclake-medium-04
    inventory="config/${config:?}.yml"

    pushd "/deployments/hadoop-yarn/ansible"

        ansible-playbook \
            --verbose \
            --verbose \
            --inventory "${inventory:?}" \
            "05-config-ssh.yml"

        ansible-playbook \
            --verbose \
            --verbose \
            --inventory "${inventory:?}" \
            "08-ping-test.yml"

    popd


# -----------------------------------------------------
# -----------------------------------------------------
# Login via Firefox
#[user@desktop]

    firefox --new-window "http://zeppelin.gaia-dev.aglais.uk:8080/" &


# -----------------------------------------------------
# -----------------------------------------------------

    Run the test ....

    AglaisPublicExamples/SetUp
    http://zeppelin.gaia-dev.aglais.uk:8080/#/notebook/2G7GZKWUH

    AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier
    http://zeppelin.gaia-dev.aglais.uk:8080/#/notebook/2G5NU6HTK
    

        #
        # Starting a new test, (500 trees on 100% data)
        #

        First cell - Took 0 sec. Last updated by zrq at July 09 2021, 1:18:06 PM.
        Last cell  - Took 0 sec. Last updated by zrq at July 09 2021, 1:28:34 PM.

        datediff --format '%Hhr %Mmin %Ssec' '1:18:06' '1:28:34'

        10min 28sec


# -----------------------------------------------------
# -----------------------------------------------------
# Login via podman exec and tail the logs.
#[user@desktop]

    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash        
            
                ssh zeppelin
        
                    tail -f /home/fedora/zeppelin/logs/zeppelin-interpreter-spark-fedora-gaia-dev-20210708-zeppelin.novalocal.log

    >   # Raw catalogue with selected columns
    >   ....
    >   INFO [2021-07-09 12:20:02,701] ({dispatcher-event-loop-5} Logging.scala[logInfo]:54) - Added rdd_6_764 in memory on worker04:38893 (size: 134.9 KB, free: 6.2 GB)
    >   INFO [2021-07-09 12:20:02,706] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Starting task 810.0 in stage 4.0 (TID 814, worker04, executor 3, partition 810, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 12:20:02,706] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 764.0 in stage 4.0 (TID 768) in 6533 ms on worker04 (executor 3) (767/2048)
    >   INFO [2021-07-09 12:20:02,711] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added rdd_6_746 in memory on worker01:33069 (size: 137.4 KB, free: 6.2 GB)
    >   INFO [2021-07-09 12:20:02,717] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Starting task 811.0 in stage 4.0 (TID 815, worker01, executor 4, partition 811, PROCESS_LOCAL, 8330 bytes)
    >   INFO [2021-07-09 12:20:02,718] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 746.0 in stage 4.0 (TID 750) in 8275 ms on worker01 (executor 4) (768/2048)
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Login via podman exec and tail the worker logs.
#[user@desktop]

    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash        
            
                ssh worker01

                    tail -f  /var/hadoop/logs/userlogs/application_1625714931998_0002/container_1625714931998_0002_01_000012/stderr

    >   # Raw catalogue with selected columns
    >   ....
    >   2021-07-09 12:19:27,835 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 557
    >   2021-07-09 12:19:27,835 INFO executor.Executor: Running task 553.0 in stage 4.0 (TID 557)
    >   2021-07-09 12:19:27,841 INFO datasources.FileScanRDD: Reading File path: file:///data/gaia/GEDR3/GEDR3_GAIASOURCE/part-00553-061dbeeb-75b5-41c3-9d01-422766759ddd_00553.c000.snappy.parquet, range: 0-294148117, partition values: [empty row]
    >   2021-07-09 12:19:27,853 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-07-09 12:19:27,857 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-07-09 12:19:27,858 INFO compat.FilterCompat: Filtering using predicate: noteq(parallax, null)
    >   2021-07-09 12:19:29,374 INFO memory.MemoryStore: Block rdd_6_534 stored as values in memory (estimated size 139.8 KB, free 6.2 GB)
    >   2021-07-09 12:19:29,379 INFO executor.Executor: Finished task 534.0 in stage 4.0 (TID 538). 2342 bytes result sent to driver
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Tunnel connection to the Spark UI on Zeppelin
# https://linuxize.com/post/how-to-setup-ssh-tunneling/
#[root@ansibler]

    ssh -f -N -L '8088:master:8088' fedora@zeppelin


# -----------------------------------------------------
# -----------------------------------------------------
# Login via Firefox
#[user@desktop]

    firefox --new-window "http://localhost:8088/" &

    # Entry point for Hadoop cluster
    http://localhost:8088/cluster

    # Fixed hostname in URL for Spark Application
    http://master01:8088/proxy/application_1625714931998_0002/

    # Modified hostname for Spark Application to use the proxy.
    http://localhost:8088/proxy/application_1625714931998_0002/


    # After a completed (first) run
    # Storage tab shows 2 RDDs cached in memory.
    
    #1 
        StorageLevel:       Memory Deserialized 1x Replicated 
        CachedPartitions:   2048
        FractionCached:     100%
        Size in memory      277.4 MB        
        Size on disk:       0 B
    
    #6 
        StorageLevel:       Memory Deserialized 1x Replicated 
        CachedPartitions:   2048
        FractionCached:     100%
        Size in memory      600.6 MB        
        Size on disk:       0 B


    # During second run Storage tab is empty.


