#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Add performance metris to the large deployment.

    Result:

        Work in progress ..


# -----------------------------------------------------
# Tunnel connection to the Spark and Grafana interfaces.
# https://linuxize.com/post/how-to-setup-ssh-tunneling/
#[root@ansibler]

    ssh -f -N \
        -o 'ServerAliveInterval=10' \
        -L '3000:monitor:3000'  \
        -L '8088:master01:8088' \
        fedora@zeppelin


# -----------------------------------------------------
# -----------------------------------------------------
# Login to the Spark UI using Firefox.
#[user@desktop]

    firefox --new-window 'http://localhost:8088/' &

    # Entry point for Hadoop cluster
    http://localhost:8088/cluster

    # Application cluster page
    http://localhost:8088/cluster/app/application_1628007610214_0001

    # Original application page
    http://master01:8088/proxy/application_1628007610214_0001/

    # Localhost application page
    http://localhost:8088/proxy/application_1628007610214_0001/
    http://localhost:8088/proxy/application_1628007610214_0001/executors/

    # 12 executors, 4 cores each, 6.7G memory


# -----------------------------------------------------
# Login to Grafana using Firefox
#[user@desktop]

    firefox --new-window 'http://localhost:3000/login' &

        user: admin
        pass: admin


    # Optionally set new password in the next page
        ########


# -----------------------------------------------------
# Add Prometheus Data Source
# From Stelios's notes

    # Click on button "Data Sources: Add your first data source"
    # Select Prometheus as the Data source
    # Set the url to: http://monitor:9090
    # Set the Scrape interval to 5s


# -----------------------------------------------------
# Add standard Dashboard
# From Stelios's notes

    # Import Dashboards for Node Exporter metrics:
    # https://grafana.com/grafana/dashboards/11074

    # Edit the filesystem monitors.
    # Several of the metrics limit the file system type 'fstype' to 'ext.*|xfs'
    # Update this to 'ext.*|btrfs' to include the discs we created.

    node_filesystem_free_bytes{instance=~'$node',fstype=~"ext.*|xfs",mountpoint !~".*pod.*"}
    node_filesystem_free_bytes{instance=~'$node',fstype=~"ext.*|btrfs",mountpoint !~".*pod.*"}


    # How to embed dashboards in our deploy ?


# -----------------------------------------------------
# Add our own Dashboard

    # Import from JSON file.
    # 20210705-02-grafana-dash.txt
    # How to embed dashboards in our deploy ?
























# -----------------------------------------------------
# Tail the worker logs from the ansibler container.
#[user@desktop]

    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash -c \
            '
            ssh worker01 \
                    "
                    lastapp=\$(
                        ls -1 /var/hadoop/logs/userlogs | tail -n 1
                        )

                    lastcont=\$(
                        ls -1 "/var/hadoop/logs/userlogs/\${lastapp}" | tail -n 1
                        )

                    tail -f /var/hadoop/logs/userlogs/\${lastapp}/\${lastcont}/stderr
                    "
            '


# -----------------------------------------------------
# Tail the zeppelin logs from the ansibler container.
#[user@desktop]

    podman exec \
        --tty \
        --interactive \
        ansibler \
            bash -c \
            '
            ssh zeppelin \
                    "
                    tail -f /home/fedora/zeppelin/logs/zeppelin-interpreter-spark-\$(id -un)-\$(hostname).log
                    "
            '

