#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Optimise the Spark configuration to use all of the available resources.

        Initial configuration only runs 12 executors on 6 workers, with lots of spare space.

        Apache Spark: Config Cheatsheet
        https://www.c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/
        https://www.c2fo.io/c2fo/spark/aws/emr/2016/09/01/apache-spark-config-cheatsheet-part2/

        https://www.c2fo.io/img/apache-spark-config-cheatsheet/C2FO-Spark-Config-Cheatsheet.xlsx

        https://github.com/AndresNamm/SparkDebugging

    Result:

        Passes the main tests



# -----------------------------------------------------
# -----------------------------------------------------
# Edit the deployment configuration.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        pushd deployments/hadoop-yarn/ansible/config

            gedit cclake-large-06.yml &

        popd
    popd

    >   ....
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Configure Hadoop, Spark and Zeppelin
#[root@ansibler]

    pushd '/deployments/hadoop-yarn/ansible'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '16-config-yarn-masters.yml'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '17-config-yarn-workers.yml'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '22-config-spark-master.yml'

    popd


# -----------------------------------------------------
# Restart the services to recognise changes.
#[root@ansibler]

    ssh master01 \
        '
        /opt/hadoop/sbin/stop-all.sh

        echo ""
        echo "Pause ...."
        sleep 30
        echo ""

        /opt/hadoop/sbin/start-all.sh
        '

    >   Stopping namenodes on [master01]
    >   Stopping datanodes
    >   Stopping secondary namenodes [gaia-dev-20210803-master01.novalocal]
    >   Stopping nodemanagers
    >   Stopping resourcemanager

    >   Starting namenodes on [master01]
    >   Starting datanodes
    >   Starting secondary namenodes [gaia-dev-20210803-master01.novalocal]
    >   Starting resourcemanager
    >   Starting nodemanagers


    ssh zeppelin \
        '
        /home/fedora/zeppelin/bin/zeppelin-daemon.sh restart
        '

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]



# -----------------------------------------------------
# Update the SSH tunnel connection.
# https://linuxize.com/post/how-to-setup-ssh-tunneling/
#[root@ansibler]

    ssh -f -N \
        -o 'ServerAliveInterval=20' \
        -L '3000:monitor:3000'  \
        -L '8088:master01:8088' \
        fedora@zeppelin


# -----------------------------------------------------
# Login to Zeppelin as a normal user.
#[root@ansibler]

    gaiauser=$(secret aglais.zeppelin.gaiauser)
    gaiapass=$(secret aglais.zeppelin.gaiapass)

    zeplogin "${gaiauser:?}" "${gaiapass}"

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "principal": "gaiauser",
    >       "ticket": "54a11f97-6866-40b5-a8ce-d2923a68a0a4",
    >       "roles": "[\"user\"]"
    >     }
    >   }


# -----------------------------------------------------
# Run the SetUp notebook.
#[root@ansibler]

    noteid=2G7GZKWUH

    zepnbclear    ${noteid}
    zepnbexecstep ${noteid}

    zepnbexecute   ${noteid}
    zepnbtotaltime ${noteid}

    >   0:0:40


# -----------------------------------------------------
# Run the HealpixSourceCounts notebook
#[root@ansibler]

    noteid=2FKJ25GVF

    zepnbclear    ${noteid}
    zepnbexecstep ${noteid}

    >   Para [20210507-084613_357121151][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20200826-105718_1698521515][Set the resolution level and define the query]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20200826-110030_2095441495][Plot up the results]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20210507-091244_670006530][Further reading and resources]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20200826-110146_414730471][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]


    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

    >   0:0:21


# -----------------------------------------------------
# Run the MeanProperMotions notebook
#[root@ansibler]

    noteid=2G748GZSW

    zepnbclear    ${noteid}
    zepnbexecstep ${noteid}

    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

    >   0:0:35


# -----------------------------------------------------
# Run the RandomForest notebook.
#[root@ansibler]

    noteid=2G5NU6HTK

    zepnbclear    ${noteid}
    zepnbexecstep ${noteid}

    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

    >   Para [20201013-131059_546082898][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201013-131649_1734629667][Basic catalogue query selections and predicates]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201013-132418_278702125][Raw catalogue with selected columns]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201120-094650_221463065][Visualisation (colour / absolute-magnitue diagram) of the raw catalogue]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201120-110502_1704727157][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201123-105445_95907042][Define the training samples]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201015-161110_18118893][Assemble training and reserve test sets]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201013-152110_1282917873][Train up the Random Forrest]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20210504-153521_1591875670][Check feature set for nulls]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201015-131823_1744793710][Classify the reserved test sets]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201016-154755_24366630][Classification confusion matrix]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201123-163421_1811049882][Relative importance of the selected features]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201123-162249_1468741293][Apply the classification model and plot sample results]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201124-100512_110153564][Histogram of classification probability]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201125-103046_1353183691][Sky distribution of good source sample]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20201125-163312_728555601][Sky distribution of bad source sample]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20210428-140519_1288739408][Further reading and resources]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]
    >   
    >   Para [20210506-134212_1741520795][null]
    >   {
    >     "status": "OK",
    >     "body": {
    >       "code": "SUCCESS",
    >       "msg": []
    >     }
    >   }
    >   Result [SUCCESS]

    >   {
    >     "status": "OK",
    >     "message": "",
    >     "body": {
    >       "paragraphs": [],
    >       "name": "/AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier",
    >       "id": "2G5NU6HTK",
    >       "noteParams": {},
    >       "noteForms": {},
    >       "angularObjects": {
    >         "md:shared_process": [],
    >         "sh:shared_process": [],
    >         "spark:gaiauser:": []
    >       },
    >       "config": {
    >         "isZeppelinNotebookCronEnable": false
    >       },
    >       "info": {}
    >     }
    >   }

    >   0:7:55


