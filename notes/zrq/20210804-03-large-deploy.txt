#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

    Target:

        Optimise the Spark configuration to use all of the available resources.

        Initial configuration only runs 12 executors on 6 workers, with lots of spare space.

        Apache Spark: Config Cheatsheet
        https://www.c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/
        https://www.c2fo.io/c2fo/spark/aws/emr/2016/09/01/apache-spark-config-cheatsheet-part2/

        https://www.c2fo.io/img/apache-spark-config-cheatsheet/C2FO-Spark-Config-Cheatsheet.xlsx

        https://github.com/AndresNamm/SparkDebugging

    Result:

        Passes the main tests



# -----------------------------------------------------
# -----------------------------------------------------
# Edit the deployment configuration.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

        pushd deployments/hadoop-yarn/ansible/config

            gedit cclake-large-06.yml &

        popd
    popd

    >   ....
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Configure Hadoop, Spark and Zeppelin
#[root@ansibler]

    pushd '/deployments/hadoop-yarn/ansible'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '16-config-yarn-masters.yml'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '17-config-yarn-workers.yml'

        ansible-playbook \
            --verbose \
            --inventory "config/${deployconf}.yml" \
            '22-config-spark-master.yml'

    popd


# -----------------------------------------------------
# Restart the services to recognise changes.
#[root@ansibler]

    ssh master01 \
        '
        /opt/hadoop/sbin/stop-all.sh

        echo ""
        echo "Pause ...."
        sleep 30
        echo ""

        /opt/hadoop/sbin/start-all.sh
        '

    >   Stopping namenodes on [master01]
    >   Stopping datanodes
    >   Stopping secondary namenodes [gaia-dev-20210803-master01.novalocal]
    >   Stopping nodemanagers
    >   Stopping resourcemanager

    >   Starting namenodes on [master01]
    >   Starting datanodes
    >   Starting secondary namenodes [gaia-dev-20210803-master01.novalocal]
    >   Starting resourcemanager
    >   Starting nodemanagers


    ssh zeppelin \
        '
        /home/fedora/zeppelin/bin/zeppelin-daemon.sh restart
        '

    >   Zeppelin stop                                              [  OK  ]
    >   Zeppelin start                                             [  OK  ]



# -----------------------------------------------------
# Update the SSH tunnel connection.
# https://linuxize.com/post/how-to-setup-ssh-tunneling/
#[root@ansibler]

    ssh -f -N \
        -o 'ServerAliveInterval=20' \
        -L '3000:monitor:3000'  \
        -L '8088:master01:8088' \
        fedora@zeppelin


# -----------------------------------------------------
# Login to Zeppelin as a normal user.
#[root@ansibler]

    gaiauser=$(secret aglais.zeppelin.gaiauser)
    gaiapass=$(secret aglais.zeppelin.gaiapass)

    zeplogin "${gaiauser:?}" "${gaiapass}"

--START--
{
  "status": "OK",
  "message": "",
  "body": {
    "principal": "gaiauser",
    "ticket": "54a11f97-6866-40b5-a8ce-d2923a68a0a4",
    "roles": "[\"user\"]"
  }
}
--END--


# -----------------------------------------------------
# Run the SetUp notebook.
#[root@ansibler]

    noteid=2G7GZKWUH

    zepnbclear    ${noteid}
    zepnbexecstep ${noteid}

    zepnbexecute   ${noteid}
    zepnbtotaltime ${noteid}

--START--
0:0:40
--END--


# -----------------------------------------------------
# Run the HealpixSourceCounts notebook
#[root@ansibler]

    noteid=2FKJ25GVF

    zepnbclear    ${noteid}
    zepnbexecstep ${noteid}

--START--
Para [20210507-084613_357121151][null]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20200826-105718_1698521515][Set the resolution level and define the query]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20200826-110030_2095441495][Plot up the results]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20210507-091244_670006530][Further reading and resources]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20200826-110146_414730471][null]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]
--END--


    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

--START--
0:0:21
--END--


# -----------------------------------------------------
# Run the MeanProperMotions notebook
#[root@ansibler]

    noteid=2G748GZSW

    zepnbclear    ${noteid}
    zepnbexecstep ${noteid}

    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

--START--
0:0:35
--END--


# -----------------------------------------------------
# Run the RandomForest notebook.
#[root@ansibler]

    noteid=2G5NU6HTK

    zepnbclear    ${noteid}
    zepnbexecstep ${noteid}

    zepnbstatus    ${noteid}
    zepnbtotaltime ${noteid}

--START--
Para [20201013-131059_546082898][null]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201013-131649_1734629667][Basic catalogue query selections and predicates]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201013-132418_278702125][Raw catalogue with selected columns]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201120-094650_221463065][Visualisation (colour / absolute-magnitue diagram) of the raw catalogue]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201120-110502_1704727157][null]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201123-105445_95907042][Define the training samples]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201015-161110_18118893][Assemble training and reserve test sets]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201013-152110_1282917873][Train up the Random Forrest]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20210504-153521_1591875670][Check feature set for nulls]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201015-131823_1744793710][Classify the reserved test sets]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201016-154755_24366630][Classification confusion matrix]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201123-163421_1811049882][Relative importance of the selected features]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201123-162249_1468741293][Apply the classification model and plot sample results]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201124-100512_110153564][Histogram of classification probability]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201125-103046_1353183691][Sky distribution of good source sample]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20201125-163312_728555601][Sky distribution of bad source sample]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20210428-140519_1288739408][Further reading and resources]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]

Para [20210506-134212_1741520795][null]
{
  "status": "OK",
  "body": {
    "code": "SUCCESS",
    "msg": []
  }
}
Result [SUCCESS]
--END--

--START--
{
  "status": "OK",
  "message": "",
  "body": {
    "paragraphs": [],
    "name": "/AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier",
    "id": "2G5NU6HTK",
    "noteParams": {},
    "noteForms": {},
    "angularObjects": {
      "md:shared_process": [],
      "sh:shared_process": [],
      "spark:gaiauser:": []
    },
    "config": {
      "isZeppelinNotebookCronEnable": false
    },
    "info": {}
  }
}
--END--

--START--
0:7:55
--END--


